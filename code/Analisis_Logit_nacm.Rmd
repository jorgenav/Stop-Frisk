---
title: "Análisis logit"
author: "Nathaly"
date: "1 de mayo de 2017"
output: html_document
---


```{r, message=FALSE}
# Carga de librerías
library(magrittr)
library(dplyr)
library(car)
library(effects)
library(randomForest)
library(caret)
library(dataQualityR)
library(DMwR)
library(foreach)
#library(doMC)
#registerDoMC(4)
library(class)
```

# Creación de modelos predictivos

## Carga de datos

```{r,message=FALSE}
# Carga del Dataset
source('Cleaning_Data.R')
dim(SQFdata)
```

## Análisis descriptivo

```{r, message=FALSE}
drq.num <- paste("./dqr_num.csv", sep = "")
drq.cat <- paste("./dqr_cat.csv", sep = "")
checkDataQuality(SQFdata, out.file.num = drq.num,  out.file.cat = drq.cat)
DQR.num <- read.csv("dqr_num.csv")
DQR.cat <- read.csv("dqr_cat.csv")
```

### A Variables numéricas

```{r}
print(DQR.num)

# Variables a tener en cuenta por NAs -> age, xcoord e ycoord
```

### B Variables categóricas

```{r}
print(DQR.cat)
# Variables a tener en cuenta por NAs > 60% -> arstoffn, sumoffen, officrid, offverb, ¿offshld (54.62)?, forceuse, othfeatr, addrnum, stname, beat, post

# Variables a tener en cuenta por NAs cercanos al 20% -> adtlrept, pistol, riflshot, asltweap, knifcuti, machgun, othrweap, pf_hands, pf_wall, pf_grnd, pf_drwep, pf_ptwep, pf_baton, pf_hcuff, pf_pepsp, pf_other, , ac_rept, ac_inves, rf_vcrim, rf_othsw, ac_proxm, rf_attir, cs_objcs, cs_descr, cs_casng, cs_lkout, rf_vcact, cs_cloth, cs_drgtr, ac_evasv, ac_assoc, cs_furtv, rf_rfcmp, , ac_cgdir, rf_verbl, cs_vcrim, cs_bulge, cs_other, ac_incid, ac_time, rf_knowl, ac_stsnd, ac_other, sb_hdobj, sb_outln, sb_admis, sb_other, rf_furt, rf_bulg, premname, stinter, crossst, sector
```

## Transformación de los datos

## Ordenación de niveles en variable objetivo

```{r}
#SQFdataTest$arstmade <- relevel(SQFdataTest$arstmade, ref = "Y")
```

### Eliminación de variables

```{r}

# Eliminación de variables con más de 60% de datos faltantes.
SQFdata_modif <- SQFdata %>%
                    select(-c(arstoffn, sumoffen, officrid, offverb, offshld,
                                       forceuse, othfeatr, addrnum, stname, beat, post))



# Eliminación de variables con 20% de NAs pero nula varianza (casos pertenecientes
# todos a una misma clase). 6 variables eliminadas
summary(SQFdata_modif$adtlrept);summary(SQFdata_modif$riflshot);
summary(SQFdata_modif$asltweap);summary(SQFdata_modif$machgun);
summary(SQFdata_modif$pf_baton);summary(SQFdata_modif$pf_pepsp)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(adtlrept, riflshot, asltweap, machgun,
                             pf_baton, pf_pepsp))



# Eliminación de variables con demasiados niveles (strings). 4 variables eliminadas
summary(SQFdata_modif$premname);summary(SQFdata_modif$stinter);
summary(SQFdata_modif$crossst);summary(SQFdata_modif$sector)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(premname, stinter, crossst, sector))



# Eliminación de variables que no aparecen en el checkDataQuality. 7 variables eliminadas.
summary(SQFdata_modif$state);summary(SQFdata_modif$zip);summary(SQFdata_modif$addrtyp);
summary(SQFdata_modif$rescode);summary(SQFdata_modif$premtype);
summary(SQFdata_modif$aptnum);summary(SQFdata_modif$timestop)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(state,zip,addrtyp,rescode,premtype,aptnum,timestop))



# Eliminación de factores con más de 53 niveles. 4 variables eliminadas.
length(levels(SQFdata_modif$pct));length(levels(SQFdata_modif$crimsusp));
length(levels(SQFdata_modif$addrpct));length(levels(SQFdata_modif$detailCM))

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(pct,crimsusp,addrpct,detailCM))



# Eliminación de variables con poca varianza. 6 variables eliminadas.
summary(SQFdata_modif$year);summary(SQFdata_modif$datestop);
summary(SQFdata_modif$compyear);summary(SQFdata_modif$comppct);
summary(SQFdata_modif$lineCM);summary(SQFdata_modif$dob)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(year,datestop,compyear,comppct, lineCM, dob))



# Eliminación de más variables con poca varianza. 1 variable eliminada.

# Se analiza el atributo y en caso de que no sea un factor, se devuelve valor
# 2 para que no sea eliminado.
fun_2level <- function(x){
    ifelse(is.factor(x),return(length(levels(x))),return(2))
}

names(SQFdata_modif)[which(sapply(SQFdata_modif, fun_2level) < 2)]

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(which(sapply(SQFdata_modif, fun_2level) < 2)))



# Eliminación de coordenadas:
SQFdata_modif <- SQFdata_modif %>%
                    select(-c(xcoord, ycoord))



# Variables en duda
summary(SQFdata_modif$ser_num)
summary(SQFdata_modif$revcmd)
summary(SQFdata_modif$repcmd)



# Número de variables final
dim(SQFdata)
dim(SQFdata_modif)
```

### Eliminación de NAs

```{r}

# Eliminación de NAs en variable age
SQFdata_modif %>% group_by(is.na(age)) %>%
    summarise(n())

SQFdata_modif <- SQFdata_modif %>% filter(!is.na(age))

dim(SQFdata)
dim(SQFdata_modif)

# Trabajo con NAs

# Variables NO eliminadas

# Modificación de variables no eliminadas

# USO DE ARMAS
summary(SQFdata_modif$pistol);summary(SQFdata_modif$knifcuti);summary(SQFdata_modif$othrweap);

SQFdata_modif$pistol[which(is.na(SQFdata_modif$pistol))]     <- 'N'
SQFdata_modif$knifcuti[which(is.na(SQFdata_modif$knifcuti))] <- 'N'
SQFdata_modif$othrweap[which(is.na(SQFdata_modif$othrweap))] <- 'N'

# USO DE FUERZA FÍSICA
summary(SQFdata_modif$pf_hands);summary(SQFdata_modif$pf_wall);summary(SQFdata_modif$pf_grnd);
summary(SQFdata_modif$pf_drwep);summary(SQFdata_modif$pf_ptwep);summary(SQFdata_modif$pf_hcuff);
summary(SQFdata_modif$pf_other);

SQFdata_modif$pf_hands[which(is.na(SQFdata_modif$pf_hands))] <- 'N'
SQFdata_modif$pf_wall[which(is.na(SQFdata_modif$pf_wall))]   <- 'N'
SQFdata_modif$pf_grnd[which(is.na(SQFdata_modif$pf_grnd))]   <- 'N'
SQFdata_modif$pf_drwep[which(is.na(SQFdata_modif$pf_drwep))] <- 'N'
SQFdata_modif$pf_ptwep[which(is.na(SQFdata_modif$pf_ptwep))] <- 'N'
SQFdata_modif$pf_hcuff[which(is.na(SQFdata_modif$pf_hcuff))] <- 'N'
SQFdata_modif$pf_other[which(is.na(SQFdata_modif$pf_other))] <- 'N'

# CIRCUNSTANCIAS ADICIONALES
summary(SQFdata_modif$ac_rept);summary(SQFdata_modif$ac_inves);summary(SQFdata_modif$ac_proxm);
summary(SQFdata_modif$ac_evasv);summary(SQFdata_modif$ac_assoc);summary(SQFdata_modif$ac_cgdir);
summary(SQFdata_modif$ac_incid);summary(SQFdata_modif$ac_time);summary(SQFdata_modif$ac_stsnd);
summary(SQFdata_modif$ac_other);

SQFdata_modif$ac_rept[which(is.na(SQFdata_modif$ac_rept))]   <- 'N'
SQFdata_modif$ac_inves[which(is.na(SQFdata_modif$ac_inves))] <- 'N'
SQFdata_modif$ac_proxm[which(is.na(SQFdata_modif$ac_proxm))] <- 'N'
SQFdata_modif$ac_incid[which(is.na(SQFdata_modif$ac_incid))] <- 'N'
SQFdata_modif$ac_time[which(is.na(SQFdata_modif$ac_time))]   <- 'N'
SQFdata_modif$ac_evasv[which(is.na(SQFdata_modif$ac_evasv))] <- 'N'
SQFdata_modif$ac_assoc[which(is.na(SQFdata_modif$ac_assoc))] <- 'N'
SQFdata_modif$ac_cgdir[which(is.na(SQFdata_modif$ac_cgdir))] <- 'N'
SQFdata_modif$ac_stsnd[which(is.na(SQFdata_modif$ac_stsnd))] <- 'N'
SQFdata_modif$ac_other[which(is.na(SQFdata_modif$ac_other))] <- 'N'

# REASON FOR FRISK
summary(SQFdata_modif$rf_vcrim);summary(SQFdata_modif$rf_othsw);summary(SQFdata_modif$rf_attir);
summary(SQFdata_modif$rf_vcact);summary(SQFdata_modif$rf_rfcmp);summary(SQFdata_modif$rf_verbl);
summary(SQFdata_modif$rf_knowl);summary(SQFdata_modif$rf_furt);summary(SQFdata_modif$rf_bulg);

SQFdata_modif %>% filter(is.na(cs_objcs)) %>%
    summarise(count_rf_vcrim  = sum(rf_vcrim == "Y", na.rm = TRUE),
            count_rf_othsw  = sum(rf_othsw == "Y", na.rm = TRUE),
            count_rf_attir  = sum(rf_attir == "Y", na.rm = TRUE),
            count_rf_vcact  = sum(rf_vcact == "Y", na.rm = TRUE),
            count_rf_rfcmp  = sum(rf_rfcmp == "Y", na.rm = TRUE),
            count_rf_furt  = sum(rf_furt == "Y", na.rm = TRUE),
            count_rf_bulg  = sum(rf_bulg == "Y", na.rm = TRUE),
            count_rf_verbl  = sum(rf_verbl == "Y", na.rm = TRUE),
            count_rf_knowl = sum(rf_knowl == "Y", na.rm = TRUE),
            tot = n()) %>%
    mutate(percent_rf_vcrim = 100*count_rf_vcrim/tot,
           percent_rf_othsw = 100*count_rf_othsw/tot,
           percent_rf_attir = 100*count_rf_attir/tot,
           percent_rf_vcact = 100*count_rf_vcact/tot,
           percent_rf_rfcmp = 100*count_rf_rfcmp/tot,
           percent_rf_furt = 100*count_rf_furt/tot,
           percent_rf_bulg = 100*count_rf_bulg/tot,
           percent_rf_verbl = 100*count_rf_verbl/tot,
           percent_rf_knowl = 100*count_rf_knowl/tot)

SQFdata_modif$rf_vcrim[which(is.na(SQFdata_modif$rf_vcrim))] <- 'N'
SQFdata_modif$rf_othsw[which(is.na(SQFdata_modif$rf_othsw))] <- 'N'
SQFdata_modif$rf_attir[which(is.na(SQFdata_modif$rf_attir))] <- 'N'
SQFdata_modif$rf_vcact[which(is.na(SQFdata_modif$rf_vcact))] <- 'N'
SQFdata_modif$rf_rfcmp[which(is.na(SQFdata_modif$rf_rfcmp))] <- 'N'
SQFdata_modif$rf_furt[which(is.na(SQFdata_modif$rf_furt))]   <- 'N'
SQFdata_modif$rf_bulg[which(is.na(SQFdata_modif$rf_bulg))]   <- 'N'
SQFdata_modif$rf_verbl[which(is.na(SQFdata_modif$rf_verbl))] <- 'N'
SQFdata_modif$rf_knowl[which(is.na(SQFdata_modif$rf_knowl))] <- 'N'

# REASON FOR STOP
summary(SQFdata_modif$cs_objcs);summary(SQFdata_modif$cs_descr);summary(SQFdata_modif$cs_casng);
summary(SQFdata_modif$cs_lkout);summary(SQFdata_modif$cs_cloth);summary(SQFdata_modif$cs_drgtr);
summary(SQFdata_modif$cs_furtv);summary(SQFdata_modif$cs_vcrim);summary(SQFdata_modif$cs_bulge);
summary(SQFdata_modif$cs_other);

SQFdata_modif %>% filter(is.na(cs_objcs)) %>%
    summarise(count_cs_descr = sum(cs_descr == "Y", na.rm = TRUE),
              count_cs_casng = sum(cs_casng == "Y", na.rm = TRUE),
              count_cs_lkout = sum(cs_lkout == "Y", na.rm = TRUE),
              count_cs_cloth = sum(cs_cloth == "Y", na.rm = TRUE),
              count_cs_drgtr = sum(cs_drgtr == "Y", na.rm = TRUE),
              count_cs_furtv = sum(cs_furtv == "Y", na.rm = TRUE),
              count_cs_vcrim = sum(cs_vcrim == "Y", na.rm = TRUE),
              count_cs_bulge = sum(cs_bulge == "Y", na.rm = TRUE),
              count_cs_other = sum(cs_other == "Y", na.rm = TRUE),
              tot = n()) %>%
    mutate(percent_cs_descr = 100*count_cs_descr/tot,
           percent_cs_casng = 100*count_cs_casng/tot,
           percent_cs_lkout = 100*count_cs_lkout/tot,
           percent_cs_cloth = 100*count_cs_cloth/tot,
           percent_cs_drgtr = 100*count_cs_drgtr/tot,
           percent_cs_furtv = 100*count_cs_furtv/tot,
           percent_cs_vcrim = 100*count_cs_vcrim/tot,
           percent_cs_bulge = 100*count_cs_bulge/tot,
           percent_cs_other = 100*count_cs_other/tot)

SQFdata_modif$cs_objcs[which(is.na(SQFdata_modif$cs_objcs))] <- 'N'
SQFdata_modif$cs_descr[which(is.na(SQFdata_modif$cs_descr))] <- 'N'
SQFdata_modif$cs_casng[which(is.na(SQFdata_modif$cs_casng))] <- 'N'
SQFdata_modif$cs_lkout[which(is.na(SQFdata_modif$cs_lkout))] <- 'N'
SQFdata_modif$cs_cloth[which(is.na(SQFdata_modif$cs_cloth))] <- 'N'
SQFdata_modif$cs_drgtr[which(is.na(SQFdata_modif$cs_drgtr))] <- 'N'
SQFdata_modif$cs_furtv[which(is.na(SQFdata_modif$cs_furtv))] <- 'N'
SQFdata_modif$cs_vcrim[which(is.na(SQFdata_modif$cs_vcrim))] <- 'N'
SQFdata_modif$cs_bulge[which(is.na(SQFdata_modif$cs_bulge))] <- 'N'
SQFdata_modif$cs_other[which(is.na(SQFdata_modif$cs_other))] <- 'N'

# BASIS OF SEARCH
summary(SQFdata_modif$sb_hdobj);summary(SQFdata_modif$sb_outln);summary(SQFdata_modif$sb_admis);
summary(SQFdata_modif$sb_other);

SQFdata_modif %>% filter(is.na(sb_hdobj)) %>%
    summarise(count_outln = sum(sb_outln == "Y", na.rm = TRUE),
              count_admis = sum(sb_admis == "Y", na.rm = TRUE),
              count_other = sum(sb_other == "Y", na.rm = TRUE),
              tot = n()) %>%
    mutate(percent_outln = 100*count_outln/tot,
           percent_admis = 100*count_admis/tot,
           percent_other = 100*count_other/tot)

SQFdata_modif$sb_hdobj[which(is.na(SQFdata_modif$sb_hdobj))] <- 'N'
SQFdata_modif$sb_outln[which(is.na(SQFdata_modif$sb_outln))] <- 'N'
SQFdata_modif$sb_admis[which(is.na(SQFdata_modif$sb_admis))] <- 'N'
SQFdata_modif$sb_other[which(is.na(SQFdata_modif$sb_other))] <- 'N'


# AÑADIR EXPLICACIÓN CON PAQUETE MissingDataGUI?

# Comprobación de NAs
sum(is.na(SQFdata))
sum(is.na(SQFdata_modif))
```

## Eliminación de variables con varianza nula

```{r}
# Con nearZeroVar se eliminan más variables
SQFdata_modif <- SQFdata_modif[-nearZeroVar(SQFdata_modif)]

dim(SQFdata)
dim(SQFdata_modif)
```

## División de muestra en train/test

```{r}
# Creación de conjuntos train y test
tot_obs <- dim(SQFdata_modif)[1]
indices <- 1:tot_obs

set.seed(1234)
indices_train <- sample(indices, 0.7*tot_obs)
SQFdataTrain <- SQFdata_modif[indices_train, ]
SQFdataTest <- SQFdata_modif[-indices_train, ]

# Datos desbalanceados
SQFdataTrain %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### Ajuste del desbalanceo: Down-sampling

- Down-Sampling:

```{r}
# Total de casos -> 4799 (si) + 27103 (no) = 31902
# Queremos que los SI correspondan a un 50% de la muestra -> Los NO deberían ser 4847 casos
training.yes <- SQFdataTrain %>% filter(arstmade == 'Y')
training.no <- SQFdataTrain %>% filter(arstmade == 'N')

set.seed(4567)
ind_training.no <- sample(rownames(training.no),4799)
training.no <- training.no[ind_training.no,]

SQFdataTrain_DSAMP <- rbind(training.yes, training.no)

SQFdataTrain_DSAMP %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

## Regresión logística: arstmade
Para encontrar los determinantes de que una persona parada sea arrestada o no, utilizamos los modelos lineales generalizados, y dado que la variable respuesta, toma valores N (no fueron arrestados) o Y (sí fueron arrestados), utilizamos la función de enlace logit. Este modelo es de la familia binomial 
Hipótesis
1.	Los casos son independientes entre sí.
2.	La probabilidad de éxito es la misma para todos los casos que tienen los mismos valores de los regresores.


### Creación de modelos vacío y completo

```{r}
# CREACION DE MODELO VACIO
#==========================================================================================
model_glm_DSAMP_Vacio <- glm(arstmade ~ 1, data = SQFdataTrain_DSAMP, family = "binomial")
#==========================================================================================

# CREACION DE MODELO COMPLETO
#==========================================================================================
model_glm_DSAMP<- glm(arstmade ~ ., data = SQFdataTrain_DSAMP, family = "binomial")

summary(model_glm_DSAMP)
#==========================================================================================

```

### Selección de modelos mediante stepwise

```{r}
# STEPWISE MODELO DOWN-SAMPLING
#==========================================================================================
model_glm_DSAMP_Forw <- step(model_glm_DSAMP_Vacio,
                       scope = list(lower = formula(model_glm_DSAMP_Vacio), upper = formula(model_glm_DSAMP)),
                       direction = "forward", trace = 0)
summary(model_glm_DSAMP_Forw)
#==========================================================================================
```


### Selección del modelo

### Prueba Likelihood ratio
Dado que la hipótesis nula sostiene que el modelo reducido es el mejor, un valor del p-value para el modelo estadístico mayor que 0,05 nos obliga a aceptar la hipótesis nula, es decir, proporciona evidencia a favor del modelo reducido. Además se puede verificar, según el criterio AIC, el modelo balanceado y construido en base a stepwise es el mejor. 

```{r, warming = FALSE, message=FALSE}

anova(model_glm_DSAMP, model_glm_DSAMP_Forw,  test="Chisq")
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic)

```

### Evaluación de los parámetros del modelo seleccionado
Como la respuesta es binaria, la función de salida es la probabilidad condicionada de que la respuesta sea un acierto dado los valores de los predictores. Los betas estimados son los log- odds, donde la probabilidad (odds) de que el suceso ocurra se da como la probabilidad de acierto dividido por la probabilidad de fallo.
En cuanto a la interpretación de los parámetros estimados del modelo *model_glm_DSAMP_Forw*, el signo de los mismos indica que ese predictor aumenta o disminuye la probabilidad de que una persona sea arrestada y para evaluar la magnitud de la variación se calculó el exponencial de cada beta. Así se puede determinar por ejemplo: si aumenta  una unidad en la edad, la probabilidad de ser arrestado  se incrementa en un factor de 1,01

```{r}
round(exp(cbind(Estimate=coef(model_glm_DSAMP_Forw),
                confint(model_glm_DSAMP_Forw))), 2)
```

### Pseudo R^2
Evaluamos el R cuadrado de McFadden mientras más cercano a uno indica que el modelo tiene poder predictivo, es este caso el valor es de 0.587.
```{r, warming = FALSE}
library(pscl)
pR2(model_glm_DSAMP_Forw)

```

### Importancia de la variable
Si bien el método stepwise selecciona el modelo por criterio AIC, es necesario verificar si al eliminar una variable que no es significativa afecta mucho al modelo, en este caso se valora la opción de eliminar la variable *haircolr*, dado que según el estadístico de Wald a un nivel de significancia de *0.05*, está en el umbral de no rechazar la hipótesis nula de que el coeficiente de una variable independiente en el modelo no es significativamente diferente de cero. Se evalúa un nuevo modelo eliminando esta variable y a priori observando el criterio AIC, no causa un gran efecto en el modelo. Esto se comprueba al analizar tabla *anova* en la que se demuestra que no hay suficiente evidencia para rechazar Ho. 

El análisis se repite para la variable *race*, dado que es un factor, a priori, relacionado con la controversia que ampara esta ley. Después de evaluar los estadísticos vemos que hay suficiente evidencia para considerar importante la variable dentro del modelo.

```{r, warming = FALSE}
#varImp(model_glm_DSAMP_Forw)
library(survey)

## Eliminar haircolr
regTermTest(model_glm_DSAMP_Forw, "haircolr")
model_glm_DSAMP_hair<- glm(arstmade ~ .-haircolr, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_DSAMP_hair_back<-step(model_glm_DSAMP_hair, direction = "backward", trace = 0)
#summary(model_glm_DSAMP_hair_back)
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic, model_glm_DSAMP_hair_back$aic)
anova(model_glm_DSAMP_hair_back, model_glm_DSAMP_Forw,  test="Chisq")

# Eliminar race
regTermTest(model_glm_DSAMP_Forw, "race")
model_glm_DSAMP_race<- glm(arstmade ~ .-race, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_DSAMP_race_back<-step(model_glm_DSAMP_race, direction = "backward", trace = 0)
#summary(model_glm_DSAMP_race_back)
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic, model_glm_DSAMP_hair_back$aic, model_glm_DSAMP_race_back$aic)
anova(model_glm_DSAMP_race_back, model_glm_DSAMP_Forw,  test="Chisq")
```

### Validación cruzada
Dado que nuestro objetivo es construir un modelo de predicción, la métrica más importante es determinar lo bien que el modelo predice para observaciones diferentes a las de prueba. Se construye una tabla de clasificación donde se cruza el verdadero valor de la observación, con la predicción de la misma según el modelo seleccionado, tomando como referencia una preddicción mayor a 0.5. Como resultado se obtiene que el modelo predijo con exactitud 1671 personas paradas que fueron arrestadas, de un total de 2091 lo que representa un **sensitivity** de 0.7991, en cuanto a la predicción de los que no fueron arrestados **specificity** corresponde a un acierto de 0.8607


```{r}
# FUNCION DE EVALUACION Y CREACION DE TABLA DE RESULTADOS
#==========================================================================================
pred_DSAMP_hair_back <- factor(predict(model_glm_DSAMP_hair_back, SQFdataTest, type="response")>0.5,
                          levels=c(FALSE, TRUE),
                          labels=c("N","Y"))

cM_DSAMP_hair_back <- confusionMatrix(pred_DSAMP_hair_back, SQFdataTest$arstmade, positive="Y")

eval_DSAMP_hair_back_metrics <- c(model_glm_DSAMP_hair_back$aic,
                   model_glm_DSAMP_hair_back$null.deviance,
                   model_glm_DSAMP_hair_back$deviance,
                   length(model_glm_DSAMP_hair_back$model)-1)

eval_DSAMP_hair_back <- c(cM_DSAMP_hair_back$byClass[7],
                   cM_DSAMP_hair_back$byClass[5:6],
                   cM_DSAMP_hair_back$byClass[2])
#==========================================================================================
```

#### Curva ROC
La curva ROC es un gráfico que muestra la relación entre los datos que se predicen correctamente con la tasa de los datos negativos que se consideran erróneamente como positivos. Esta métrica ofrece un mejor resumen de la capacidad predictiva que una tabla de clasificación, porque presenta la potencia predictiva para todos los posibles valores sin establecer una referencia arbitraria, permitiendo así evaluar el rendimiento del clasificador. El área bajo la curva ROC para los datos de testeo es de 0.8977 lo que indica que el modelo discrimina adecuadamente a los arrestados y no arrestados.
```{r, warming = FALSE, message=FALSE}
library(ROCR)

prob_test <- predict(model_glm_DSAMP_hair_back, SQFdataTest, type="response")
pr_test <- prediction(prob_test, SQFdataTest$arstmade)
pred_tpr_fpr <- performance(pr_test, measure = "tpr", x.measure = "fpr")
plot(pred_tpr_fpr, main = "ROC curve", col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)

auc_test <- performance(pr_test, measure = "auc")
auc_test <- auc_test@y.values[[1]]
auc_test
```


# Conclusiones

En los modelos estadísticos analizados, en principio se determina que la variable "race" que corresponde a la raza de las personas paradas  resulta significativa en la probabilidad de que sean arrestados, sin embargo, resultaría interesante verificar si efectivamente este es un factor determinante para que una persona sea parada o no, es decir, verificar la hipótesis de que esta ley es un "política de discriminación racial indirecta".  

Según las estadísticas presentadas por el Departamento de Policía (NYPD), en el año 2016,  Nueva York ha experimentado una reducción en todas las categorías de delitos. Además, de la reducción de uso de la técnica de "Stop and Frisk". Ante estos resultados, resulta interesante conocer el impacto que tiene esta ley en las estadísticas de delincuencia.



