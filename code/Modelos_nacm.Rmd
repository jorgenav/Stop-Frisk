---
title: "Modelos"
author: "Nathaly"
date: "15 de abril de 2017"
output: html_document
---
```{r, warning = FALSE, message=FALSE}
# Carga del Dataset
if(!exists("foo", mode="function")) source("Cleaning_Data.R")

if (!"ggplot2" %in% installed.packages()){
        install.packages("ggplot2")
}
if (!"caret" %in% installed.packages()){
        install.packages("caret")
}
if (!"lmtest" %in% installed.packages()){
        install.packages("lmtest")
}
if (!"pscl" %in% installed.packages()){
        install.packages("pscl")
}
if (!"dplyr" %in% installed.packages()){
        install.packages("dplyr")
}
if (!"pROC" %in% installed.packages()){
        install.packages("pROC")
}
library(ggplot2)
library(caret)
library(lmtest)
library(pscl)
library(dplyr)
library(pROC)
```



## Datos de entrenamiento: Selección de variables

```{r}
copia <- SQFdata
data <- dplyr::select(copia,
                  arstmade,
                inout,  
                trhsloc,
                perobs,
                crimsusp,
                perstop,
                typeofid,
                explnstp,
                othpers,
                arstoffn,
                sumissue,
                sumoffen,
                offunif,
                frisked,
                searched,
                contrabn,
                adtlrept, 
                pistol,
                #riflshot, no avanza el modelo logit pocos "Y"
                #asltweap, no avanza el modelo logit pocos "Y"
                knifcuti,
                machgun,
                #othrweap, no avanza el modelo logit pocos "Y"
                radio,
                forceuse,
                sex,
                race,
                age,
                ht_feet,
                ht_inch,
                weight,
                haircolr,
                #eyecolor, TENGO que reducir las clases
                build,
                othfeatr,
                city
                  )
```

## Limpieza de los datos

```{r, warming = FALSE}
#corregir en Cleaning_Data, lo mismo para las variables offshld offverb forceuse
#SQFdata$officrid[which(SQFdata$officrid == " ")] <- NA
#SQFdata$officrid <- factor(SQFdata$officrid, levels = c("I"), labels=c('Id'))
#

data$arstoffn <- as.character(data$arstoffn)
data$arstoffn[is.na(data$arstoff)] <- "NoArrestado"
data$arstoffn <- as.factor(data$arstoffn)

data$forceuse <- as.character(data$forceuse)
data$forceuse[is.na(data$forceuse)] <- "NoFuerza"
data$forceuse <- as.factor(data$forceuse)

data$adtlrept <- as.character(data$adtlrept)
data$adtlrept[is.na(data$adtlrept)] <- "Y"
data$adtlrept <- as.factor(data$adtlrept)


```


# Eliminar variables con más del 50% de NA's
```{r, warming = FALSE}

miss_value<-which(colSums(is.na(data))>nrow(data) * 0.5)
miss_value
data <- data[ , -miss_value]

```

# Eliminar factores con menos de dos categorías o con más de 20 categorías
```{r, warming = FALSE}
fun_v2 <- function( x ){
    ifelse(is.factor( x ),return(length(levels( x ))),return(2))
}

data <- data[,-c(which(sapply(data, fun_v2) < 2 | sapply(data, fun_v2) > 20))]

```

# Eliminar casos con NA's
```{r, warming = FALSE}

x <- na.omit(data)

```
Después de la limpieza de datos nos quedamos con el 76%.

## Datos de test: Selección de variables

```{r, warming = FALSE}
# Carga del Dataset
if(!exists("foo", mode="function")) source("Cleaning_Data_Test.R")
y <- na.omit(data_2015)

```


## MODELO LOGÍSTICO 

# Selección de variables: Stepwise

# Modelo completo y vacío
```{r, warming = FALSE}

modelo_completo<- glm(arstmade~., family = binomial(link=logit), data = x)
modelo_vacio<- glm(arstmade ~1, family = binomial(link=logit), data = x)

```

# Step: Backward
```{r, warming = FALSE}
modelo_back <-step(modelo_completo, trace = 0)
summary(modelo_back)
#round(exp(cbind(Estimate=coef(modelo_back), confint(modelo_back))), 2) 

```

### Step: Forward
```{r, warming = FALSE}
modelo_for <-step(modelo_vacio, scope = list(lower=formula(modelo_vacio), upper = formula(modelo_completo)),direction="forward", trace = 0)
summary(modelo_for)

```

### Step: Dos direcciones
```{r, warming = FALSE}
modelo_both <-step(modelo_vacio, scope = list(lower=formula(modelo_vacio), upper = formula(modelo_completo)),direction="both", trace = 0)
summary(modelo_both)

```

# Predicción de valores del modelo
```{r, warming = FALSE}
# probabilidades en escala de la salida
head(fitted(modelo_back)) 
```

## Selección de variables por remuestro 
```{r, warming = FALSE, message=FALSE}
model_train<- train(arstmade~., method="glm",family = binomial(link=logit), data = x)
summary(model_train)
```
## Evaluación de modelos


# Prueba Likelihood ratio
Dado que la hipótesis nula sostiene que el modelo reducido es el mejor, un valor del p-value para el modelo estadístico mayor que 0,05 nos obliga a aceptar la hipótesis nula, es decir proporciona evidencia a favor del modelo reducido.

```{r, warming = FALSE, message=FALSE}

anova(modelo_completo, modelo_both,  test="Chisq")
lrtest(modelo_completo, modelo_both)

```

# Pseudo R^2
Evaluamos el R cuadrado de McFadden mientras más cercano a uno indica que el modelo tiene poder predictivo.
```{r, warming = FALSE}
pR2(modelo_both)

```

## Pruebas estadísticas para predictores individuales

# Importancia de la variable

```{r, warming = FALSE}
varImp(modelo_both)
        
```
## Validación de los valores predichos

# Tasa de clasificación: Datos de entrenamiento
```{r, warming = FALSE}
predic <- predict(modelo_both, newdata= x, type="response")
table(x$arstmade, predic>0.5)
zz <- cut(predic, c(-0.25, 0.4, 0.5, 0.55, 0.7, 1))
prediccionTrain = revalue(zz, c(`(-0.25,0.4]` = "BAJO", `(0.4,0.5]` = "MEDIO-BAJO",
`(0.5,0.55]` = "MEDIO", `(0.55,0.7]` = "MEDIO-ALTO", `(0.7,1]` = "ALTO"))
a<- table(x$arstmade, prediccionTrain)
a

round(a[2, ]/(a[1, ] + a[2, ]), 2)

 
```

## Tasa de clasificación: Datos de prueba

```{r, warming = FALSE}

predic_test <- predict(modelo_both, newdata= y, type="response")
table(y$arstmade, predic_test > 0.5)
zz_test <- cut(predic_test, c(-0.25, 0.4, 0.5, 0.55, 0.7, 1))
prediccion_test <- revalue(zz_test, c(`(-0.25,0.4]` = "BAJO", `(0.4,0.5]` = "MEDIO-BAJO",
`(0.5,0.55]` = "MEDIO", `(0.55,0.7]` = "MEDIO-ALTO", `(0.7,1]` = "ALTO"))
a_test<- table(y$arstmade, prediccion_test)
a_test

round(a_test[2, ]/(a_test[1, ] + a_test[2, ]), 2)

 
```

## Curva ROC: Datos de entranamiento
La curva ROC es un gráfico que muestra la relación entre los datos que se predicen correctamente con la tasa de los datos negativos que se consideran erróneamente como positivos. Esta medida permite evaluar el rendimiento del clasificador. Se evalúa el área bajo la curva, en este caso es de 0.897 lo que indica que el modelo discrimina adecuadamente a los arrestados y no arrestados.
```{r, warming = FALSE}

prob <- predict(modelo_both, type = c("response"))
g <- roc(arstmade ~ prob, data = x)
plot(g)

pr <- prediction(prob, x$arstmade)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
#acc <- performance(pr, measure = "acc")
#plot(acc) 
```

## Curva ROC: Datos de prueba
La curva ROC para los datos de testeo es de 0.876 lo que indica que el modelo discrimina adecuadamente a los arrestados y no arrestados.
```{r, warming = FALSE}

prob_test <- predict(modelo_both, newdata=y, type = "response")
g_test <- roc(arstmade ~ prob_test, data = y)
plot(g_test)

pr_test <- prediction(prob_test, y$arstmade)
auc_test <- performance(pr_test, measure = "auc")
auc_test <- auc_test@y.values[[1]]
auc_test
#acc <- performance(pr, measure = "acc")
#plot(acc) 
```




