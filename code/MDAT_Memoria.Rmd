---
title: "MDAT_Memoria"
author: "Nathaly Cárdenas, Iván Artalejo, Hugo Fernández, Jorge Navarro"
date: "3 de mayo de 2017"
output:
  pdf_document: default
  html_document: default
---

```{r, message = FALSE, warning = FALSE}
library(dataQualityR)
library(knitr)
library(grid)
library(gridExtra)
library(pscl)
library(magrittr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(PASWR2)
library(leaflet)
library(proj4)
library(caret)
library(survey)
library(ROCR)
library(class)
library(foreach)
library(doMC)
registerDoMC(4)
library(rpart)
library(randomForest)
library(parallelSVM)
library(e1071)
library(nnet)
library(pROC)
library(doParallel)
library(cluster)
library(useful)

```

# 1. DESCRIPCIÓN DEL PROBLEMA

El programa ***[Stop and frisk](https://en.wikipedia.org/wiki/Stop-and-frisk_in_New_York_City)*** de la ciudad de Nueva York consiste en la práctica de detenciones temporales, interrogatorios e incluso cacheos a ciudadanos en busca de armas o cualquier tipo de contrabando. Los motivos en los cuales la policía puede ampararse para llevar a cabo estas prácticas se encuentran dentro de la ley criminal estadounidense.

La mayoría de detenciones producidas se centran en la población afroamericana y latina de la ciudad de edades comprendidas entre los 15 y los 25 años, lo cual ha generado gran controversia en torno a dicha ley. También contribuye al rechazo generado por la ley determinados **[estudios](https://www.washingtonpost.com/politics/2016/live-updates/general-election/real-time-fact-checking-and-analysis-of-the-first-presidential-debate/fact-check-trump-on-crime-statistics-and-stop-and-frisk/?utm_term=.52808601905f)** que demuestran que no existe relación entre el número de detenidos y la tasa de criminalidad de la ciudad. 

El departamento de policía de NY facilita de forma periódica **[datos](https://www.nyclu.org/en/stop-and-frisk-data)** sobre las detenciones realizadas en la ciudad. 9 de cada 10 personas detenidas son inocentes y aunque el número de detenciones se ha visto reducido considerablemente, pasando en 2011 de 685,724 detenciones a 22,939 en 2015, las proporciones según la etnia de las personas detenidas se han mantenido constantes.

Se generan distintos modelos a lo largo del trabajo para poder determinar la necesidad o no de arrestar a las personas detenidas.

# 2. DESCRIPCIÓN DE LOS DATOS

Se expone a continuación una breve descripción sobre las variables incluidas en el dataset y un análisis de la calidad de las observaciones.

## 2.1 Diccionario de datos

```{r, message=FALSE, warning=FALSE}
if(!file.exists("../data/data_dictionary.csv"))
    download.file(paste("https://raw.githubusercontent.com/jorgenav/Stop-Frisk/",
                  "master/data/data_dictionary.csv", sep = ""),
                  "../data/data_dictionary.csv")
SQFdataDictionary <- read.csv("../data/data_dictionary.csv")

kable(SQFdataDictionary, caption="NYPD Stop Question Frisk Database 2014")
```

## 2.2 Data Quality Report

```{r, message=FALSE, warning=FALSE}
# Carga de datos del proyecto
if(!file.exists("../data/2014.csv")) {
  download.file("http://www.nyc.gov/html/nypd/downloads/zip/analysis_and_planning/2014_sqf_csv.zip",
                "../data/2014_sqf_csv.zip")
  unzip("../data/2014_sqf_csv.zip", exdir = "../data/")
}

SQFdata <- read.csv("../data/2014.csv")

drq.num <- paste("./dqr_num.csv", sep = "")
drq.cat <- paste("./dqr_cat.csv", sep = "")
checkDataQuality(SQFdata, out.file.num = drq.num,  out.file.cat = drq.cat)
DQR.num <- read.csv("dqr_num.csv")
DQR.cat <- read.csv("dqr_cat.csv")
```

### 2.2.a Variables numéricas

```{r, message=FALSE, warning=FALSE}
grid.table(DQR.num,
           theme = ttheme_default(base_size = 5, padding = unit(c(1, 1), "mm")))
```

### 2.2.b Variables categóricas

```{r, message=FALSE, warning=FALSE}
grid.table(DQR.cat[1:45,1:15],
           theme = ttheme_default(base_size = 5, padding = unit(c(1, 1), "mm")))
```

```{r}
grid.table(DQR.cat[46:86,1:15],
           theme = ttheme_default(base_size = 5, padding = unit(c(1, 1), "mm")))
```

\newpage

# 3. PREPARACIÓN DE LOS DATOS

## 3.1 Depuración de los datos

### 3.1.1 Tratamiento fechas y horas

```{r, message=FALSE, warning=FALSE}
# Variable datestop
SQFdata$datestop <- mdy(SQFdata$datestop)  #Convert Strings to Dates

# Variable timestop
myfunc_time <- function(x){
    if(nchar(x)==3){x <- paste('0', as.character(x),sep='')}
    if(nchar(x)==2){x <- paste('0', '0', as.character(x),sep='')}
    if(nchar(x)==1){x <- paste('0', '0', '0', as.character(x),sep='')}
    return(as.character(strptime(x, format ='%H%M'),format='%H:%M'))
  }
SQFdata$timestop <- sapply(SQFdata$timestop,myfunc_time)
SQFdata$timestop <- hm(SQFdata$timestop)  #Convert Strings to Times

# Variable dob
SQFdata$dob <- mdy(SQFdata$dob)  #Convert to Dates
```

### 3.1.2 Unificación valores

```{r, message=FALSE, warning=FALSE}
# Corrección perstop
SQFdata$perstop = as.integer(SQFdata$perstop)

# Corregir NAs y unificar valores en pistol
SQFdata$pistol[which(SQFdata$pistol == " ")] <- NA
SQFdata$pistol[which(SQFdata$pistol == "1")] <- "Y"
SQFdata$pistol <- factor(SQFdata$pistol, levels = c('Y','N'))

# Corregir NAs y unificar valores en riflshot
SQFdata$riflshot[which(SQFdata$riflshot == " ")] <- NA
SQFdata$riflshot[which(SQFdata$riflshot == "1")] <- "Y"
SQFdata$riflshot <- factor(SQFdata$riflshot, levels = c('Y','N'))

# Corregir NAs y unificar valores en asltweap
SQFdata$asltweap[which(SQFdata$asltweap == " ")] <- NA
SQFdata$asltweap[which(SQFdata$asltweap == "1")] <- "Y"
SQFdata$asltweap <- factor(SQFdata$asltweap, levels = c('Y','N'))

# Corregir NAs y unificar valores en knifcuti
SQFdata$knifcuti[which(SQFdata$knifcuti == " ")] <- NA
SQFdata$knifcuti[which(SQFdata$knifcuti == "1")] <- "Y"
SQFdata$knifcuti <- factor(SQFdata$knifcuti, levels = c('Y','N'))

# Corregir NAs y unificar valores en machgun
SQFdata$machgun[which(SQFdata$machgun == " ")] <- NA
SQFdata$machgun <- factor(SQFdata$machgun, levels = c('N'))

# Corregir NAs y unificar valores en othrweap
SQFdata$othrweap[which(SQFdata$othrweap == " ")] <- NA
SQFdata$othrweap[which(SQFdata$othrweap == "1")] <- "Y"
SQFdata$othrweap <- factor(SQFdata$othrweap, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_hands
SQFdata$pf_hands[which(SQFdata$pf_hands == " ")] <- NA
SQFdata$pf_hands[which(SQFdata$pf_hands == "1")] <- "Y"
SQFdata$pf_hands <- factor(SQFdata$pf_hands, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_wall
SQFdata$pf_wall[which(SQFdata$pf_wall == " ")] <- NA
SQFdata$pf_wall[which(SQFdata$pf_wall == "1")] <- "Y"
SQFdata$pf_wall <- factor(SQFdata$pf_wall, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_grnd
SQFdata$pf_grnd[which(SQFdata$pf_grnd == " ")] <- NA
SQFdata$pf_grnd[which(SQFdata$pf_grnd == "1")] <- "Y"
SQFdata$pf_grnd <- factor(SQFdata$pf_grnd, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_drwep
SQFdata$pf_drwep[which(SQFdata$pf_drwep == " ")] <- NA
SQFdata$pf_drwep[which(SQFdata$pf_drwep == "1")] <- "Y"
SQFdata$pf_drwep <- factor(SQFdata$pf_drwep, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_ptwep
SQFdata$pf_ptwep[which(SQFdata$pf_ptwep == " ")] <- NA
SQFdata$pf_ptwep[which(SQFdata$pf_ptwep == "1")] <- "Y"
SQFdata$pf_ptwep <- factor(SQFdata$pf_ptwep, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_baton
SQFdata$pf_baton[which(SQFdata$pf_baton == " ")] <- NA
SQFdata$pf_baton[which(SQFdata$pf_baton == "1")] <- "Y"
SQFdata$pf_baton <- factor(SQFdata$pf_baton, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_hcuff
SQFdata$pf_hcuff[which(SQFdata$pf_hcuff == " ")] <- NA
SQFdata$pf_hcuff[which(SQFdata$pf_hcuff == "1")] <- "Y"
SQFdata$pf_hcuff <- factor(SQFdata$pf_hcuff, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_pepsp
SQFdata$pf_pepsp[which(SQFdata$pf_pepsp == " ")] <- NA
SQFdata$pf_pepsp[which(SQFdata$pf_pepsp == "1")] <- "Y"
SQFdata$pf_pepsp <- factor(SQFdata$pf_pepsp, levels = c('Y','N'))

# Corregir NAs y unificar valores en pf_other
SQFdata$pf_other[which(SQFdata$pf_other == " ")] <- NA
SQFdata$pf_other[which(SQFdata$pf_other == "1")] <- "Y"
SQFdata$pf_other <- factor(SQFdata$pf_other, levels = c('Y','N'))

# Corregir NAs y unificar valores en radio
SQFdata$radio[which(SQFdata$radio == "0")] <- "N"
SQFdata$radio[which(SQFdata$radio == "1")] <- "Y"
SQFdata$radio <- factor(SQFdata$radio, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_rept
SQFdata$ac_rept[which(SQFdata$ac_rept == " ")] <- NA
SQFdata$ac_rept[which(SQFdata$ac_rept == "1")] <- "Y"
SQFdata$ac_rept <- factor(SQFdata$ac_rept, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_inves
SQFdata$ac_inves[which(SQFdata$ac_inves == " ")] <- NA
SQFdata$ac_inves[which(SQFdata$ac_inves == "1")] <- "Y"
SQFdata$ac_inves <- factor(SQFdata$ac_inves, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_vcrim
SQFdata$rf_vcrim[which(SQFdata$rf_vcrim == " ")] <- NA
SQFdata$rf_vcrim[which(SQFdata$rf_vcrim == "1")] <- "Y"
SQFdata$rf_vcrim <- factor(SQFdata$rf_vcrim, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_othsw
SQFdata$rf_othsw[which(SQFdata$rf_othsw == " ")] <- NA
SQFdata$rf_othsw[which(SQFdata$rf_othsw == "1")] <- "Y"
SQFdata$rf_othsw <- factor(SQFdata$rf_othsw, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_proxm
SQFdata$ac_proxm[which(SQFdata$ac_proxm == " ")] <- NA
SQFdata$ac_proxm[which(SQFdata$ac_proxm == "1")] <- "Y"
SQFdata$ac_proxm <- factor(SQFdata$ac_proxm, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_attir
SQFdata$rf_attir[which(SQFdata$rf_attir == " ")] <- NA
SQFdata$rf_attir[which(SQFdata$rf_attir == "1")] <- "Y"
SQFdata$rf_attir <- factor(SQFdata$rf_attir, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_objcs
SQFdata$cs_objcs[which(SQFdata$cs_objcs == " ")] <- NA
SQFdata$cs_objcs[which(SQFdata$cs_objcs == "1")] <- "Y"
SQFdata$cs_objcs <- factor(SQFdata$cs_objcs, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_descr
SQFdata$cs_descr[which(SQFdata$cs_descr == " ")] <- NA
SQFdata$cs_descr[which(SQFdata$cs_descr == "1")] <- "Y"
SQFdata$cs_descr <- factor(SQFdata$cs_descr, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_casng
SQFdata$cs_casng[which(SQFdata$cs_casng == " ")] <- NA
SQFdata$cs_casng[which(SQFdata$cs_casng == "1")] <- "Y"
SQFdata$cs_casng <- factor(SQFdata$cs_casng, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_lkout
SQFdata$cs_lkout[which(SQFdata$cs_lkout == " ")] <- NA
SQFdata$cs_lkout[which(SQFdata$cs_lkout == "1")] <- "Y"
SQFdata$cs_lkout <- factor(SQFdata$cs_lkout, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_vcact
SQFdata$rf_vcact[which(SQFdata$rf_vcact == " ")] <- NA
SQFdata$rf_vcact[which(SQFdata$rf_vcact == "1")] <- "Y"
SQFdata$rf_vcact <- factor(SQFdata$rf_vcact, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_cloth
SQFdata$cs_cloth[which(SQFdata$cs_cloth == " ")] <- NA
SQFdata$cs_cloth[which(SQFdata$cs_cloth == "1")] <- "Y"
SQFdata$cs_cloth <- factor(SQFdata$cs_cloth, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_drgtr
SQFdata$cs_drgtr[which(SQFdata$cs_drgtr == " ")] <- NA
SQFdata$cs_drgtr[which(SQFdata$cs_drgtr == "1")] <- "Y"
SQFdata$cs_drgtr <- factor(SQFdata$cs_drgtr, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_evasv
SQFdata$ac_evasv[which(SQFdata$ac_evasv == " ")] <- NA
SQFdata$ac_evasv[which(SQFdata$ac_evasv == "1")] <- "Y"
SQFdata$ac_evasv <- factor(SQFdata$ac_evasv, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_assoc
SQFdata$ac_assoc[which(SQFdata$ac_assoc == " ")] <- NA
SQFdata$ac_assoc[which(SQFdata$ac_assoc == "1")] <- "Y"
SQFdata$ac_assoc <- factor(SQFdata$ac_assoc, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_furtv
SQFdata$cs_furtv[which(SQFdata$cs_furtv == " ")] <- NA
SQFdata$cs_furtv[which(SQFdata$cs_furtv == "1")] <- "Y"
SQFdata$cs_furtv <- factor(SQFdata$cs_furtv, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_rfcmp
SQFdata$rf_rfcmp[which(SQFdata$rf_rfcmp == " ")] <- NA
SQFdata$rf_rfcmp[which(SQFdata$rf_rfcmp == "1")] <- "Y"
SQFdata$rf_rfcmp <- factor(SQFdata$rf_rfcmp, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_cgdir
SQFdata$ac_cgdir[which(SQFdata$ac_cgdir == " ")] <- NA
SQFdata$ac_cgdir[which(SQFdata$ac_cgdir == "1")] <- "Y"
SQFdata$ac_cgdir <- factor(SQFdata$ac_cgdir, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_verbl
SQFdata$rf_verbl[which(SQFdata$rf_verbl == " ")] <- NA
SQFdata$rf_verbl[which(SQFdata$rf_verbl == "1")] <- "Y"
SQFdata$rf_verbl <- factor(SQFdata$rf_verbl, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_vcrim
SQFdata$cs_vcrim[which(SQFdata$cs_vcrim == " ")] <- NA
SQFdata$cs_vcrim[which(SQFdata$cs_vcrim == "1")] <- "Y"
SQFdata$cs_vcrim <- factor(SQFdata$cs_vcrim, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_bulge
SQFdata$cs_bulge[which(SQFdata$cs_bulge == " ")] <- NA
SQFdata$cs_bulge[which(SQFdata$cs_bulge == "1")] <- "Y"
SQFdata$cs_bulge <- factor(SQFdata$cs_bulge, levels = c('Y','N'))

# Corregir NAs y unificar valores en cs_other
SQFdata$cs_other[which(SQFdata$cs_other == " ")] <- NA
SQFdata$cs_other[which(SQFdata$cs_other == "1")] <- "Y"
SQFdata$cs_other <- factor(SQFdata$cs_other, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_incid
SQFdata$ac_incid[which(SQFdata$ac_incid == " ")] <- NA
SQFdata$ac_incid[which(SQFdata$ac_incid == "1")] <- "Y"
SQFdata$ac_incid <- factor(SQFdata$ac_incid, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_time
SQFdata$ac_time[which(SQFdata$ac_time == " ")] <- NA
SQFdata$ac_time[which(SQFdata$ac_time == "1")] <- "Y"
SQFdata$ac_time <- factor(SQFdata$ac_time, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_knowl
SQFdata$rf_knowl[which(SQFdata$rf_knowl == " ")] <- NA
SQFdata$rf_knowl[which(SQFdata$rf_knowl == "1")] <- "Y"
SQFdata$rf_knowl <- factor(SQFdata$rf_knowl, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_stsnd
SQFdata$ac_stsnd[which(SQFdata$ac_stsnd == " ")] <- NA
SQFdata$ac_stsnd[which(SQFdata$ac_stsnd == "1")] <- "Y"
SQFdata$ac_stsnd <- factor(SQFdata$ac_stsnd, levels = c('Y','N'))

# Corregir NAs y unificar valores en ac_other
SQFdata$ac_other[which(SQFdata$ac_other == " ")] <- NA
SQFdata$ac_other[which(SQFdata$ac_other == "1")] <- "Y"
SQFdata$ac_other <- factor(SQFdata$ac_other, levels = c('Y','N'))

# Corregir NAs y unificar valores en sb_hdobj
SQFdata$sb_hdobj[which(SQFdata$sb_hdobj == " ")] <- NA
SQFdata$sb_hdobj[which(SQFdata$sb_hdobj == "1")] <- "Y"
SQFdata$sb_hdobj <- factor(SQFdata$sb_hdobj, levels = c('Y','N'))

# Corregir NAs y unificar valores en sb_outln
SQFdata$sb_outln[which(SQFdata$sb_outln == " ")] <- NA
SQFdata$sb_outln[which(SQFdata$sb_outln == "1")] <- "Y"
SQFdata$sb_outln <- factor(SQFdata$sb_outln, levels = c('Y','N'))

# Corregir NAs y unificar valores en sb_admis
SQFdata$sb_admis[which(SQFdata$sb_admis == " ")] <- NA
SQFdata$sb_admis[which(SQFdata$sb_admis == "1")] <- "Y"
SQFdata$sb_admis <- factor(SQFdata$sb_admis, levels = c('Y','N'))

# Corregir NAs y unificar valores en sb_other
SQFdata$sb_other[which(SQFdata$sb_other == " ")] <- NA
SQFdata$sb_other[which(SQFdata$sb_other == "1")] <- "Y"
SQFdata$sb_other <- factor(SQFdata$sb_other, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_furt
SQFdata$rf_furt[which(SQFdata$rf_furt == " ")] <- NA
SQFdata$rf_furt[which(SQFdata$rf_furt == "1")] <- "Y"
SQFdata$rf_furt <- factor(SQFdata$rf_furt, levels = c('Y','N'))

# Corregir NAs y unificar valores en rf_bulg
SQFdata$rf_bulg[which(SQFdata$rf_bulg == " ")] <- NA
SQFdata$rf_bulg[which(SQFdata$rf_bulg == "1")] <- "Y"
SQFdata$rf_bulg <- factor(SQFdata$rf_bulg, levels = c('Y','N'))

# Corregir NAs y unificar valores en othfeatr
SQFdata$othfeatr[which(SQFdata$othfeatr == " ")] <- NA

# Corregir NAs y unificar valores en addrnum
SQFdata$addrnum[which(SQFdata$addrnum == " ")] <- NA

# Corregir NAs y unificar valores en adtlrept
SQFdata$adtlrept[which(SQFdata$adtlrept == " ")] <- NA

# Corregir NAs y unificar valores en age
SQFdata$age[which(SQFdata$age == "**")] <- NA
SQFdata$age = as.integer(sub("([[:space:]])","",SQFdata$age))
SQFdata$age[which(SQFdata$age < 10 | SQFdata$age > 90)] <- NA

# Corregir NAs y unificar valores en arstoffn
SQFdata$arstoffn[which(SQFdata$arstoffn == " ")] <- NA

# Corregir NAs y unificar valores en crossst
SQFdata$crossst[which(SQFdata$crossst == " ")] <- NA

# Corregir NAs y unificar valores en forceuse
SQFdata$forceuse[which(SQFdata$forceuse == " ")] <- NA
SQFdata$forceuse <- factor(SQFdata$forceuse, levels = c("DO", "DS", "OR", "OT", "SF", "SW"),
                           labels=c('Defense of other', 'Defense of self', 'Overcome resistence',
                                    'Other', 'Suspected flight', 'Suspected weapon'))

# Corregir NAs y unificar valores en officrid
SQFdata$officrid[which(SQFdata$officrid == " ")] <- NA
SQFdata$officrid <- factor(SQFdata$officrid, levels = c("I", "0"), labels=c('Id', 'No'))

# Corregir NAs y unificar valores en offshld
SQFdata$offshld[which(SQFdata$offshld == " ")] <- NA
SQFdata$offshld <- factor(SQFdata$offshld, levels = c("S", "0"), labels=c('Shield', 'No'))

# Corregir NAs y unificar valores en offverb
SQFdata$offverb[which(SQFdata$offverb == " ")] <- NA
SQFdata$offverb <- factor(SQFdata$offverb, levels = c("V", "0"), labels=c('Verbal', 'No'))

# Corregir NAs y unificar valores en othfeatr
SQFdata$othfeatr[which(SQFdata$othfeatr == " ")] <- NA

# Corregir NAs y unificar valores en premname
SQFdata$premname[which(SQFdata$premname == " ")] <- NA

# Corregir NAs y unificar valores en sector
SQFdata$sector[which(SQFdata$sector == " ")] <- NA

# Corregir NAs y unificar valores en stinter
SQFdata$stinter[which(SQFdata$stinter == " ")] <- NA

# Corregir NAs y unificar valores en stname
SQFdata$stname[which(SQFdata$stname == " ")] <- NA

# Corregir NAs y unificar valores en sumoffen
SQFdata$sumoffen[which(SQFdata$sumoffen == " ")] <- NA

# Corrección pct
SQFdata$pct <- factor(SQFdata$pct)

# Corrección addrpct
SQFdata$addrpct <- factor(SQFdata$addrpct)

# Corrección beat
SQFdata$beat <- factor(SQFdata$beat)

# Corrección post
SQFdata$post <- factor(SQFdata$post)

# Corrección detailCM
SQFdata$detailCM <- factor(SQFdata$detailCM)

# Corrección inout
SQFdata$inout <- factor(SQFdata$inout, levels = c('I','O'), labels=c('Inside', 'Outside'))

# Corrección trhsloc
SQFdata$trhsloc <- factor(SQFdata$trhsloc, levels = c("H", "P", "T"),
                          labels=c('Housing', 'Neither', 'Transit'))

# Corrección typeofid
SQFdata$typeofid <- factor(SQFdata$typeofid, levels = c("O", "P", "R", "V"),
                           labels=c('Other', 'Photo', 'Refused', 'Verbal'))

# Corrección sex
SQFdata$sex <- factor(SQFdata$sex, levels = c("F", "M", "Z"), labels=c('Female', 'Male', 'Unknown'))

# Corrección race
SQFdata$race <- factor(SQFdata$race, levels = c("A", "B", "I", "P", "Q", "U", "W", "Z"),
                       labels=c('ASIAN/PACIFIC ISLANDER', 'BLACK', 'AMERICAN INDIAN/ALASKAN NATIVE',
                                'BLACK-HISPANIC', 'WHITE-HISPANIC', 'UNKNOWN', 'WHITE', 'OTHER'))

# Corrección eyecolor
SQFdata$eyecolor <- factor(SQFdata$eyecolor,
                           levels = c("BK","BL","BR","DF", "GR", "GY","HA", "MA",
                                      "MC","P","VI","XX","Z"),
                           labels=c('Black', 'Blue', 'Brown', 'Two different',
                                    'Green', 'Gray', 'Hazel', 'Maroon', 'MC',
                                    'Pink', 'Violet', 'Unknown', 'Other'))

# Corrección haircolr
SQFdata$haircolr <- factor(SQFdata$haircolr,
                           levels = c("BA","BK","BL","BR","DY","FR","GY",
                                      "RA","SN","SP","WH","XX","ZZ"),
                        labels=c('Bald', 'Black', 'Blond', 'Brown', 'Dyed',
                                 'Frosted', 'Gray', 'Red', 'Sandy',
                                 'Salt and pepper', 'White', 'Unknown', 'Other'))

# Corrección build
SQFdata$build <- factor(SQFdata$build, levels = c("H", "M", "T", "U", "Z"),
                        labels=c('Heavy', 'Medium', 'Thin', 'Muscular', 'Unknown'))
```

## 3.2 Análisis exploratorio

### 3.2.1 Variable objetivo: Arresto (arstmade)

```{r, fig.height=5, fig.width=15}
tot <- length(SQFdata$arstmade)
SQFdata %>% group_by(Arresto = arstmade) %>%
    summarise(Casos = n(),
              Porcentaje = paste(round(n()/tot*100,2),'%'))
```

```{r, warning=FALSE}
ggplot(data = SQFdata, aes(arstmade)) + geom_bar() + ylab("Frequency")
```

### 3.2.2 Variables independientes

#### Complexión del sospechoso (build)

```{r}
SQFdata %>% group_by(build) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "build"**, que se paran (Stop) a muchos más sospechosos con complexión "Medium" y "Thin" que del resto, siendo el porcentaje de sospechosos parados con complexión "Muscular" muy bajo. Aunque esto podría estar influenciado por el número de individuos que existen de cada caso en la población en general.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(build)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(build)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(build, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia un mayor porcentaje de arrestos en el grupo "Muscular" (18.38%) comparado con los demás, siendo el grupo con menor porcentaje de arrestos el grupo "Medium" (13.93%). En base a este análisis exploratorio, a priori parece que existen **ligeras** diferencias entre los diferentes grupos, aunque podrían no ser estadísticamente significativas (a comprobar en posterior análisis). En cuyo caso (negativo), se concluiría que no existen diferencias sustanciales entre los grupos y por lo tanto no es un factor relevante a la hora de determinar si se produce o no un arresto.

#### ¿Fue el sospechoso cacheado? (frisked)

```{r}
SQFdata %>% group_by(frisked) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "frisked"**, que de los sospechos parados se cachean al doble de individuos (66.27%) respecto a los que no son cacheados (33.73%).

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(frisked)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(frisked)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(frisked, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n = paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que no hay grandes diferencias en los porcentajes de arrestos en función de si el sospechoso ha sido previamente cacheado o no. Por lo que se puede concluir que, a priori, este factor no es determinante a la hora de ser arrestado.

#### ¿Fue encontrado un cuchillo o instrumento de corte en el sospechoso?  (knifcuti)

```{r}
SQFdata %>% group_by(knifcuti) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "knifcuti"**, que de los sospechos parados tan solo el 2.33% portan un cuchillo o similar. A parte de esto, se aprecia que el porcentanje de NAs es del 23.16%, siendo un valor nada despreciable. Aunque es razonable pensar que, de este porcentaje, los casos donde el sospechoso portaba un arma de este estilo y que no haya sido registrado por el oficial de policía han de ser mímimos, ya que como hemos visto es un hecho destacado y poco frecuente. Siendo más bien la razón de que no se haya registrado ningún dato el que no se portase este tipo de arma. Por lo que, si imputásemos los "NA" como "N" el porcentaje de "Y" sería aún más pequeño.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(knifcuti)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(knifcuti)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(knifcuti, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos se dispara hasta el 64.14% en caso de ser encontrado un cuchillo. Por lo que se puede concluir que, a priori, éste es un factor relevante a la hora de ser arrestado.

#### ¿Fue encontrada una ametralladora en el sospechoso? (machgun)

```{r}
SQFdata %>% group_by(machgun) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "machgun"**, que no ha sido parado ningún sospecho que portase una ametralladora. A parte de esto, se aprecia que el porcentanje de NAs es del 23.72%, siendo un valor nada despreciable. Aunque es razonable pensar que, de este porcentaje, los casos donde el sospechoso portaba un arma de este estilo y que no haya sido registrado por el oficial de policía han de ser inexistentes, ya que es un hecho destacado como para ser pasado por alto. Siendo más bien la razón de que no se haya registrado ningún dato, el que no se portase este tipo de arma.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(machgun)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(machgun)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(machgun, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que los porcentajes de arrestos son prácticamente iguales para los casos donde el sospechoso no portaba este tipo de arma o donde no se haya registrado este dato.

#### ¿Fue encontrada otro tipo de arma en el sospechoso? (othrweap)

```{r}
SQFdata %>% group_by(othrweap) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "othrweap"**, que de los sospechos parados tan solo el 0.79% portaban otro tipo de arma no catalogada. A parte de eso, se aprecia que el porcentanje de NAs es del 23.52%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(othrweap)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(othrweap)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(othrweap, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos se dispara hasta el 61.71% en caso de ser encontrado un arma de otro tipo no catalogada. Por lo que se puede concluir que, a priori, éste es un factor relevante a la hora de ser arrestado.

#### Fuerza física usada por el oficial de policía - Apuntar con el arma (pf_ptwep)

```{r}
SQFdata %>% group_by(pf_ptwep) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "pf_ptwep"**, que el oficial de policía tuvo que apuntar con su arma al sospecho parado tan solo el 0.73% de las ocasiones. A parte de esto, se aprecia que el porcentanje de NAs es del 23.54%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_ptwep)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(pf_ptwep)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(pf_ptwep, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos aumenta hasta el 23.49% cuando el oficial de policía tuvo que apuntar con su arma al sospecho siendo el 14.94% cuando no ocurrió esto último. Por lo que se puede concluir que, a priori, éste puede ser un factor relevante a la hora de ser arrestado aunque no lo es tanto como sucede en otras variables.

#### Fuerza física usada por el oficial de policía - Porra (pf_baton)

```{r}
SQFdata %>% group_by(pf_baton) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "pf_baton"**, que el oficial de policía tuvo que utilizar la porra contra el sospecho parado tan solo en el 0.02% de las ocasiones (10 ocasiones en total). Por lo que, se puede concluir que es un tipo de defensa muy poco usada por los oficiales de policía que en caso de tener que utilizar la fuerza optan por otro tipo de armas antes que por ésta.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_baton)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(pf_baton)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(pf_baton, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos se dispara hasta el 80% en los casos donde el oficial de policía tuvo que utilizar la porra contra el sospecho parado. Por lo que se puede concluir que, a priori, éste es un factor relevante a la hora de ser arrestado. Aunque la escasez de casos puede que no sean suficientes para sacar conclusiones definitivas.

#### Razón para la parada - El sospechoso actuando como un vigía (cs_lkout)

```{r}
SQFdata %>% group_by(cs_lkout) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "cs_lkout"** que de los sospechos parados, el 14.4% lo fue por estar actuando como vigía. A parte de eso, se aprecia que el porcentanje de NAs es del 20.42%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_lkout)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(cs_lkout)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(cs_lkout, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos es más bajo (9.15%) en caso de ser parado por estar actuando como un vigía que en otros casos (15.97%). Por lo que, apriori, no parece que sea un factor determinante a la hora de ser arrestado.

#### Razón para la parada - Llevar ropa usada frecuentemente en un crimen (cs_cloth)

```{r}
SQFdata %>% group_by(cs_cloth) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "cs_cloth"**, que de los sospechos parados tan solo el 4.78% lo fueron por llevar ropa usada frecuentemente en un crimen. A parte de eso, se aprecia que el porcentanje de NAs es del 22.78%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_cloth)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(cs_cloth)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(cs_cloth, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos es más bajo (9.69%) en caso de ser parado por llevar ropa usada frecuentemente en un crimen que en los casos donde no (15.26%). Por lo que, apriori, no parece que sea un factor determinante a la hora de ser arrestado.

#### Razón para el cacheo - Atuendo inapropiado para la estación del año (rf_attir)

```{r}
SQFdata %>% group_by(rf_attir) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "rf_attir"**, que de los sospechos cacheados tan solo el 7.7% lo fueron por llevar un atuendo inapropiado para la estación del año en curso. A parte de esto, se aprecia que el porcentanje de NAs es del 22.23%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_attir)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(rf_attir)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(rf_attir, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos es más bajo (11.77%) en caso de ser cacheado por llevar un atuendo inapropiado para la estación del año en curso que en los casos donde no (15.30%). Por lo que, apriori, no parece que sea un factor determinante a la hora de ser arrestado.

#### Razón para el cacheo - Acciones relacionadas en un crimen violento (rf_vcact)

```{r}
SQFdata %>% group_by(rf_vcact) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "rf_vcact"**, que de los sospechos cacheados el 9.05% lo fueron por cometer acciones relacionadas en un crimen violento. A parte de esto, se aprecia que el porcentanje de NAs es del 21.61%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_vcact)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(rf_vcact)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(rf_vcact, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos es un poco más bajo (12.07%) en caso de ser cacheado por cometer acciones relacionadas en un crimen violento que en los casos donde no (15.19%). Por lo que, apriori, no parece que sea un factor determinante a la hora de ser arrestado.

#### Fundamentos del registro - Silueta de arma (sb_outln)

```{r}
SQFdata %>% group_by(sb_outln) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "sb_outln"**, que tan solo en el 0.92% de las ocasiones (419 ocasiones en total) la razón para que el sospechoso fuese registrado o inspeccionado fue que se percibió una silueta de arma en el cacheo. A parte de esto, se aprecia que el porcentanje de NAs es del 23.5%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sb_outln)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(sb_outln)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(sb_outln, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos aumenta hasta el 50.36% en los casos donde se registra al sospecho porque se aprecia una silueta de arma. Por lo que se puede concluir que, a priori, éste es un factor relevante a la hora de ser arrestado.

#### Fundamentos del registro - Declaraciones del sospechoso (sb_admis)

```{r}
SQFdata %>% group_by(sb_admis) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "sb_admis"**, que tan solo en el 0.83% de las ocasiones (380 ocasiones en total) el sospechoso fue registrado o inspeccionado por las declaraciones manifestadas por el propio sospechoso. A parte de esto, se aprecia que el porcentanje de NAs es del 23.52%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sb_admis)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(sb_admis)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(sb_admis, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos aumenta hasta el 65.26% en los casos donde se registra al sospechoso siendo la razón las declaraciones manifestadas por el propio sospechoso. Por lo que se puede concluir que, a priori, éste es un factor relevante a la hora de ser arrestado.

#### Circunstancias adicionales - Momento del día con mayor indicencia de crímenes (ac_time)

```{r}
SQFdata %>% group_by(ac_time) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "ac_time"**, que el 40.3% de las ocasiones cuando se para a un sospechoso corresponden con periodos del día con mayor incidencia de crímenes, siendo el porcentaje de NAs de 14.87%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_time)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(ac_time)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(ac_time, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos es muy similar en todos los casos, estando en torno al 15%. Por lo que, apriori, no parece que sea un factor determinante a la hora de ser arrestado.

#### Circunstancias adicionales - Señales o sonidos de actividad criminal (ac_stsnd)

```{r}
SQFdata %>% group_by(ac_stsnd) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "ac_stsnd"**, que tan solo en el 3.06% de las ocasiones (1400 ocasiones en total) el sospechoso fue parado por percibirse señales o sonidos de actividad criminal. A parte de esto, se aprecia que el porcentanje de NAs es del 23.02%.

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_stsnd)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(ac_stsnd)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(ac_stsnd, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos es muy similar en todos los casos, estando en torno al 15%. Por lo que, apriori, no parece que sea un factor determinante a la hora de ser arrestado.

#### Razón de utilización de la fuerza (forceuse)

```{r}
SQFdata %>% group_by(forceuse) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Lo primero que se aprecia en la distribución de la **variable "forceuse"**, es el gran número de casos de datos faltantes (NA) siendo el 78.91% del total de casos, una cifra muy alta. Pero si analizamos un poco más en profundidad, nos damos cuenta que no existe una categoría a marcar cuando no se usó la fuerza. Por lo que cabe pensar que cuando el oficial de policía no usó la fuerza contra el sopechoso simplemente no marcó ninguna de las casillas disponibles, dejando todas en blanco. Por lo que los NAs serían realmente casos donde no se usó la fuerza. Los casos donde se haya utilizado la fuerza y no haya sido registrado han de ser mínimos ya que es un hecho destacado como para ser pasado por alto.

Dentro de los casos donde se utilizó la fuerza contra el sospechoso, destacan la defensa propia y la huida del sospecho sobre el resto de razones para usarla (sospechoso con arma, ofrecimiento de resistencia y la defensa de otros).

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(forceuse)) +
    geom_bar() + ylab("Frequency") + theme(axis.text.x = element_text(angle=45, hjust=1))
p2 = ggplot(data = SQFdata, aes(forceuse)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage") + theme(axis.text.x = element_text(angle=45, hjust=1))
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(forceuse, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia un mayor porcentaje de arrestos en los casos "Ofreció resistencia a la autoridad" (40.25%), "Otros" (39.34%) y "Huida del sospechoso" (24.82%) comparado con el resto de casos, siendo el grupo con menor porcentaje de arrestos el grupo "NA (no se utilizó la fuerza)" (12.28%).

Por lo que, apriori, parece que es un factor determinante a la hora de ser arrestado.

#### ¿El oficial de policía explicó la razón de la parada? (explnstp)

```{r}
SQFdata %>% group_by(explnstp) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

Se puede apreciar en la distribución de la **variable "explnstp"**, que el oficial de policía explicó al sospecho la razón de la parada en la práctica totalidad de las ocasiones (99.85%).

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(explnstp)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(explnstp)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(explnstp, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia que el porcentaje de arrestos se dobla (38.24%)  en los casos donde el oficial de policía no explicó la razón de la parada al sospechoso respecto a los casos donde sí lo hizo (15.03%). Aunque la escasez de casos, donde no se explicó la razón de la parada, puede que no sean suficientes para determinar que éste sea un factor relevante a la hora de ser arrestado.

#### Localización de la Parada: Cruce con la calle (crossst)

```{r}
SQFdata %>% group_by(crossst) %>%
        filter(n() > 150) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/nrow(SQFdata)*100,2),"%")) %>%
        arrange(desc(n))
```

La variable "crossst" (localización de la Parada: Cruce con la calle) tiene 3.437 valores distintos entre los 45.787 casos registrados. Por lo que, hemos hecho un filtrado de las localizaciones donde el número de paradas registradas es mayor al menos a 150 casos para que los indicadores resultantes sean mínimamente significativos.

Se puede apreciar en la distribución de la **variable "crossst"**, que las "localizaciones de la Parada: Cruce con la calle X" con más casos son: Broadway y Park Avenue con más de 400 casos; y East 14 Street, Nostrand Avenue, RichMond Terrace, 3 Avenue y Port Richmond Avenue con más de 200 casos.

```{r, fig.height=15, fig.width=15, warning=FALSE}
SQFdata.filtered = SQFdata %>%
                      group_by(crossst) %>%
                      filter(n() > 150)

p1 = ggplot(data = SQFdata.filtered , aes(crossst)) +
    geom_bar() + ylab("Frequency") + theme(axis.text.x = element_text(angle=45, hjust=1))
p2 = ggplot(data = SQFdata.filtered , aes(crossst)) +
    geom_bar(aes(fill = arstmade), position = "fill") +
    ylab("Percentage") + theme(axis.text.x = element_text(angle=45, hjust=1))
multiplot(p1,p2,cols=1)
```

```{r}
SQFdata.filtered %>% group_by(crossst, arstmade) %>%
                      summarise(n=n()) %>%
                      mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%")) %>%
                      filter(arstmade=="Y") %>%
                      arrange(desc(n))
```

En cuanto a la **variable dependiente "arstmade"**, se aprecia un mayor porcentaje de arrestos en las siguientes localizaciones de la parada (cruce con la calle): East 132 Street, Morris Avenue, East 14 Street, Park Avenue, 3 Avenue y East 169 Street que en el resto de localizaciones. Por lo que, apriori, puede que sea un factor determinante a la hora de ser arrestado.

#### Localización de la Parada: xcoord  vs  ycoord

```{r, echo=FALSE}
OnlyHTML <- opts_knit$get("rmarkdown.pandoc.to") == 'html'
```

```{r, fig.height=30, fig.width=30, eval=OnlyHTML}
coords <- SQFdata[, c("xcoord", "ycoord")]
coords.new <- project(coords, inverse=TRUE,
                      proj="+proj=lcc +lat_1=41.03333333333333 +lat_2=40.66666666666666
                      +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000.0000000001
                      +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs")
SQFdata["xcoord"] <- coords.new[[1]]
SQFdata["ycoord"] <- coords.new[[2]]

df <- SQFdata %>% 
    select(xcoord, ycoord, arstmade) %>% 
    filter(!is.na(xcoord)|!is.na(ycoord))
pal <- colorFactor(c("#2980b9", "#C70039"), df$arstmade)

leaflet(data = df) %>%
  addProviderTiles(providers$Esri.WorldGrayCanvas) %>%
  setView(-73.9796295, 40.6978522, zoom = 11) %>%
  addCircleMarkers(lng=~df$xcoord, lat=~df$ycoord, radius=2,
                   stroke=FALSE, color=~pal(df$arstmade), popup=df$arstmade) %>%
  addLegend(position="bottomleft", colors=c("#C70039","#2980b9"),
            labels=c("arstmade (Yes)", "arstmade (No)"))
```

#### Raza del sospechoso (race)

```{r race}
SQFdata %>% group_by(Raza = race) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje = paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r race-arstmade}
SQFdata %>% group_by(Raza = race, Arresto = arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r race-plot, fig.height=12, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(race)) +
    geom_bar() + ylab("Frecuencia") + xlab('Raza') +
    theme_minimal() + theme(axis.text.x = element_text(angle=-45, hjust = 0))
p2 = ggplot(data = SQFdata, aes(x = race)) +
    geom_bar(aes(fill = arstmade), position = "fill") +
    ylab("Porcentaje de arrestos") + xlab('Raza') +
    theme_minimal() + theme(axis.text.x = element_text(angle=-45, hjust = 0)) +
    scale_y_continuous(labels = scales::percent)
multiplot(p1,p2,cols=2)
```

Se observa una clara diferencia en cuanto al número de casos para cada uno de los niveles de la variable *race*. Mientras que más de un 50% de los casos se dan para el nivel *Black*, tan solo un 0.42% son de tipo *American indian*.

En cuanto al número de arrestos realizados, *Black-hispanic* y *White-hispanic* parecen presentar una tasa ligeramente superior que el resto.


#### Edad del sospechoso (age)

```{r age}

ages <- SQFdata$age[which(!is.na(SQFdata$age))]

z = cut(SQFdata$age, c(min(ages)-1, 25, 40, max(ages)))
summary(z)

SQFdata_age <- SQFdata
SQFdata_age$age <- factor(relevel(z, ref = 1))

SQFdata %>% group_by(age) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))

SQFdata_age %>% group_by(age) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r age-arstmade}
SQFdata %>% group_by(age, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))

SQFdata_age %>% group_by(age, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r age-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(age)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(age)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)

p1 = ggplot(data = SQFdata_age, aes(age)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata_age, aes(age)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Tras factorizar la variable edad, se observa como para los sospechosos de menor edad (<25 años) existe un mayor número de casos. Sin embargo, a pesar de haber más detenciones de personas jóvenes, la tendencia en cuanto a arrestos es la contraria, es decir, los menores de 25 años muestran una tasa menor de arrestos.

Podría ser interesante tratar de refinar más los puntos de corte en cuanto a las edades de los sospechosos.

#### Sospechoso portando contrabando (contrabn)

```{r contrabn }
SQFdata %>% group_by(contrabn) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje = paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r contrabn-arstmade}
SQFdata %>% group_by(contrabn, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r contrabn-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(contrabn)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(contrabn)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Si el sospechoso lleva contrabando encima, es muy probable que se le arreste.

#### Sospechoso portando fusil de asalto (asltweap)

```{r asltweap}
SQFdata %>% group_by(asltweap) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r asltweap-arstmade}
SQFdata %>% group_by(asltweap, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r asltweap-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(asltweap)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(asltweap)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No existen suficientes casos como para obtener conclusiones. O bien se descargan datos de otros años o se elimina la variable.

#### Descripción de código del crimen (detailCM)

```{r detailCM}
SQFdata_detailCM <- SQFdata %>%
    group_by(detailCM) %>%
    mutate(count = n()) %>%
    filter(count > 2200) %>%
    arrange(desc(count))

SQFdata %>% group_by(detailCM) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        filter(Casos > 900) %>%
        arrange(desc(Casos))

SQFdata_detailCM %>% group_by(detailCM) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        arrange(desc(Casos))
```

```{r detailCM-arstmade}
SQFdata %>% group_by(detailCM, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        # filter(Casos > 200) %>%
        arrange(desc(detailCM), desc(arstmade), desc(Casos))

SQFdata_detailCM %>% group_by(detailCM, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        # filter(Casos > 200) %>%
        arrange(desc(detailCM), desc(arstmade), desc(Casos))
```

```{r detailCM-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(detailCM)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(detailCM)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)

p1 = ggplot(data = SQFdata_detailCM, aes(detailCM)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata_detailCM, aes(detailCM)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Se oservan grandes diferencias entre los distintos tipos de crímenes registrados. Sin embargo, para muchos de ellos se dispone de pocas observaciones por lo que se opta por mostrar únicamente aquellos casos de los que se disponga un mayor número de registros.

Se observan diferencias en cuanto a las tasas de arresto dentro de los tipos de crimen seleccionados.

#### Uso de fuerza física - Sospechoso al suelo (pf_grnd)

```{r pf_grnd}
SQFdata %>% group_by(pf_grnd) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r pf_grnd-arstmade}
SQFdata %>% group_by(pf_grnd, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r pf_grnd-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_grnd)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(pf_grnd)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Se muestra una tasa de arrestos mayor para los casos en los que se reduce al sospechoso en el suelo. Sin embargo, existen pocos casos como para que se pueda afirmar con seguridad.

#### Uso de fuerza física - Desenfundar arma (pf_drwep)

```{r pf_drwep}
SQFdata %>% group_by(pf_drwep) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r pf_drwep-arstmade}
SQFdata %>% group_by(pf_drwep, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r pf_drwep-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_drwep)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(pf_drwep)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

La tasa de arrestos se muestra muy similar en ambos casos. Existen pocas observaciones como para poder afirmar diferencias con seguridad.

#### Motivo de parada - Encajar con descripción (cs_descr)

```{r cs_descr}
SQFdata %>% group_by(cs_descr) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r cs_descr-arstmade}
SQFdata %>% group_by(cs_descr, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r cs_descr-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_descr)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(cs_descr)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No existe diferencia en la tasa de arrestos según si la detención se produce por encajar con una descripción o no.

#### Motivo de parada - ¿¿Acechar?? a víctima o lugar (cs_casng)

```{r cs_casng }
SQFdata %>% group_by(cs_casng) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r cs_casng-arstmade}
SQFdata %>% group_by(cs_casng, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r cs_casng-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_casng)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(cs_casng)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Se muestra una tasa de arrestos ligeramente menor para los casos en los que se encuentra al sospechoso acechando a una víctima o lugar.
Puede ser debido a que al encontrar acechando al sospechoso, aún no se ha cometido ningún crimen y por tanto no es posible llevar a cabo el arresto pero si detener durante algún tiempo al sospechoso.

#### Motivo de parada - Otros (cs_other)

```{r cs_other}
SQFdata %>% group_by(cs_other) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r cs_other-arstmade}
SQFdata %>% group_by(cs_other, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r cs_other-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_other)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(cs_other)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No existen diferencias en cuanto a la tasa de arrestos.

#### Motivo de cacheo - Otras sospechas de armas (rf_othsw)

```{r rf_othsw }
SQFdata %>% group_by(rf_othsw) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r rf_othsw-arstmade}
SQFdata %>% group_by(rf_othsw, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r rf_othsw-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_othsw)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(rf_othsw)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Se muestran diferencias en las tasas de arresto. De la misma forma que para otras variables, puede ser debido a que si existe la sospecha de que se esté portando un arma y se confirma, se produce el arresto con mayor probabilidad.

#### Motivo de cacheo - Bulto sospechoso (rf_bulg)

```{r rf_bulg}
SQFdata %>% group_by(rf_bulg) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r rf_bulg-arstmade}
SQFdata %>% group_by(rf_bulg, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r rf_bulg-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_bulg)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(rf_bulg)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No existen diferencias en cuanto a la tasa de arrestos.

#### Motivo de búsqueda - Objeto contundente (sb_hdobj)

```{r sb_hdobj }
SQFdata %>% group_by(sb_hdobj) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r sb_hdobj-arstmade}
SQFdata %>% group_by(sb_hdobj, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r sb_hdobj-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sb_hdobj)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(sb_hdobj)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Existen ligeras diferencias en la tasa de arrestos.

#### Circunstancias adicionales - Cambio de dirección al ver a un oficial (ac_cgdir)

```{r ac_cgdir }
SQFdata %>% group_by(ac_cgdir) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r ac_cgdir-arstmade}
SQFdata %>% group_by(ac_cgdir, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r ac_cgdir-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_cgdir)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(ac_cgdir)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

La tasa de arresto es similar en ambos casos.

#### Circunstancias adicionales - Área de alta tasa de criminalidad (ac_incid)

```{r ac_incid }
SQFdata %>% group_by(ac_incid) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r ac_incid-arstmade}
SQFdata %>% group_by(ac_incid, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r ac_incid-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_incid)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(ac_incid)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No existen diferencias en cuanto a la tasa de arresto.

#### Circunstancias adicionales - Otras (ac_other)

```{r ac_other }
SQFdata %>% group_by(ac_other) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r ac_other-arstmade}
SQFdata %>% group_by(ac_other, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r ac_other-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_other)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(ac_other)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No existen diferencias en la tasa de arrestos.

#### Cruce en el que se produce la parada (stinter)

```{r stinter}
SQFdata_stinter <- SQFdata %>%
    group_by(stinter) %>%
    mutate(count = n()) %>%
    filter(count > 270) %>%
    arrange(desc(count))

SQFdata %>% group_by(stinter) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))

SQFdata_stinter %>% group_by(stinter) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        arrange(desc(Casos))
```

```{r stinter-arstmade}
SQFdata %>% group_by(stinter, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        arrange(desc(stinter), desc(arstmade), desc(Casos))

SQFdata_stinter %>% group_by(stinter, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%")) %>%
        arrange(desc(stinter), desc(arstmade), desc(Casos))
```

```{r stinter-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(stinter)) + geom_bar() +
    ylab("Frequency") + theme(axis.text.x = element_text(angle=-45, hjust = 0))
p2 = ggplot(data = SQFdata, aes(stinter)) +
    geom_bar(aes(fill = arstmade), position = "fill") +
    ylab("Percentage") + theme(axis.text.x = element_text(angle=-45, hjust = 0))
multiplot(p1,p2,cols=2)

p1 = ggplot(data = SQFdata_stinter, aes(stinter)) + geom_bar() +
    ylab("Frequency") + theme(axis.text.x = element_text(angle=-45, hjust = 0))
p2 = ggplot(data = SQFdata_stinter, aes(stinter)) +
    geom_bar(aes(fill = arstmade), position = "fill") +
    ylab("Percentage") + theme(axis.text.x = element_text(angle=-45, hjust = 0))
multiplot(p1,p2,cols=2)
```

Existen claras diferencias según el cruce en el que se produce la detención. Cabe destacar que para poder apreciar la información se seleccionan únicamente aquellos para los que se dispone de un mayor número de observaciones.

#### Sector en el que se produce la parada (sector)

```{r sector }
SQFdata %>% group_by(sector) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r sector-arstmade}
SQFdata %>% group_by(sector, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r sector-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sector)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(sector)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

No se observan diferencias en la tasa de arresto que en general se mantiene constante.

#### Tipo de identificación de la persona parada (typeofid)

```{r typeofid }
SQFdata %>% group_by(typeofid) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r typeofid-arstmade}
SQFdata %>% group_by(typeofid, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r typeofid-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(typeofid)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(typeofid)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

En la mayoría de los casos se da un reconocimiento verbal o por foto y no existen grandes diferencias entre ambos en la tasa de arrestos. Para el resto de casos no se dispone de datos suficientes como para poder afirmar diferencias con seguridad.

#### Paro, interrogatorio o cacheo a otras personas (othpers)

```{r othpers }
SQFdata %>% group_by(othpers) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r othpers-arstmade}
SQFdata %>% group_by(othpers, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r othpers-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(othpers)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(othpers)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

La tasa de arrestos es ligeramente inferior cuando existen más personas involucradas. Esto puede ser debido a que el agente tiene que repartir el tiempo entre los distintos sospechosos o personas involucradas en el crimen.

#### Llamada de radio (radio)

```{r radio }
SQFdata %>% group_by(radio) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r radio-arstmade}
SQFdata %>% group_by(radio, arstmade) %>%
        summarise(Casos = n()) %>%
        mutate(Porcentaje=paste0(round(Casos/sum(Casos)*100,2),"%"))
```

```{r radio-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(radio)) + geom_bar() + ylab("Frequency")
p2 = ggplot(data = SQFdata, aes(radio)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Percentage")
multiplot(p1,p2,cols=2)
```

Existen ligeras diferencias en la tasa de arresto.

#### Tiempo de observación (perobs)

```{r, fig.height=5, fig.width=15}
cor(SQFdata$perobs, SQFdata$perstop)
```

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(arstmade) %>%
        summarise(n=n(), 
                  min= min(perobs),
                  `25%`=quantile(perobs, probs=0.25), 
                  `50%`=quantile(perobs, probs=0.50),                  
                  media= round(mean(perobs),2),
                  `75%`=quantile(perobs, probs=0.75),                  
                  max= max(perobs)) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```


```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = SQFdata %>% filter(perobs<100) %>%
        ggplot(aes(x=perobs)) + geom_histogram() 
p2 = SQFdata %>% filter(perobs<20) %>%
        ggplot(aes(arstmade, perobs)) + geom_boxplot()
p3 = SQFdata %>% filter(perobs<100) %>%
        ggplot(aes(x=perobs, color=arstmade, fill=arstmade)) +
        geom_histogram(alpha=0.5, position="identity")

multiplot(p1,p2,p3,cols=2)
```

Antes de parar una persona, el oficial observa a la persona y evalúa parámetros, variables e indicios que den cuenta la necesidad de iniciar el procedimiento “stop and frisk”. El 98% de las personas paradas fueron observadas entre  0 a 10 minutos, el 2% está distribuido entre 11 hasta 635 minutos. El tiempo empleado para observar a las personas que fueron paradas y arrestadas es menor en relación a las que no fueron arrestadas

#### Tiempo de parada (perstop)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(arstmade) %>%
        summarise(n=n(), 
                  min= min(perstop),
                  `25%`=quantile(perstop, probs=0.25), 
                  `50%`=quantile(perstop, probs=0.50),                  
                  media= round(mean(perstop),2),
                  `75%`=quantile(perstop, probs=0.75),                  
                  max= max(perstop)) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(x=perstop)) + geom_histogram() 
p2 = ggplot(data = SQFdata, aes(arstmade, perstop)) + geom_boxplot()
p3 = SQFdata %>% filter(perobs<100) %>%
        ggplot(aes(x=perstop, color=arstmade, fill=arstmade)) +
        geom_histogram( alpha=0.5, position="identity")

multiplot(p1,p2,p3,cols=2)
```

El período de parada no presenta una sola distribución, a priori, se puede determinar que es multimodal.  Las paradas tuvieron un período de tiempo principalmente de 62, 14 y 6 minutos. Al igual que el tiempo de observación, este es mayor en las personas que no fueron arrestadas.

#### Condados (city)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(city) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(city)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(city)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(arstmade,city) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Registrado (searched)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(searched) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(searched)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(searched)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(arstmade,searched) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Pistola (pistol)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(pistol) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pistol)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pistol)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(pistol, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### El oficial usa fuerza física - esposas (pf_hcuff)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(pf_hcuff) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_hcuff)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pf_hcuff)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(arstmade, pf_hcuff) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### El oficial usa fuerza física - spray pimienta (pf_pepsp)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(pf_pepsp) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_pepsp)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pf_pepsp)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(pf_pepsp, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Razón para la parada - acciones indicaban transacción de drogas (cs_drgtr)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(cs_drgtr) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_drgtr)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(cs_drgtr)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(cs_drgtr, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Razón para la parada - movimientos sospechosos (cs_furtv)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by( cs_furtv) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_furtv)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(cs_furtv)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(cs_furtv, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Razón para la parada - acciones que indican estar involucrado en un crimen violento (cs_vcrim)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(cs_vcrim) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_vcrim)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(cs_vcrim)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(cs_vcrim, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Razón para la parada - rehusarse a cumplir con las instrucciones del oficial (rf_rfcmp)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(rf_rfcmp) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_rfcmp)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(rf_rfcmp)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(rf_rfcmp, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Razón para la parada - amenazas verbales por parte del sospechoso (rf_verbl)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(rf_verbl) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_verbl)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(rf_verbl)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(rf_verbl, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Razón de busqueda - otros (sb_other)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(sb_other) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sb_other)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(sb_other)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(sb_other, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Circunstancias adicionales - proximidad a la escena del delito (ac_proxm)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by( ac_proxm) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_proxm)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(ac_proxm)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(ac_proxm, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Circunstancias adicionales - informe de la víctima / testigo / oficial (ac_rept)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(ac_rept) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_rept)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(ac_rept)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(ac_rept, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Fue parado dentro o fuera (inout)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(inout) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(inout)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(inout)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(inout, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Fue ubicado por la autoridad tránsito o local (trhsloc)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(trhsloc) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(trhsloc)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(trhsloc)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(trhsloc, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Recinto donde se realizó la parada (pct)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(pct) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))%>%
        arrange(desc(n))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pct)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pct)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% filter(city=="BRONX" & arstmade=="Y")%>%
        group_by(pct) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))%>%
        arrange(desc(n))
```

#### Dirección del recinto donde se realizó la parada (addrpct)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(addrpct) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))%>%
        arrange(desc(n))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(addrpct)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(addrpct)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% filter(city=="BRONX" & arstmade=="Y")%>%
        group_by(addrpct) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))%>%
        arrange(desc(n))
```

#### Comando del oficial que hace el informe  (repcmd)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by( repcmd) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))%>%
        arrange(desc(n))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(repcmd)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(repcmd)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% filter(city=="MANHATTAN" & arstmade=="Y")%>%
        group_by( repcmd) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))%>%
        arrange(desc(n))
```

#### Comando del oficial que revisa  (revcmd)

```{r, fig.height=5, fig.width=15}
SQFdata %>% group_by(revcmd) %>%
        summarise(n=n()) %>%
        mutate(freq_n=paste0(round( n/sum(n)*100,2),"%"))
```

```{r, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(revcmd)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(revcmd)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

```{r}
SQFdata %>% group_by(revcmd, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

#### Sexo (Sex)

```{r sex}
SQFdata %>% group_by(sex) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r sex-arstmade}
SQFdata %>% group_by(sex, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r sex-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sex)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(sex)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

La mayor frecuencia de paradas fueron en los hombres 42528 frente a las 2865 mujeres que fueron paradas, donde el 14.56% de los hombres fueron detenidos y el 22.44% de las mujeres, pero en términos numéricos detuvieron a 6190 hombres frente a las 643 mujeres.

#### Peso (weight) en libras

```{r weight-arstmade}
weight <- SQFdata$weight[which(!is.na(SQFdata$weight))]
z = cut(SQFdata$weight, c(min(weight)-1, 50,250, 500, max(weight)))
SQFdata_weigth <- SQFdata
SQFdata_weigth$weigth <- factor(relevel(z, ref = 3))

SQFdata %>% group_by(weight, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))

SQFdata_weigth %>% group_by(weight, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r weight-plot, fig.height=5, fig.width=15, warning=FALSE}

p1 = ggplot(data = SQFdata, aes(weight)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(weight)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)

p1 = ggplot(data = SQFdata_weigth, aes(weight)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata_weigth, aes(weight)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

#### Color del pelo (Haircolor)

```{r haircolr}
SQFdata %>% group_by(haircolr) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r haircolr-arstmade}
SQFdata %>% group_by(haircolr, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r haircolr-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(haircolr)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(haircolr)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

La mayor frecuencia de paradas se produjeron en los que tienen el color de pelo moreno y castaño, donde se produjeron arrestos en el 15.08% y en el 12.84% respectivamente. Aunque el mayor porcentaje de arrestos se han producido en ...

#### Sospechoso portando rifle (riflshot)

```{r}
SQFdata %>% group_by(riflshot) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r riflshot-arstmade}
SQFdata %>% group_by(riflshot, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r riflshot-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(riflshot)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(riflshot)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

La mayor frecuencia de paradas se han producido en los que no llevaban rifles de asalto, con 34926 paradas, 5238 o el 15-5 de estos fueron arrestados, aunque lo importante es que los 3 que si portaban rifles de asalto si han sido arrestados.

#### Sospechoso fue a una citacion previa (sumissue)

```{r sumissue}
SQFdata %>% group_by(sumissue) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r sumissue-arstmade}
SQFdata %>% group_by(sumissue, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r sumissue-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(sumissue)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(sumissue)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

La mayor frecuencia de paradas fueron a los sospechosos que no habian ido a una citacion previa, de estos el 15.32% fueron arrestados. De los 1214 que si habian ido a una citacion previa, solo el 5.68% fueron arrestados.

#### Fuerza fisica usada por el oficial - manos (pf_hands)

```{r pf_hands}
SQFdata %>% group_by(pf_hands) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r pf_hands-arstmade}
SQFdata %>% group_by(pf_hands, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r pf_hands-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_hands)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pf_hands)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

La mayor frecuencia de las paradas han sido en los oficiales que no usaron como fuerza fisica las manos, de las 27449 personas el 14.33% fueron arrestadas, en cuanto a los 7205 personas en el que los oficiales usaron la fuerza fisica, el 18.61% de estos fueron arrestados.

#### Fuerza fisica usada por el oficial - sospechoso en tierra (pf_wall)

```{r pf_wall}
SQFdata %>% group_by(pf_wall) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r pf_wall-arstmade}
SQFdata %>% group_by(pf_wall, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r pf_wall-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_wall)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pf_wall)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

La mayor frecuencia de las paradas se han producido en las que el oficial no pidio al sospechoso ir al suelo con 33325 personas, de estas el 14.94% han sido arrestos, en cuanto a las 2050 personas que los oficiales si han pedido a los sospechosos ir al suelo, el 16.39% si han sido arrestados.
 
#### Fuerza fisica usada por el oficial - otros (pf_other)

```{r pf_other}
SQFdata %>% group_by(pf_other) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r pf_other-arstmade}
SQFdata %>% group_by(pf_other, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r pf_other-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(pf_other)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(pf_other)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

Entre todas las paradass en las que los oficiales usaron otro tipo de fuerza fisica, se han producido un 14.39% de arrestos.

#### Sospechoso lleva objetos sospechosos (cs_objcs)

```{r cs_objcs}
SQFdata %>% group_by(cs_objcs) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r cs_objcs-arstmade}
SQFdata %>% group_by(cs_objcs, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r cs_objcs-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_objcs)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(cs_objcs)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De los 1589 paradas en las que los sospechosos llevaban objetos sospechosos, han arrestado al 31.53% de estos.

#### Sospechoso con bulto sospechoso (cs_bulge)

```{r cs_bulge}
SQFdata %>% group_by(cs_bulge) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r cs_bulge-arstmade}
SQFdata %>% group_by(cs_bulge, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r cs_bulge-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(cs_bulge)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(cs_bulge)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 3476 paradas que realizaron los agentes que encontraron bultos sospechosos, han arrestado al 15.25%.

#### Sospechoso de crimen violento (rf_vcrim)

```{r rf_vcrim}
SQFdata %>% group_by(rf_vcrim) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r rf_vcrim-arstmade}
SQFdata %>% group_by(rf_vcrim, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r rf_vcrim-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_vcrim)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(rf_vcrim)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 10096 paradas que han realizado los oficiales de los sospechosos de crimen violento, han arrestado al 10.92% de las personas.

#### Sospechoso con antecendentes (rf_knowl)

```{r rf_knowl}
SQFdata %>% group_by(rf_knowl) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r rf_knowl-arstmade}
SQFdata %>% group_by(rf_knowl, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r rf_knowl-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_knowl)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(rf_knowl)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 2313 paradas que han realizado los agentes a los sospechosos que tenian antecedentes, han arrestado al 10.12%.

#### Sospechoso con movimientos furtivos (rf_furt)

```{r rf_furt}
SQFdata %>% group_by(rf_furt) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r rf_furt-arstmade}
SQFdata %>% group_by(rf_furt, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r rf_furt-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(rf_furt)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(rf_furt)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 16359 paradas realizadas a los sospechosos que hicieron movimientos furtivos, han arrrestado al 14.9%.

#### Respuestas evasivas en el cuestionario (ac_evasv)

```{r ac_evasv}
SQFdata %>% group_by(ac_evasv) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r ac_evasv-arstmade}
SQFdata %>% group_by(ac_evasv, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r ac_evasv-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_evasv)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(ac_evasv)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 9980 paradas realizadas a las personas que tuvieron respuestas evasivas en los cuestionarios, han arrestado al 19.28%.

#### Sospechoso relacionado con un criminal (ac_assoc)

```{r ac_assoc}
SQFdata %>% group_by(ac_assoc) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r ac_assoc-arstmade}
SQFdata %>% group_by(ac_assoc, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r ac_assoc-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_assoc)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(ac_assoc)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 3316 paradas realizadas a los sospechosos de estar relacionados con criminales, han arrestado al 11.1%.

#### Sospechoso bajo investigacion (ac_inves)

```{r ac_inves}
SQFdata %>% group_by(ac_inves) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r ac_inves-arstmade}
SQFdata %>% group_by(ac_inves, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r ac_inves-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(ac_inves)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(ac_inves)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 6813 paradas realizadas por los agentes a los sospechosos que estan bajo una investigacion, han arrestado al 12.12%.

#### Nombre de la calle donde el sospechoso fue parado (stname)

```{r stname}
SQFdata %>% group_by(stname) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r stname-arstmade}
SQFdata %>% group_by(stname, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r stname-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(stname)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(stname)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

#### El oficial iba uniformado (offunif)

```{r offunif}
SQFdata %>% group_by(offunif) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r offunif-arstmade}
SQFdata %>% group_by(offunif, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r offunif-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(offunif)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(offunif)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 24804 paradas en las que el agente iba uniformado, han arrestado al 17.39%.

#### Declaracion verbal proporcionada por el oficial uniformada (offverb)

```{r offverb}
SQFdata %>% group_by(offverb) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r offverb-arstmade}
SQFdata %>% group_by(offverb, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r offverb-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(offverb)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(offverb)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 14575 paradas en las que los agentes uniformados hicieron la declaracion verbal, el 13.39% fueron arrestados.

#### Identificacion proporcionada por el oficial uniformado (officrid)

```{r officrid}
SQFdata %>% group_by(officrid) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r officrid-arstmade}
SQFdata %>% group_by(officrid, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r officrid-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(officrid)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(officrid)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 889 paradas realizadas por los agentes que proporcionaron su identificacion, detuvieron al 21.26% de las personas.

#### El oficial llevaba escudo protector (offshld)

```{r offshld}
SQFdata %>% group_by(offshld) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r offshld-arstmade}
SQFdata %>% group_by(offshld, arstmade) %>%
        summarise(n=n()) %>%
        mutate(percentage_n=paste0(round(n/sum(n)*100,2),"%"))
```

```{r offshld-plot, fig.height=5, fig.width=15, warning=FALSE}
p1 = ggplot(data = SQFdata, aes(offshld)) + geom_bar() + ylab("Frecuencia")
p2 = ggplot(data = SQFdata, aes(offshld)) +
    geom_bar(aes(fill = arstmade), position = "fill") + ylab("Porcentaje")
multiplot(p1,p2,cols=2)
```

De las 20778 paradas que realizaron los agentes que llevaban escudo, detuvieron al 12.26% de las personas.

### 3.2.3 Conclusiones

**NYPD Stop Question Frisk Database 2014**
	112     variables 
	45.787  casos registrados

#### Variable objetivo: arstmade (WAS AN ARREST MADE?)

Del total de casos parados (45.787) durante el año 2104, fueron arrestados 6.898, es decir el 15,07%

```{r, fig.height=5, fig.width=15}
tot <- length(SQFdata$arstmade)
SQFdata %>% group_by(Arresto = arstmade) %>%
    summarise(Casos = n(),
              Porcentaje = paste(round(n()/tot*100,2),'%'))
```

#### Variables explicativas:

De todas las variables analizadas, existe un gran número de ellas en las que la tasa de arresto no muestra grandes diferencias según el valor que toman, por lo que no son relevantes a la hora de decidir el arresto del sospechoso.

Respecto a las variables en las que sí se aprecian diferencias respecto al arresto, resuminos a continuación los insights encontrados más significativos:

#### Grupo de variables sobre la razón de la parada:

|VARIABLE   |DESCRIPTION                                                  |
|-----------|-------------------------------------------------------------|
|explnstp   |	DID OFFICER EXPLAIN REASON FOR STOP ?                     |
|cs_drgtr   |	REASON FOR STOP - ACTIONS INDICATIVE OF A DRUG TRANSACTION|
|cs_vcrim   |	REASON FOR STOP - ACTIONS OF ENGAGING IN A VIOLENT CRIME  |
|cs_objcs   |	REASON FOR STOP - CARRYING SUSPICIOUS OBJECT              |
|cs_casng   |	REASON FOR STOP - CASING A VICTIM OR LOCATION             |
|cs_descr   |	REASON FOR STOP - FITS A RELEVANT DESCRIPTION             |
|cs_furtv   |	REASON FOR STOP - FURTIVE MOVEMENTS                       |
|cs_other   |	REASON FOR STOP - OTHER                                   |
|cs_lkout   |	REASON FOR STOP - SUSPECT ACTING AS A LOOKOUT             |
|cs_bulge   |	REASON FOR STOP - SUSPICIOUS BULGE                        |
|cs_cloth   |	REASON FOR STOP - WEARING CLOTHES COMMONLY USED IN A CRIME|

* En la práctica totalidad de los casos, 99.85%, el oficial de policía explicó la razón de la parada según la base de datos analizada.
* El 39.15% fueron parados por que el oficial detectó movimientos sospechosos, sin embargo, un bajo porcentaje fueron arrestados (14.29%), algo muy parecido sucede cuando la persona se rehusa a cumplir las instrucciones del oficial o cuando amenza verbalmente, lo que a priori, puede significar que no son razones tan relevantes para parar a una persona. 
* Es importante resaltar que cuando la parada se efectúa bajo la sospecha que el individuo ha participado en un crimen violento (10.56%) de los casos tan solo el 9,96% de ellos son arrestados, esto da indicios que los parámetros bajo los que se determina esta sospecha no son efectivas.
* Cuando la parada es por sospecha de llevar objetos sospechos (3,47% de los casos), terminan arrestando al 31.56% de ellos.
* Otras razones para efectuar la parada como la sospecha de que el individuo estaba comercializando drogas (7.64%) da cuenta que puede ser un factor un tanto más relevante que los anteriores ya que aumenta la detención al 24.76%.
* Como nota llamativa, el 4,78% son parados por llevar ropa usada frecuentemente en un crimen, aunque la media de arrestos para estos casos baja hasta el 9,69%.

#### Grupo de variables sobre las características físicas de los sospechosos:

|VARIABLE   |DESCRIPTION                                     |
|-----------|------------------------------------------------|
|sex		|   SUSPECT’S SEX                                |
|race	    |   SUSPECT’S RACE                               |
|dob		|   SUSPECT’S DATE OF BIRTH (CCYY-MM-DD)         |
|age		|   SUSPECT’S AGE                                |
|ht_feet	|   SUSPECT’S HEIGHT (FEET)                      |
|ht_inch	|   SUSPECT’S HEIGHT (INCHES)                    |
|weight		|   SUSPECT’S WEIGHT                             |
|haircolr	|   SUSPECT’S HAIRCOLOR                          |
|eyecolor	|   SUSPECT’S EYE COLOR                          |
|build		|   SUSPECT’S BUILD                              |
|othfeatr	|   SUSPECT’S OTHER FEATURES (SCARS, TATOOS ETC.)|

Respecto a la variables que aglutinan las diferentes características físicas de los sopechosos hemos detectado que:

* Si nos fijamos en el sexo, se paran mucho más a hombres que a mujeres, un 92,88% frente al 6.26%. En cambio, mientras que la media de arrestos en hombres es del 15.56% en las mujeres aumenta hasta el 22.44%.
* Si observamos la variable raza: se observa una clara diferencia en cuanto al número de casos para cada uno de los niveles. Mientras que más de un 50% de los casos se dan para el nivel _Black_, tan solo un 0.42% son de tipo _American indian_. En cuanto al número de arrestos realizados, _Black-hispanic_ y _White-hispanic_ parecen presentar una tasa ligeramente superior que el resto.

#### Grupo de variables sobre la localización de la parada:

|VARIABLE   |DESCRIPTION                                       |
|-----------|--------------------------------------------------|
|inout	    |	WAS STOP INSIDE OR OUTSIDE ?                   |
|trhsloc    |	WAS LOCATION HOUSING OR TRANSIT AUTHORITY ?    |
|addrtyp    |	LOCATION OF STOP ADDRESS TYPE                  |
|rescode    |	LOCATION OF STOP RESIDENT CODE                 |
|premtype   |	LOCATION OF STOP PREMISE TYPE                  |
|premname   |	LOCATION OF STOP PREMISE NAME                  |
|addrnum    |	LOCATION OF STOP ADDRESS NUMBER                |
|stname	    |	LOCATION OF STOP STREET NAME                   |
|stinter    |	LOCATION OF STOP INTERSECTION                  |
|crossst    |	LOCATION OF STOP CROSS STREET                  |
|aptnum	    |   LOCATION OF STOP APT NUMBER                    |
|city	    |	LOCATION OF STOP CITY                          |
|state	    |	LOCATION OF STOP STATE                         |
|zip	    |	LOCATION OF STOP ZIP CODE                      |
|addrpct    |	LOCATION OF STOP ADDRESS PRECINCT              |
|sector	    |	LOCATION OF STOP SECTOR                        |
|beat	    |	LOCATION OF STOP BEAT                          |
|post	    |	LOCATION OF STOP POST                          |
|xcoord	    |	LOCATION OF STOP X COORD                       |
|ycoord     |	LOCATION OF STOP Y COORD                       |

Respecto a estas variables lo más significativo es:

* Las paradas realizadas en el interior de alguna construcción son más probables que terminen en un arresto que las realizadas fuera, 35.43% y 10.45% respectivamente. Cabe mencionar que más del 80% de paradas son realizadas fuera.
* La mayor frecuencia de paradas fueron en los condados: Brooklyn (29.2%) y Queens (29.12%); el menor número en Staten Island (10,92%), sin embargo,  en relación a la población es el condado con mayor número de paradas. 
* De las 45.787 paradas en 2014, el  15% concluyeron en arrestos, de estos el 29%  fueron en Manhattan, principalmente en los recintos: 25, 9 y 23. En Bronx el 25.08% principalmente en los recintos 40, 42 y 44. El comando oficial que más informes realiza es el 826 ubicado en Bronx.

#### Grupo de variables sobre el cacheo:

|VARIABLE   |DESCRIPTION                                                  |
|-----------|-------------------------------------------------------------|
|frisked    |	WAS SUSPECT FRISKED ?                                     |
|rf_furt    |	REASON FOR FRISK - FURTIVE MOVEMENTS                      |
|rf_attir   |	REASON FOR FRISK - INAPPROPRIATE ATTIRE FOR SEASON        |
|rf_knowl   |	REASON FOR FRISK - KNOWLEDGE OF SUSPECT'S PRIOR CRIM BEHAV|
|rf_othsw   |	REASON FOR FRISK - OTHER SUSPICION OF WEAPONS             |
|rf_rfcmp   |	REASON FOR FRISK - REFUSE TO COMPLY W OFFICER'S DIRECTIONS|
|rf_bulg    |	REASON FOR FRISK - SUSPICIOUS BULGE                       |
|rf_verbl   |	REASON FOR FRISK - VERBAL THREATS BY SUSPECT              |
|rf_vcrim   |	REASON FOR FRISK - VIOLENT CRIME SUSPECTED                |
|rf_vcact   |	REASON FOR FRISK-  ACTIONS OF ENGAGING IN A VIOLENT CRIME |

Respecto a estas variables lo más significativo ha sido:

* Se puede apreciar en la distribución de la variable "frisked", que de los sospechos parados se cachean al doble de individuos (66.27%) respecto a los que no son cacheados (33.73%). En cuanto a la variable dependiente "arstmade", se aprecia que no hay grandes diferencias en los porcentajes de arrestos en función de si el sospechoso ha sido previamente cacheado o no.
* rf_furt 35.73% - rf_attir 7.7% - rf_knowl 5.05% - rf_othsw 9,92% - rf_rfcmp 12.95% - rf_bulg	 7.83% - rf_verbl 0,99% - rf_vcrim 22,05% - rf_vcact 9,05%
* Otras sospechas de armas (rf_othsw):  Con el 9.92 % de los casos se muestran diferencias en las tasas de arresto. De la misma forma que para otras variables, puede ser debido a que si existe la sospecha de que se esté portando un arma y se confirma, se produce el arresto con mayor probabilidad, 35.56%.

#### Grupo de variables sobre el registro:

|VARIABLE   |DESCRIPTION                                                   |
|-----------|--------------------------------------------------------------|
|searched   |	WAS SUSPECT SEARCHED ?                                     |
|sb_admis   |	BASIS OF SEARCH - ADMISSION BY SUSPECT OF WEAPONS POSSESION|
|sb_hdobj   | 	BASIS OF SEARCH - HARD OBJECT                              |
|sb_outln   |	BASIS OF SEARCH - OUTLINE OF WEAPON                        |
|sb_other   |	BASIS OF SEARCH - OTHER                                    |
|knifcuti   |	WAS A KNIFE OR CUTTING INSTRUMENT FOUND ON SUSPECT ?       |
|pistol	    |	WAS A PISTOL FOUND ON SUSPECT ?                            |
|riflshot   |	WAS A RIFLE FOUND ON SUSPECT ?                             |
|asltweap   |	WAS AN ASSAULT WEAPON FOUND ON SUSPECT ?                   |
|machgun    |	WAS A MACHINE GUN FOUND ON SUSPECT ?                       |
|othrweap   |	WAS ANOTHER TYPE OF WEAPON FOUND ON SUSPECT                |
|contrabn   |	WAS CONTRABAND FOUND ON SUSPECT ?                          |

Respecto a estas variables lo más significativo ha sido:

* Solo el 15.91% de personas paradas fueron registradas (paso posterior al cacheo) por el oficial de policía y más de la mitad fueron arrestadas (53.81%)
* Tan solo en el 0.83% de las ocasiones (380 ocasiones en total) la razón para que el sospechoso fuese registrado o inspeccionado fue las declaraciones del sospechoso, quedando arrestado en el 65.26% de las ocasiones.
* Tan solo en el 0.92% de las ocasiones (419 ocasiones en total) la razón para que el sospechoso fuese registrado o inspeccionado fue que se percibió una silueta de arma en el cacheo. el porcentaje de arrestos aumenta hasta el 50.36% en los casos donde se registra al sospecho porque se aprecia una silueta de arma.
* En el 6.69% el motivo de la busqueda fue un objeto contundente, siendo arrestado el 23,82%. 
* De los sospechos parados tan solo el 2.33% portan un cuchillo o similar pero el porcentaje de arrestos se dispara hasta el 64.14% en caso de ser encontrado un cuchillo. Por lo que se puede concluir que, a priori, éste es un factor relevante a la hora de ser arrestado.
* Un porcentaje bajo de los parados estuvo en posesión de un arma de fuego (0.43%) pero de estos la mayoría fueron arrestados (87.82%).
* De los sospechos parados tan solo el 0.79% portaban otro tipo de arma no catalogada y se aprecia que el porcentaje de arrestos se dispara hasta el 61.71% en caso de ser encontrado un arma de otro tipo no catalogada.
* Si el sospechoso lleva contrabando encima (3.97%), es muy probable que se le arreste (82.52%).

#### Grupo de variables sobre la fuerza física usada por el oficial de policía:

|VARIABLE   |DESCRIPTION                                             |
|-----------|--------------------------------------------------------|
|forceuse   |	REASON FORCE USED                                    | 
|pf_baton   |	PHYSICAL FORCE USED BY OFFICER - BATON               |
|pf_hcuff   |	PHYSICAL FORCE USED BY OFFICER - HANDCUFFS           |
|pf_hands   |	PHYSICAL FORCE USED BY OFFICER - HANDS               |
|pf_other   |	PHYSICAL FORCE USED BY OFFICER - OTHER               |
|pf_pepsp   |	PHYSICAL FORCE USED BY OFFICER - PEPPER SPRAY        |
|pf_wall    |   PHYSICAL FORCE USED BY OFFICER - SUSPECT AGAINST WALL|
|pf_grnd    |   PHYSICAL FORCE USED BY OFFICER - SUSPECT ON GROUND   |
|pf_drwep   |	PHYSICAL FORCE USED BY OFFICER - WEAPON DRAWN        |
|pf_ptwep   |	PHYSICAL FORCE USED BY OFFICER - WEAPON POINTED      |

* Dentro de los casos donde se utilizó la fuerza contra el sospechoso, destacan la defensa propia y la huida del sospecho sobre el resto de razones para usarla (sospechoso con arma, ofrecimiento de resistencia y la defensa de otros). En cuanto a la variable dependiente "arstmade", se aprecia un mayor porcentaje de arrestos en los casos "Ofreció resistencia a la autoridad" (40.25%), "Otros" (39.34%) y "Huida del sospechoso" (24.82%) comparado con el resto de casos, siendo el grupo con menor porcentaje de arrestos el grupo "NA (no se utilizó la fuerza)" (12.28%).
* El oficial de policía tuvo que utilizar la porra contra el sospecho tan solo en el 0.02% de las ocasiones (10 ocasiones en total). Por lo que, se puede concluir que es un tipo de defensa muy poco usada por los oficiales de policía que en caso de tener que utilizar la fuerza optan por otro tipo de armas antes que por ésta.
* El oficial necesita recurrir a algún tipo de fuerza física como uso de esposas en 10 de cada 100 casos, de las cuales son arrestadas el 50%.
* Tan sólo el 15,74% uso las manos como fuerza, arrestando en estos casos al 16,49%.
* Sospechoso contra la pared (4.48%), siendo arrestados (16.49%)
* Se muestra una tasa de arrestos mayor (42.12%) para los casos en los que se reduce al sospechoso en el suelo, cosa que ocurre el 0.93%.
* Tan solo el policía tuvo que desenfundar su arma el 0,98%, arrestando al sospechoso el 20.04% de las ocasiones.
* El oficial de policía tuvo que apuntar con su arma al sospecho parado tan solo el 0.73% (332 de las ocasiones) y se aprecia que el porcentaje de arrestos aumenta hasta el 23.49% cuando el oficial de policía tuvo que apuntar con su arma al sospecho siendo el 14.94% cuando no ocurrió esto último. Por lo que se puede concluir que, a priori, éste puede ser un factor relevante a la hora de ser arrestado aunque no lo es tanto como sucede en otras variables.
* El gas pimienta fue usado en tan solo  el 0.02% pero de estos el 63.64% fueron detenidos.

#### Grupo de variables sobre otras circunstancias de la parada:

|VARIABLE   |DESCRIPTION                                                        |
|-----------|-------------------------------------------------------------------|
|othpers    |	WERE OTHER PERSONS STOPPED, QUESTIONED OR FRISKED ?             |
|offunif    |	WAS OFFICER IN UNIFORM ?                                        |
|offverb    |	VERBAL STATEMENT PROVIDED BY OFFICER (IF NOT IN UNIFORM)        |
|offshld    |	SHIELD PROVIDED BY OFFICER (IF NOT IN UNIFORM)                  |
|officrid   |	ID CARD PROVIDED BY OFFICER (IF NOT IN UNIFORM)                 |
|ac_rept    |	ADDITIONAL CIRCUMSTANCES - REPORT BY VICTIM/WITNESS/OFFICER     |
|ac_incid   |	ADDITIONAL CIRCUMSTANCES - AREA HAS HIGH CRIME INCIDENCE        |
|ac_time    |   ADDITIONAL CIRCUMSTANCES - TIME OF DAY FITS CRIME INCIDENCE     |
|ac_assoc   |	ADDITIONAL CIRCUMSTANCES - ASSOCIATING WITH KNOWN CRIMINALS     |
|ac_proxm   |	ADDITIONAL CIRCUMSTANCES - PROXIMITY TO SCENE OF OFFENSE        |
|ac_evasv   |	ADDITIONAL CIRCUMSTANCES - EVASIVE RESPONSE TO QUESTIONING      |
|ac_cgdir   |	ADDITIONAL CIRCUMSTANCES - CHANGE DIRECTION AT SIGHT OF OFFICER |
|ac_inves   |	ADDITIONAL CIRCUMSTANCES - ONGOING INVESTIGATION                |
|ac_stsnd   | 	ADDITIONAL CIRCUMSTANCES - SIGHTS OR SOUNDS OF CRIMINAL ACTIVITY|
|ac_other   |	ADDITIONAL CIRCUMSTANCES – OTHER                                |

* En el 25% de los casos se paran, interrogan o cachean a más de una persona, pero los procentajes de arrestos son practicamente iguales o ligeramente inferior que cuando se para a una sola. 
* En el 54% el policía iba uniformado, siendo ligeramente superior la tasa de arrestos en estos casos 17.39% frente al 12.31%.
* Las paradas efectuadas en circunstancias como: la declaración de una víctima o la proximidad a la escena de un delito no superan el 30% y del total de estos el 17% son arrestados.
* El resto de circunstancias adicionales no presentan tasas de arresto muy diferentes a la media. 

## 3.3 Transformación de variables

Se genera un dataset a partir de diversas transformaciones aplicadas a las variables del dataset original. Se busca seleccionar las variables y las observaciones que puedan aportar información a los modelos y eliminar todos aquellos casos que no permitan trabajar con ellos.

### 3.3.1 Creación de dataset transformado

```{r}
SQFdata_modif <- SQFdata
```

### 3.3.2 Eliminación de variables

En las tablas obtenidas en el segundo apartado del presente documento se puede obtener información sobre qué variables sería interesante eliminar del dataset teniendo en cuenta distintos aspectos:

* Porcentaje de datos faltantes.
* Casos con varianza nula o casi nula.
* Factores con demasiados niveles.
* Otros aspectos.

```{r}
#
# Eliminación de variables con más de ~60% de datos faltantes.
#
perc_NA <- function(x) {
    perc <- sum(is.na(x))*100/length(x)
    paste(perc,"%")
}

perc_NA(SQFdata_modif$arstoffn);perc_NA(SQFdata_modif$sumoffen);perc_NA(SQFdata_modif$officrid)
perc_NA(SQFdata_modif$offverb);perc_NA(SQFdata_modif$offshld);perc_NA(SQFdata_modif$forceuse)
perc_NA(SQFdata_modif$othfeatr);perc_NA(SQFdata_modif$addrnum);perc_NA(SQFdata_modif$stname)
perc_NA(SQFdata_modif$beat);perc_NA(SQFdata_modif$post);perc_NA(SQFdata_modif$state)
perc_NA(SQFdata_modif$zip);perc_NA(SQFdata_modif$rescode);perc_NA(SQFdata_modif$premtype)
perc_NA(SQFdata_modif$aptnum);

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(arstoffn, sumoffen, officrid, offverb, offshld,
                              forceuse, othfeatr, addrnum, stname, beat,
                              post, state, zip, rescode, premtype, aptnum))


#
# Eliminación de variables con poca o nula varianza (casos pertenecientes
# todos a una misma clase). 7 variables eliminadas
#
summary(SQFdata_modif$adtlrept);summary(SQFdata_modif$riflshot);
summary(SQFdata_modif$asltweap);summary(SQFdata_modif$machgun);
summary(SQFdata_modif$pf_baton);summary(SQFdata_modif$pf_pepsp)
summary(SQFdata_modif$addrtyp);summary(SQFdata_modif$year);
summary(SQFdata_modif$compyear);summary(SQFdata_modif$comppct);
summary(SQFdata_modif$lineCM);summary(SQFdata_modif$dob);
summary(SQFdata_modif$dettypCM)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(adtlrept, riflshot, asltweap, machgun,
                             pf_baton, pf_pepsp, addrtyp, year,
                             compyear, comppct, lineCM, dob, dettypCM))



# 
# Eliminación de variables con demasiados niveles (strings). 8 variables eliminadas
# 
length(levels(SQFdata_modif$premname));length(levels(SQFdata_modif$stinter))
length(levels(SQFdata_modif$crossst));length(levels(SQFdata_modif$sector))
length(levels(SQFdata_modif$pct));length(levels(SQFdata_modif$crimsusp))
length(levels(SQFdata_modif$addrpct));length(levels(SQFdata_modif$detailCM))

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(premname, stinter, crossst, sector,
                              pct, crimsusp, addrpct, detailCM))

# 
# Variables asociadas a series temporales o coordenadas -> No son de interés para
# el problema que ocupa
# 
SQFdata_modif <- SQFdata_modif %>%
                    select(-c(datestop, timestop, xcoord, ycoord))



# 
# Número de variables final
# 
dim(SQFdata)
dim(SQFdata_modif)
```

### 3.3.3 Tratamiento de NAs

Nos encontramos ante dos casos distintos de NAs después de haber realizado la eliminación previa de variables:

* Variable *age*: Presenta 212 casos sin valor frente a los 45.787 totales disponibles en el dataset original. Dado que se trata de un porcentaje ínfimo de casos, se opta por eliminarlos del conjunto de datos.
    
* Variables asociadas a distintos aspectos de la dentención (armas, fuerza física, circunstancias adicionales, etc): Se consideran dichas variables como información complementaria a la detención. De esta forma se asume que, en aquellos casos donde no existe información sobre la variable, o bien el agente no ha rellenado la casilla o ha rellenado alguna de las otras clases de la variable. Por tanto, se asigna a todas esas observaciones el nivel NO. Esta decisión permitirá volver a eliminar variables que presenten varianza casi nula.


```{r}
# 
# Eliminación de NAs en variable age
#
SQFdata_modif %>% group_by(is.na(age)) %>%
    summarise(n())

SQFdata_modif <- SQFdata_modif %>% filter(!is.na(age))



# 
# Modificación de variables no eliminadas
# 

# Uso de armas
summary(SQFdata_modif$pistol);summary(SQFdata_modif$knifcuti);
summary(SQFdata_modif$othrweap);

SQFdata_modif$pistol[which(is.na(SQFdata_modif$pistol))]     <- 'N'
SQFdata_modif$knifcuti[which(is.na(SQFdata_modif$knifcuti))] <- 'N'
SQFdata_modif$othrweap[which(is.na(SQFdata_modif$othrweap))] <- 'N'

# Uso de fuerza física
summary(SQFdata_modif$pf_hands);summary(SQFdata_modif$pf_wall);
summary(SQFdata_modif$pf_grnd);summary(SQFdata_modif$pf_drwep);
summary(SQFdata_modif$pf_ptwep);summary(SQFdata_modif$pf_hcuff);
summary(SQFdata_modif$pf_other);

SQFdata_modif$pf_hands[which(is.na(SQFdata_modif$pf_hands))] <- 'N'
SQFdata_modif$pf_wall[which(is.na(SQFdata_modif$pf_wall))]   <- 'N'
SQFdata_modif$pf_grnd[which(is.na(SQFdata_modif$pf_grnd))]   <- 'N'
SQFdata_modif$pf_drwep[which(is.na(SQFdata_modif$pf_drwep))] <- 'N'
SQFdata_modif$pf_ptwep[which(is.na(SQFdata_modif$pf_ptwep))] <- 'N'
SQFdata_modif$pf_hcuff[which(is.na(SQFdata_modif$pf_hcuff))] <- 'N'
SQFdata_modif$pf_other[which(is.na(SQFdata_modif$pf_other))] <- 'N'

# Circunstancias adicionales
summary(SQFdata_modif$ac_rept);summary(SQFdata_modif$ac_inves);
summary(SQFdata_modif$ac_proxm);summary(SQFdata_modif$ac_evasv);
summary(SQFdata_modif$ac_assoc);summary(SQFdata_modif$ac_cgdir);
summary(SQFdata_modif$ac_incid);summary(SQFdata_modif$ac_time);
summary(SQFdata_modif$ac_stsnd);summary(SQFdata_modif$ac_other);

SQFdata_modif$ac_rept[which(is.na(SQFdata_modif$ac_rept))]   <- 'N'
SQFdata_modif$ac_inves[which(is.na(SQFdata_modif$ac_inves))] <- 'N'
SQFdata_modif$ac_proxm[which(is.na(SQFdata_modif$ac_proxm))] <- 'N'
SQFdata_modif$ac_incid[which(is.na(SQFdata_modif$ac_incid))] <- 'N'
SQFdata_modif$ac_time[which(is.na(SQFdata_modif$ac_time))]   <- 'N'
SQFdata_modif$ac_evasv[which(is.na(SQFdata_modif$ac_evasv))] <- 'N'
SQFdata_modif$ac_assoc[which(is.na(SQFdata_modif$ac_assoc))] <- 'N'
SQFdata_modif$ac_cgdir[which(is.na(SQFdata_modif$ac_cgdir))] <- 'N'
SQFdata_modif$ac_stsnd[which(is.na(SQFdata_modif$ac_stsnd))] <- 'N'
SQFdata_modif$ac_other[which(is.na(SQFdata_modif$ac_other))] <- 'N'

# Razones para el cacheo
summary(SQFdata_modif$rf_vcrim);summary(SQFdata_modif$rf_othsw);
summary(SQFdata_modif$rf_attir);summary(SQFdata_modif$rf_vcact);
summary(SQFdata_modif$rf_rfcmp);summary(SQFdata_modif$rf_verbl);
summary(SQFdata_modif$rf_knowl);summary(SQFdata_modif$rf_furt);
summary(SQFdata_modif$rf_bulg);

SQFdata_modif$rf_vcrim[which(is.na(SQFdata_modif$rf_vcrim))] <- 'N'
SQFdata_modif$rf_othsw[which(is.na(SQFdata_modif$rf_othsw))] <- 'N'
SQFdata_modif$rf_attir[which(is.na(SQFdata_modif$rf_attir))] <- 'N'
SQFdata_modif$rf_vcact[which(is.na(SQFdata_modif$rf_vcact))] <- 'N'
SQFdata_modif$rf_rfcmp[which(is.na(SQFdata_modif$rf_rfcmp))] <- 'N'
SQFdata_modif$rf_furt[which(is.na(SQFdata_modif$rf_furt))]   <- 'N'
SQFdata_modif$rf_bulg[which(is.na(SQFdata_modif$rf_bulg))]   <- 'N'
SQFdata_modif$rf_verbl[which(is.na(SQFdata_modif$rf_verbl))] <- 'N'
SQFdata_modif$rf_knowl[which(is.na(SQFdata_modif$rf_knowl))] <- 'N'

# Razones para la detención
summary(SQFdata_modif$cs_objcs);summary(SQFdata_modif$cs_descr);
summary(SQFdata_modif$cs_casng);summary(SQFdata_modif$cs_lkout);
summary(SQFdata_modif$cs_cloth);summary(SQFdata_modif$cs_drgtr);
summary(SQFdata_modif$cs_furtv);summary(SQFdata_modif$cs_vcrim);
summary(SQFdata_modif$cs_bulge);summary(SQFdata_modif$cs_other);

SQFdata_modif$cs_objcs[which(is.na(SQFdata_modif$cs_objcs))] <- 'N'
SQFdata_modif$cs_descr[which(is.na(SQFdata_modif$cs_descr))] <- 'N'
SQFdata_modif$cs_casng[which(is.na(SQFdata_modif$cs_casng))] <- 'N'
SQFdata_modif$cs_lkout[which(is.na(SQFdata_modif$cs_lkout))] <- 'N'
SQFdata_modif$cs_cloth[which(is.na(SQFdata_modif$cs_cloth))] <- 'N'
SQFdata_modif$cs_drgtr[which(is.na(SQFdata_modif$cs_drgtr))] <- 'N'
SQFdata_modif$cs_furtv[which(is.na(SQFdata_modif$cs_furtv))] <- 'N'
SQFdata_modif$cs_vcrim[which(is.na(SQFdata_modif$cs_vcrim))] <- 'N'
SQFdata_modif$cs_bulge[which(is.na(SQFdata_modif$cs_bulge))] <- 'N'
SQFdata_modif$cs_other[which(is.na(SQFdata_modif$cs_other))] <- 'N'

# Motivos de búsqueda
summary(SQFdata_modif$sb_hdobj);summary(SQFdata_modif$sb_outln);
summary(SQFdata_modif$sb_admis);summary(SQFdata_modif$sb_other);

SQFdata_modif$sb_hdobj[which(is.na(SQFdata_modif$sb_hdobj))] <- 'N'
SQFdata_modif$sb_outln[which(is.na(SQFdata_modif$sb_outln))] <- 'N'
SQFdata_modif$sb_admis[which(is.na(SQFdata_modif$sb_admis))] <- 'N'
SQFdata_modif$sb_other[which(is.na(SQFdata_modif$sb_other))] <- 'N'

# Comprobación de NAs
sum(is.na(SQFdata))
sum(is.na(SQFdata_modif))
```

### 3.3.4 Eliminación de variables con varianza nula

```{r}
# 
# Con caret::nearZeroVar se elimina el resto de variables que presentan varianza
# nula después de aplicar la imputación de NAs
#
sapply(SQFdata_modif[nearZeroVar(SQFdata_modif)], summary)

SQFdata_modif <- SQFdata_modif[-nearZeroVar(SQFdata_modif)]

dim(SQFdata)
dim(SQFdata_modif)
```



## 3.4 Creación de conjuntos de *train* y *test*

Tras haber realizado las transformaciones necesarias a las variables, se crean los conjuntos de *train* y *test* a partir del dataset modificado. Tras crear los conjuntos se comprueba la proporción de clases que existe en la variable objetivo.

```{r}
# 
# Creación de conjuntos train y test
# 
tot_obs <- dim(SQFdata_modif)[1]
indices <- 1:tot_obs

set.seed(1234)
indices_train <- sample(indices, 0.7*tot_obs)
SQFdataTrain = SQFdata_modif[indices_train, ]
SQFdataTest = SQFdata_modif[-indices_train, ]



# Datos desbalanceados
SQFdataTrain %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### 3.4.1 Ajuste del desbalanceo: Down-Sampling

Tal y como se puede observar en la tabla anterior, de los casos seleccionados para el conjunto de train, el caso positivo o arresto de la persona detenida corresponde únicamente a un 15\% de ellos. Al disponer de un número tan reducido en nuestro conjunto de train, el modelo tenderá a predecir más casos negativos que positivos, lo que supone dejar marchar a personas que deberían ser arrestadas.

Esta situación, conocida como clases desbalanceadas, es muy típica en problemas de clasificación binaria. Para tratar de resolver este problema se pueden adoptar diferentes medidas:

* Conseguir más datos.
* Remuestreo del conjunto de train con diferentes técnicas: Up-Sampling, Down-Sampling, SMOTE, etc.
* Uso de modelos con peso.

En la realización del presente trabajo se han empleado las técnicas de remuestreo expuestas. Únicamente se muestran los resultados obtenidos tras emplear Down-Sampling dado que el resto de técnicas suponían mejoras menores, lo cual es lógico teniendo en cuenta que el dataset original cuenta con un total de 45.787 observaciones y por tanto es posible eliminar observaciones sin arriesgarse a perser demasiada información para generar los modelos.

Cabe destacar que, a pesar de mejorar en la predicción de los casos positivos, también conlleva desventajas frente al dataset desbalanceado. De las métricas empleadas para evaluar los modelos, la técnica de Down-Sampling mejora el *sensitivity* del modelo pero empeora su *precision*. Dichas métricas se corresponden con:
    
* ***Sensitivity***: Tasa de arrestos reales predichos como tal.

$$\text{Sensitivity}=\frac{TP}{TP+FN}$$

* ***Precision***: Tasa de acierto en la predicción de arrestos.

$$\text{Precision}=\frac{TP}{TP+FP}$$

Siendo $TP=\text{True Positive}$ y $FN=\text{False Negative}$.

La mejora en la predicción de casos positivos se basa en el incremento de las predicciones para dicha clase a costa de una reducción en la contraria. Esto conlleva un menor número de $FN$ y un mayor número de $TP$ en la matriz de confusión, pero también un mayor número de $FP$.

Analizando las dos situaciones, el hecho de que el modelo empeore su *precision* supone arrestar a gente que no debería ser arrestada. Por el contrario, que mejore su *sensitivity* implica reducir el número de sospechosos que deberían ser arrestados y sin embargo se les permite marchar.

Dado que se considera más perjudicial para la ciudad el hecho de dejar marchar a un sospechoso que debiera ser arrestado, se opta finalmente por las soluciones aportadas por la ténica Down-Sampling.

$$"All\ models\ are\ wrong,\ but\ some\ are\ useful"$$


```{r}
# 
# Total de casos -> 4799 (SI) + 27103 (NO) = 32050
# Queremos que los SI correspondan a un 50% de la muestra -> Los NO deberían ser 4799 casos
# 
training.yes <- SQFdataTrain %>% filter(arstmade == 'Y')
training.no <- SQFdataTrain %>% filter(arstmade == 'N')

set.seed(4567)
ind_training.no <- sample(rownames(training.no),4799)
training.no <- training.no[ind_training.no,]

SQFdataTrain_DSAMP <- rbind(training.yes, training.no)

SQFdataTrain_DSAMP %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

\newpage

# 4. MODELADO
## 4.0 Clustering

La estrategia será la separación del conjunto completo en distintos clústeres para poder aplicar a cada grupo de datos el modelo más adecuado.

### 4.0.1 Dummificación y escalado de variables

De forma previa a la aplicación de la técnica de clustering escogida, es necesario crear variables dummies a partir de las categóricas y escalar las numéricas para poder emplear la distancia euclídea.

#### 4.0.1.1 Almacenamiento de labels

```{r}
labels <- SQFdata_modif$arstmade
SQFdata_modif <- SQFdata_modif %>% select(-arstmade)
```

#### 4.0.1.2 Dummificacion de variables

```{r}
# Dummificación de variables de tipo Y|N
YesNoCat <- sapply(SQFdata_modif,
                   function(x) (ifelse(is.factor(x),
                                       (levels(x) == c("Y","N") || (levels(x) == c("N","Y"))),
                                       FALSE)))

SQFdata_modif[YesNoCat] <- sapply(SQFdata_modif[YesNoCat], function(x) ifelse(x=="Y",1,0))

sapply(SQFdata_modif[which(names(SQFdata_modif) %>% 
                               is_in(names(YesNoCat[YesNoCat == FALSE])))], levels)


# Dummificación de recstat (Ni idea de que es...)
SQFdata_modif %>% group_by(recstat) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$recstat <- ifelse(SQFdata_modif$recstat=="1",1,0)


# Dummificación de inout
SQFdata_modif %>% group_by(inout) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$inout <- ifelse(SQFdata_modif$inout=="Inside",1,0)


# Dummificación de trhsloc
SQFdata_modif %>% group_by(trhsloc) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$trhsloc.Housing <- ifelse(SQFdata_modif$trhsloc=="Housing",1,0)
SQFdata_modif$trhsloc.Transit <- ifelse(SQFdata_modif$trhsloc=="Transit",1,0)

SQFdata_modif <- SQFdata_modif %>%
    select(-trhsloc)


# Dummificación de typeofid
SQFdata_modif %>% group_by(typeofid) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$typeofid.Other <- ifelse(SQFdata_modif$typeofid=="Other",1,0)
SQFdata_modif$typeofid.Refused <- ifelse(SQFdata_modif$typeofid=="Refused",1,0)
SQFdata_modif$typeofid.Verbal <- ifelse(SQFdata_modif$typeofid=="Verbal",1,0)

SQFdata_modif <- SQFdata_modif %>%
    select(-typeofid)


# Dummificación de sexo
SQFdata_modif %>% group_by(sex) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$sex.Male <- ifelse(SQFdata_modif$sex=="Male",1,0)
SQFdata_modif$sex.Female <- ifelse(SQFdata_modif$sex=="Female",1,0)

SQFdata_modif <- SQFdata_modif %>% 
    select(-sex)


# Dummificación de raza
SQFdata_modif %>% group_by(race) %>%
    summarise(count = n()) %>%
    mutate(perc = count/sum(count))

SQFdata_modif$race.ASIAN <- ifelse(SQFdata_modif$race=="ASIAN/PACIFIC ISLANDER",1,0)
SQFdata_modif$race.NATIVE <- ifelse(SQFdata_modif$race=="AMERICAN INDIAN/ALASKAN NATIVE",1,0)
SQFdata_modif$race.B_HISP <- ifelse(SQFdata_modif$race=="BLACK-HISPANIC",1,0)
SQFdata_modif$race.W_HISP <- ifelse(SQFdata_modif$race=="WHITE-HISPANIC",1,0)
SQFdata_modif$race.WHITE <- ifelse(SQFdata_modif$race=="WHITE",1,0)
SQFdata_modif$race.OTHER <- ifelse(SQFdata_modif$race=="OTHER",1,0)
SQFdata_modif$race.UNKNOWN <- ifelse(SQFdata_modif$race=="UNKNOWN",1,0)

SQFdata_modif <- SQFdata_modif %>%
    select(-race)

# Dummificación de haircolor
SQFdata_modif %>% group_by(haircolr) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$haircolr.Bald <- ifelse(SQFdata_modif$haircolr=="Bald",1,0)
SQFdata_modif$haircolr.Black <- ifelse(SQFdata_modif$haircolr=="Black",1,0)
SQFdata_modif$haircolr.Blond <- ifelse(SQFdata_modif$haircolr=="Blond",1,0)
SQFdata_modif$haircolr.Brown <- ifelse(SQFdata_modif$haircolr=="Brown",1,0)
SQFdata_modif$haircolr.Dyed <- ifelse(SQFdata_modif$haircolr=="Dyed",1,0)
SQFdata_modif$haircolr.Gray <- ifelse(SQFdata_modif$haircolr=="Gray",1,0)
SQFdata_modif$haircolr.Red <- ifelse(SQFdata_modif$haircolr=="Red",1,0)
SQFdata_modif$haircolr.Sandy <- ifelse(SQFdata_modif$haircolr=="Sandy",1,0)
SQFdata_modif$haircolr.SaltPepper <- ifelse(SQFdata_modif$haircolr=="Salt and pepper",1,0)
SQFdata_modif$haircolr.Unknown <- ifelse(SQFdata_modif$haircolr=="Unknown",1,0)

SQFdata_modif <- SQFdata_modif %>% 
    select(-haircolr)

# Dummificación de eyecolor
SQFdata_modif %>% group_by(eyecolor) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$eyecolor.Black <- ifelse(SQFdata_modif$eyecolor=="Black",1,0)
SQFdata_modif$eyecolor.Blue <- ifelse(SQFdata_modif$eyecolor=="Blue",1,0)
SQFdata_modif$eyecolor.Brown <- ifelse(SQFdata_modif$eyecolor=="Brown",1,0)
SQFdata_modif$eyecolor.Two <- ifelse(SQFdata_modif$eyecolor=="Two different",1,0)
SQFdata_modif$eyecolor.Green <- ifelse(SQFdata_modif$eyecolor=="Green",1,0)
SQFdata_modif$eyecolor.Gray <- ifelse(SQFdata_modif$eyecolor=="Gray",1,0)
SQFdata_modif$eyecolor.Hazel <- ifelse(SQFdata_modif$eyecolor=="Hazel",1,0)
SQFdata_modif$eyecolor.Maroon <- ifelse(SQFdata_modif$eyecolor=="Maroon",1,0)
SQFdata_modif$eyecolor.MC <- ifelse(SQFdata_modif$eyecolor=="MC",1,0)
SQFdata_modif$eyecolor.Pink <- ifelse(SQFdata_modif$eyecolor=="Pink",1,0)
SQFdata_modif$eyecolor.Violet <- ifelse(SQFdata_modif$eyecolor=="Violet",1,0)
SQFdata_modif$eyecolor.Unknown <- ifelse(SQFdata_modif$eyecolor=="Unknown",1,0)

SQFdata_modif <- SQFdata_modif %>% 
    select(-eyecolor)


# Dummificación de build
SQFdata_modif %>% group_by(build) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$build.Heavy <- ifelse(SQFdata_modif$build=="Heavy",1,0)
SQFdata_modif$build.Thin <- ifelse(SQFdata_modif$build=="Thin",1,0)
SQFdata_modif$build.Muscular <- ifelse(SQFdata_modif$build=="Muscular",1,0)
SQFdata_modif$build.Unknown <- ifelse(SQFdata_modif$build=="Unknown",1,0)

SQFdata_modif <- SQFdata_modif %>%
    select(-build)

# Dummificación de city
SQFdata_modif %>% group_by(city) %>%
    summarise(count = n()) %>%
    mutate(perc = count*100/sum(count))

SQFdata_modif$city.BRONX <- ifelse(SQFdata_modif$city=="BRONX",1,0)
SQFdata_modif$city.MANHATTAN <- ifelse(SQFdata_modif$city=="MANHATTAN",1,0)
SQFdata_modif$city.QUEENS <- ifelse(SQFdata_modif$city=="QUEENS",1,0)
SQFdata_modif$city.S_ISLAND <- ifelse(SQFdata_modif$city=="STATEN ISLAND",1,0)

SQFdata_modif <- SQFdata_modif %>%
    select(-city)


# Comprobacion -> Todas las variables son numeric
dim(SQFdata_modif)
dim(SQFdata_modif[which(sapply(SQFdata_modif,is.numeric))])

str(SQFdata_modif)
```

#### 4.0.1.3 Escalado de variables

```{r}
VarEscalar <- colnames(SQFdata_modif[sapply(SQFdata_modif,
                                            function(x) (min(x)!=0) || (max(x)!=1))])

summary(SQFdata_modif[VarEscalar])

escalado <- function(z) {
    min_z <- min(z)
    max_z <- max(z)
    z <- sapply(z, function(x) (x-min_z)/(max_z-min_z))    
    return(z)
}

SQFdata_modif[VarEscalar] <- sapply(SQFdata_modif[VarEscalar], escalado)
str(SQFdata_modif)
dim(SQFdata_modif)

SQFdata_modif$arstmade <- labels
```

#### 4.0.1.4 Creación de conjuntos de *train* y *test*

```{r}
# 
# Creación de conjuntos train y test
# 
tot_obs <- dim(SQFdata_modif)[1]
indices <- 1:tot_obs

set.seed(1234)
indices_train <- sample(indices, 0.7*tot_obs)
SQFdataTrain = SQFdata_modif[indices_train, ]
SQFdataTest = SQFdata_modif[-indices_train, ]

# Datos desbalanceados
SQFdataTrain %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### 4.0.3 Clustering

#### 4.0.3.1 Selección del número óptimo de clusters

```{r, warning=FALSE}
k_kmeans <- FitKMeans(SQFdataTrain[which(names(SQFdataTrain)!="arstmade")],
                      max.clusters = 15, nstart = 20, seed = 123)
k_kmeans

PlotHartigan(k_kmeans)
```

#### 4.0.3.2 Creación de clusters

```{r}
set.seed(123)
cl_kmeans <- kmeans(x = SQFdataTrain[which(names(SQFdataTrain)!="arstmade")],
                    centers = 6)

SQFdataTrain$cluster <- cl_kmeans$cluster
```

#### 4.0.3.3 Análisis de resultados por clúster

```{r}
dim(SQFdata_modif)
dim(SQFdataTrain)
```

```{r}
SQFdataTrain %>% group_by(cluster, arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos/(dim(SQFdataTrain)[1])*100, 2))
```

#### 4.0.3.4 Separación en conjuntos por clúster para train de modelos

```{r}
SQFdataTrain.cl.1 <- SQFdataTrain %>% filter(cluster == 1)
SQFdataTrain.cl.2 <- SQFdataTrain %>% filter(cluster == 2)
SQFdataTrain.cl.3 <- SQFdataTrain %>% filter(cluster == 3)
SQFdataTrain.cl.4 <- SQFdataTrain %>% filter(cluster == 4)
SQFdataTrain.cl.5 <- SQFdataTrain %>% filter(cluster == 5)
SQFdataTrain.cl.6 <- SQFdataTrain %>% filter(cluster == 6)

dim(SQFdataTrain)[1]
dim(SQFdataTrain.cl.1)[1] + dim(SQFdataTrain.cl.2)[1] + dim(SQFdataTrain.cl.3)[1] + dim(SQFdataTrain.cl.4)[1] + dim(SQFdataTrain.cl.5)[1] + dim(SQFdataTrain.cl.6)[1]

SQFdataTrain.cl.1 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = paste(round(Casos/sum(Casos)*100,2), "%"))

SQFdataTrain.cl.2 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = paste(round(Casos/sum(Casos)*100,2), "%"))

SQFdataTrain.cl.3 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(Porcentaje_clase = paste(round(Casos/sum(Casos)*100,2), "%"))

SQFdataTrain.cl.4 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(Porcentaje_clase = paste(round(Casos/sum(Casos)*100,2), "%"))

SQFdataTrain.cl.5 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(Porcentaje_clase = paste(round(Casos/sum(Casos)*100,2), "%"))

SQFdataTrain.cl.6 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = paste(round(Casos/sum(Casos)*100,2), "%"))
```

### 4.0.4 Knn para muestras de test

#### 4.0.4.1 Agrupación según k vecinos más próximos

```{r}
knn_test <- knn3(cluster ~ ., data = SQFdataTrain, k = 10, prob = FALSE)

prediction <- predict(knn_test, SQFdataTest, type = "prob")

class_predict <- function(x) names(x[which.max(x)])

clases <- list()

for(i in seq(dim(prediction)[1])){
    cat(i, "\n")
    clase <- names(prediction[i,])[which.max(prediction[i,])]
    clases[i] <- clase
}

clases <- factor(clases, levels = c(1,2,3,4,5,6))

SQFdataTest$cluster <- clases

SQFdataTest %>% 
    group_by(cluster) %>% 
    summarise(Casos = n())
```

#### 4.0.4.2 Separación de datasets de test

```{r}
SQFdataTest.cl.1 <- SQFdataTest %>% filter(cluster == 1)
SQFdataTest.cl.2 <- SQFdataTest %>% filter(cluster == 2)
SQFdataTest.cl.3 <- SQFdataTest %>% filter(cluster == 3)
SQFdataTest.cl.4 <- SQFdataTest %>% filter(cluster == 4)
SQFdataTest.cl.5 <- SQFdataTest %>% filter(cluster == 5)
SQFdataTest.cl.6 <- SQFdataTest %>% filter(cluster == 6)

dim(SQFdataTest)[1]
dim(SQFdataTest.cl.1)[1] + dim(SQFdataTest.cl.2)[1] + dim(SQFdataTest.cl.3)[1] + dim(SQFdataTest.cl.4)[1] + dim(SQFdataTest.cl.5)[1] + dim(SQFdataTest.cl.6)[1]

SQFdataTest.cl.1 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos*100/dim(SQFdataTest)[1],2))

SQFdataTest.cl.2 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos*100/dim(SQFdataTest)[1],2))

SQFdataTest.cl.3 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos*100/dim(SQFdataTest)[1],2))

SQFdataTest.cl.4 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos*100/dim(SQFdataTest)[1],2))

SQFdataTest.cl.5 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos*100/dim(SQFdataTest)[1],2))

SQFdataTest.cl.6 %>% group_by(arstmade) %>% 
    summarise(Casos = n()) %>% 
    mutate(percent_class = round(Casos/sum(Casos)*100,2),
           percent_tot = round(Casos*100/dim(SQFdataTest)[1],2))
```



## 4.1 Regresión logística

Para encontrar los determinantes de que una persona parada sea arrestada o no, utilizamos los modelos lineales generalizados, y dado que la variable respuesta, toma valores N (no fueron arrestados) o Y (sí fueron arrestados), utilizamos la función de enlace logit. Este modelo es de la familia binomial.

Hipótesis

1.	Los casos son independientes entre sí.
2.	La probabilidad de éxito es la misma para todos los casos que tienen los mismos valores de los regresores.

### 4.1.1 Creación de modelos vacío y completo

```{r}
# Creación de modelo vacío
model_glm_DSAMP_Vacio <- glm(arstmade ~ 1, data = SQFdataTrain_DSAMP, family = "binomial")

# Creación de modelo completo
model_glm_DSAMP <- glm(arstmade ~ ., data = SQFdataTrain_DSAMP, family = "binomial")
```

### 4.1.2 Selección de modelos mediante stepwise

```{r}
# Stepwise modelo con Down-Sampling
model_glm_DSAMP_Forw <- step(model_glm_DSAMP_Vacio,
                       scope = list(lower = formula(model_glm_DSAMP_Vacio),
                                    upper = formula(model_glm_DSAMP)),
                       direction = "forward", trace = 0)
summary(model_glm_DSAMP_Forw)
```

### 4.1.3 Prueba Likelihood ratio

Dado que la hipótesis nula sostiene que el modelo reducido es el mejor, un valor del p-value para el modelo estadístico mayor que 0,05 nos obliga a aceptar la hipótesis nula, es decir, proporciona evidencia a favor del modelo reducido. Además se puede verificar, según el criterio AIC, el modelo balanceado y construido en base a stepwise es el mejor. 

```{r, warming = FALSE, message=FALSE}
anova(model_glm_DSAMP, model_glm_DSAMP_Forw,  test="Chisq")
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic)
```

### 4.1.4 Evaluación de los parámetros del modelo seleccionado

Como la respuesta es binaria, la función de salida es la probabilidad condicionada de que la respuesta sea un acierto dado los valores de los predictores. Los betas estimados son los log- odds, donde la probabilidad (odds) de que el suceso ocurra se da como la probabilidad de acierto dividido por la probabilidad de fallo.
En cuanto a la interpretación de los parámetros estimados del modelo *model_glm_DSAMP_Forw*, el signo de los mismos indica que ese predictor aumenta o disminuye la probabilidad de que una persona sea arrestada y para evaluar la magnitud de la variación se calculó el exponencial de cada beta. Así se puede determinar por ejemplo: si aumenta  una unidad en la edad, la probabilidad de ser arrestado  se incrementa en un factor de 1,01

```{r warning=FALSE}
round(exp(cbind(Estimate=coef(model_glm_DSAMP_Forw),
                confint(model_glm_DSAMP_Forw))), 2)
```

### 4.1.5 Pseudo R^2

Evaluamos el R cuadrado de McFadden mientras más cercano a uno indica que el modelo tiene poder predictivo, es este caso el valor es de 0.587.

```{r, warming = FALSE}
pR2(model_glm_DSAMP_Forw)
```

### 4.1.6 Importancia de la variable

Si bien el método stepwise selecciona el modelo por criterio AIC, es necesario verificar si al eliminar una variable que no es significativa afecta mucho al modelo, en este caso se valora la opción de eliminar la variable *haircolr*, dado que según el estadístico de Wald a un nivel de significancia de *0.05*, está en el umbral de no rechazar la hipótesis nula de que el coeficiente de una variable independiente en el modelo no es significativamente diferente de cero. Se evalúa un nuevo modelo eliminando esta variable y a priori observando el criterio AIC, no causa un gran efecto en el modelo. Esto se comprueba al analizar tabla *anova* en la que se demuestra que no hay suficiente evidencia para rechazar Ho. 

El análisis se repite para la variable *race*, dado que es un factor, a priori, relacionado con la controversia que ampara esta ley. Después de evaluar los estadísticos vemos que hay suficiente evidencia para considerar importante la variable dentro del modelo.

```{r, warming = FALSE}
# Eliminar haircolr
regTermTest(model_glm_DSAMP_Forw, "haircolr")
model_glm_DSAMP_hair<- glm(arstmade ~ .-haircolr, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_DSAMP_hair_back<-step(model_glm_DSAMP_hair, direction = "backward", trace = 0)
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic, model_glm_DSAMP_hair_back$aic)
anova(model_glm_DSAMP_hair_back, model_glm_DSAMP_Forw,  test="Chisq")

# Eliminar race
regTermTest(model_glm_DSAMP_Forw, "race")
model_glm_DSAMP_race<- glm(arstmade ~ .-race, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_DSAMP_race_back<-step(model_glm_DSAMP_race, direction = "backward", trace = 0)

c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic,
  model_glm_DSAMP_hair_back$aic, model_glm_DSAMP_race_back$aic)

anova(model_glm_DSAMP_race_back, model_glm_DSAMP_Forw,  test="Chisq")
```

## 4.2 Knn

### 4.2.1 Knn con variables numéricas

```{r}
train.labels <- SQFdataTrain_DSAMP$arstmade
test.labels <- SQFdataTest$arstmade

train.numeric <- SQFdataTrain_DSAMP %>% 
  select(ser_num, perobs, perstop, repcmd, revcmd, age, ht_feet, ht_inch, weight) %>% 
  mutate_each(funs(scale))

test.numeric <- SQFdataTest %>%
  select(ser_num,perobs,perstop,repcmd,revcmd,age,ht_feet,ht_inch,weight) %>% 
  mutate_each(funs(scale))
```

```{r}
knn_total.numeric <- knn1(train.numeric, test.numeric, train.labels)
error1 <- sum(knn_total.numeric != test.labels)/length(test.labels);
1-error1
```

### 4.2.2 Knn con variables categóricas

```{r warning=FALSE}
train.cat <- SQFdataTrain_DSAMP %>%
  mutate_each(funs(as.numeric))

test.cat <- SQFdataTest %>%
  mutate_each(funs(as.numeric))

z = rep(1, dim(train.cat)[1]) %*% as.matrix(test.cat[1, ])
sim = apply(z - train.cat == 0, 1, sum)/dim(train.cat)[2]

# Repetimos para todos los puntos
ntrain <- dim(train.cat)[1]
ntest <- dim(test.cat)[1]
d <- dim(train.cat)[2]
sim <- matrix(0, ntest, ntrain)

for (i in 1:ntest) {
  z = rep(1, ntrain) %*% as.matrix(test.cat[i, ])
  sim[i, ] = apply(z - train.cat == 0, 1, sum)/d
}

similaridadCategorica = sim
indices = apply(sim, 1, which.max)
prediccionCategorica = rep(0, ntest)
for (i in 1:ntest) {
  z = table(train.labels[which(sim[i, ] == sim[i, indices[i]])])
  prediccionCategorica[i] = attributes(which(z == max(z)))$names
}
attributes(which(z == max(z)))$names
```

### 4.2.3 Unión de las medidas

```{r}
total = rbind(test.numeric, train.numeric)
distanciaEuclidea = as.matrix(dist(total))[1:ntest, (ntest + 1):(ntest + ntrain)]
similaridadNumerica = 1 - distanciaEuclidea/max(distanciaEuclidea)
similaridadFinal = (0.3 * similaridadNumerica + 0.7 * similaridadCategorica)
sim = similaridadFinal
k = 10
indices = apply(sim, 1, function(x) sort (x, index.return = TRUE,decreasing = TRUE)$ix[1:k])
prediccion_knn = rep(0, ntest)
for (i in 1:ntest) {
  prediccion_knn[i] = 2 * sum(as.numeric(train.labels[indices[,i]]) - 1) >= k
}

```

## 4.3 Random Forest

A continuación se recurre al uso de árboles de decisión para predecir la variable objetivo del problema planteado. Se seguirá el código programado por Javier Moguerza y como complemento al mismo, se compara el procesado de dicho código de forma secuencial y en paralelo.

### 4.3.1 Selección de predictores

La función `randomForest::rfcv` permite realizar una evaluación del comportamiento del modelo según el número de variables a escoger para cada rama. Dado que el conjunto de train cuenta con relativamente pocos predictores, se emplea un step elevado para comprobar todas las particiones posibles y seleccionar la óptima a la hora de generar el modelo. Una vez realizado el cálculo, se escoge el valor óptimo para generar el conjunto de árboles.

```{r}
# Random Forest con Cross-Validation para selección de predictores
cv.model_rf_10 <- rfcv(trainx=SQFdataTrain_DSAMP[,-match("arstmade",
                                                         colnames(SQFdataTrain_DSAMP))],
                       trainy=SQFdataTrain_DSAMP$arstmade, cv.fold=10,
                       step=0.99, mtry=function(p) max(1, floor(sqrt(p))), ntree = 100)
```

### 4.3.2 Preparación de datos para la generación de modelos

```{r}
# Preparación de datasets con target en última columna
SQFdataTrain_DSAMP_RF <- SQFdataTrain_DSAMP %>% select(-arstmade)
SQFdataTrain_DSAMP_RF <- cbind(SQFdataTrain_DSAMP_RF,
                               arstmade = SQFdataTrain_DSAMP$arstmade)

SQFdataTest_RF <- SQFdataTest %>% select(-arstmade)
SQFdataTest_RF <- cbind(SQFdataTest_RF, arstmade = SQFdataTest$arstmade)

# Parámetros para el bosque (N - Nº arboles, K - Nº predictores, M - Nº muestras)
N = 600
K = as.integer(names(cv.model_rf_10$error.cv[which.min(cv.model_rf_10$error.cv)])) 
M = round(dim(SQFdataTrain_DSAMP_RF)[1]*0.7)

# Posición de la variable respuesta en el dataset
res = which(colnames(SQFdataTrain_DSAMP_RF)=="arstmade")

# Vectores de modelos
moguerza.forest.sec <- vector("list", N)
moguerza.forest.par <- vector("list", N)
 
# Matrices de predictores
vars.sec = matrix(0,K,N)
vars.par = matrix(0,K,N)

# Tamaño total de la muestra de train y test
k = dim(SQFdataTrain_DSAMP_RF)[1]
m = dim(SQFdataTest_RF)[1]
```

### 4.3.3 Generación de modelos

Se combina la generación de los modelos secuencial y paralelo con el cálculo del tiempo requerido para cada uno de ellos.

* Código secuencial:

```{r}
start.time <- Sys.time()

for(i in 1:N) {
    # Selección de predictores y observaciones para el árbol
    a = sort(sample(1:(dim(SQFdataTrain_DSAMP_RF)[2]-1),K))
    b = sort(sample(1:k, M))
    
    # Datos para el árbol
    SQFdataTrain_DSAMP.vot = SQFdataTrain_DSAMP_RF[b,c(a,res)]
    
    # Creación de los árboles
    model.rp <- rpart(SQFdataTrain_DSAMP.vot[,K+1] ~., data = SQFdataTrain_DSAMP.vot[,1:K],
                      cp=0.0001, control = rpart.control(maxdepth = 10),
                      parms=list(split="gini"))
    
    # Almacenamiento de árboles en modelo secuencial
    moguerza.forest.sec[[i]] = model.rp
    
    # Almacenamiento de los predictores seleccionados por árbol
    vars.sec[,i] = as.vector(a)
}

time.taken.sec <- Sys.time() - start.time
```

* Código paralelo:

```{r}
start.time <- Sys.time()

# Creación de conjuntos aleatorios de train
SQFdataTrain_DSAMP.vot <- foreach(n = 1:N) %dopar% {
    # Selección de predictores y observaciones para el árbol
    a = sort(sample(1:(dim(SQFdataTrain_DSAMP_RF)[2]-1),K))
    b = sort(sample(1:k, M))

    # Datos para el árbol
    SQFdataTrain_DSAMP_RF[b,c(a,res)]
}

# Creación de árboles
moguerza.forest.par <- foreach(i=1:N) %dopar% {
    model.rp <- rpart(SQFdataTrain_DSAMP.vot[[i]][,K+1] ~.,
                      data = SQFdataTrain_DSAMP.vot[[i]][,1:K],
                      cp=0.0001, control = rpart.control(maxdepth = 10),
                      parms=list(split="gini"))
}

# Almacenamiento de predictores por árbol
for (i in 1:N) {
    vars.par[,i] <- which(is_in(colnames(SQFdataTrain_DSAMP_RF),
                                attr(moguerza.forest.par[[i]]$terms,"term.labels")))
}

time.taken.par <- Sys.time() - start.time

paste("Tiempo generación del modelo código secuencial:",
      as.character.POSIXt(round(time.taken.sec, 2)))
paste("Tiempo generación del modelo código paralelo:",
      as.character.POSIXt(round(time.taken.par, 2)))
```

### 4.3.4 Evaluación del error en conjunto de train

* Código secuencial:

```{r}
# Matriz de predicciones
pred.matrix.train.sec <- matrix(0,k,N)

for (j in 1:N)
{
    prediction = predict(moguerza.forest.sec[[j]], SQFdataTrain_DSAMP_RF[,vars.sec[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
    pred.matrix.train.sec[,j] = prediction.fact
}
# Vector de probabilidades
p.arstmade.train.sec <- rowSums(pred.matrix.train.sec==factores[2])/N

pred.train.fact.sec <- factores[round(p.arstmade.train.sec)+1]
real.train.fact <- relevel(SQFdataTrain_DSAMP_RF[,res], ref = 'Y')
pred.train.fact.sec <- relevel(as.factor(pred.train.fact.sec), ref = "Y")

table.moguerza.train.sec = table(pred.train.fact.sec, real.train.fact)
confusionMatrix(table.moguerza.train.sec)
```

* Código paralelo:

```{r}
# Matriz de predicciones
pred.matrix.train.par <- matrix(0,k,N)

pred.vect.train.par <- foreach(j = 1:N) %dopar% {
    prediction <- predict(moguerza.forest.par[[j]], SQFdataTrain_DSAMP_RF[,vars.par[,j]] )
    factores <- colnames(prediction)
    prediction.fact <- factores[max.col(prediction)]
}

for(j in 1:N){
    pred.matrix.train.par[,j] <- pred.vect.train.par[[j]]
}

# Vector de probabilidades
p.arstmade.train.par <- rowSums(pred.matrix.train.par==factores[2])/N

pred.train.fact.par <- factores[round(p.arstmade.train.par)+1]
real.train.fact <- relevel(SQFdataTrain_DSAMP_RF[,res], ref = 'Y')
pred.train.fact.par <- relevel(as.factor(pred.train.fact.par), ref = "Y")

table.moguerza.train.par = table(pred.train.fact.par, real.train.fact)
confusionMatrix(table.moguerza.train.par)
```

### 4.3.5 Evaluación del error en conjunto de test

* Código secuencial:

```{r}
# Matriz de predicciones
pred.matrix.test.sec = matrix(0,m,N)

start.time <- Sys.time()
for (j in 1:N)
{
    prediction = predict(moguerza.forest.sec[[j]], SQFdataTest_RF[,vars.sec[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
    pred.matrix.test.sec[,j] = prediction.fact
}

time.pred.sec <- Sys.time() - start.time

# Vector de probabilidades
p.arstmade.test.sec = rowSums(pred.matrix.test.sec==factores[2])/N 

pred.test.fact.sec = factores[round(p.arstmade.test.sec) + 1]
real.train.fact = relevel(SQFdataTest_RF[,res], ref = "Y")
pred.test.fact.sec <- relevel(as.factor(pred.test.fact.sec), ref = "Y")

table.moguerza.test.sec = table(pred.test.fact.sec,real.train.fact)
confusionMatrix(table.moguerza.test.sec)
```

* Código paralelo:

```{r}
# Matriz de predicciones
pred.matrix.test.par = matrix(0,m,N)

start.time <- Sys.time()
pred.vect.test.par <- foreach(j = 1:N) %dopar% {
    prediction <- predict(moguerza.forest.par[[j]], SQFdataTest_RF[,vars.par[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
}

for(j in 1:N){
    pred.matrix.test.par[,j] = pred.vect.test.par[[j]]
}

time.pred.par <- Sys.time() - start.time

# Vector de probabilidades
p.arstmade.test.par = rowSums(pred.matrix.test.par==factores[2])/N

pred.test.fact.par = factores[round(p.arstmade.test.par)+1]
real.train.fact = relevel(SQFdataTest_RF[,res], ref = "Y")
pred.test.fact.par <- relevel(as.factor(pred.test.fact.par), ref = "Y")

table.moguerza.test.par = table(pred.test.fact.par,real.train.fact)
confusionMatrix(table.moguerza.test.par)

paste("Tiempo de predicción del modelo código secuencial:",
      as.character.POSIXt(round(time.pred.sec, 2)))
paste("Tiempo de predicción del modelo código paralelo:",
      as.character.POSIXt(round(time.pred.par, 2)))
```

Se observan resultados similares para ambos modelos, por lo que en adelante se empleará únicamente uno de ellos.

## 4.4 SVM
### 4.4.1. Preparacion del conjunto de train y test

```{r}
indices_train_svm <- sample(indices, 0.7*tot_obs)
SQFdataTrain_svm = SQFdata_modif[indices_train_svm, ]
SQFdataTest_svm = SQFdata_modif[-indices_train_svm, ]
```
### 4.4.2. Ejecucion del train y test del SVM

```{r}
svm.train.radial <- parallelSVM(arstmade ~ . , SQFdataTrain, kernel = "radial", gamma = 0.1, cost = 100)
svm.test.radial <- predict(svm.train.radial, newdata=SQFdataTest,decision.values=TRUE)
summary(svm.train.radial)
table(svm.test.radial)
```
\newpage

## 4.5 Redes neuronales
### 4.5.1 Recodificación variables con categorías desbalanceadas o sin registros
```{r}
levels(SQFdata_modif$eyecolor) <- list(black="Black", blue="Blue", brown="Brown", green="Green",  
                                       gray="Gray", hazel="Hazel", unknown="Unknown",
                                       other=c("Two different", "Maroon","MC","Pink","Violet", "Other"))
levels(SQFdata_modif$haircolr) <- list(bald="Bald", black="Black", blond="Blond", brown="Brown",
                                       gray="Gray", red="Red", unknown="Unknown", 
                                       other=c("Dyed", "Frosted","Sandy", "White", "Other"))
```


### 4.5.2 Eliminación de variables relacionadas con el registro

```{r}
SQFdata_modif <- SQFdata_modif %>% 
    select(-c(ser_num,repcmd, revcmd, recstat))

```

### 4.5.3 Tratamiento previo a las variables

```{r}
SQFdata_modif.num <- SQFdata_modif[,sapply(SQFdata_modif, is.numeric)]
```


#### 4.5.3.1 Variables dummies 

```{r}
SQFdata_modif.cat <- SQFdata_modif[,sapply(SQFdata_modif, is.factor)]


# binarización factores con dos niveles
SQFdata_modif.cat1<- SQFdata_modif.cat[, sapply(SQFdata_modif.cat, function(col) length(unique(col))) < 3]

YesNoCat <- sapply(SQFdata_modif.cat1,
                   function(x) (levels(x) == c("Y","N")) || (levels(x) == c("N","Y")))
SQFdata_modif.cat1[YesNoCat] <- sapply(SQFdata_modif.cat1[YesNoCat], function(x) ifelse(x=="Y",1,0))

SQFdata_modif.cat1$inout<- as.numeric(SQFdata_modif.cat1$inout)
SQFdata_modif.cat1$inout[SQFdata_modif.cat1$inout==2] <- 0


# binarización factores con más de dos niveles
SQFdata_modif.cat2 <- SQFdata_modif.cat[, sapply(SQFdata_modif.cat, function(col) length(unique(col))) > 2]
SQFdata_modif.cat2 <- acm.disjonctif(SQFdata_modif.cat2) 

```

#### 4.5.3.2 Dataset completo
```{r}
SQFdata_modif.num.cat<- data.frame(SQFdata_modif.cat1, SQFdata_modif.cat2, SQFdata_modif.num)
```



### 4.5.4 División de muestra en train y test

```{r}
set.seed(4567)
nfilas    <- nrow(SQFdata_modif.num.cat)
muestra   <- sample(nfilas, nfilas*.70)
train     <- SQFdata_modif.num.cat[muestra, ]
test      <- SQFdata_modif.num.cat[-muestra, ]

# Datos desbalanceados
train %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### 4.5.5 Ajuste del desbalanceo: Down-sampling

- Down-Sampling:

```{r}
train.yes <- train %>% filter(arstmade == 1)
train.no <- train %>% filter(arstmade == 0)

set.seed(4567)
ind_train.no <- sample(rownames(train.no),4768)
train.no <- train.no[ind_train.no,]

SQFdataTrain_DSAMP <- rbind(train.yes, train.no)

SQFdataTrain_DSAMP %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### 4.5.6 Escalamiento datos de entrenamiento
```{r}
maxs <- apply(SQFdataTrain_DSAMP , 2, max) 
mins <- apply(SQFdataTrain_DSAMP , 2, min)

SQFdataTrain_DSAMP.scaled <- as.data.frame(scale(SQFdataTrain_DSAMP , center = mins, scale = maxs - mins))
#sum(is.na(SQFdataTrain_DSAMP.scaled))
```

### 4.5.7 Modelo

```{r}
library(doParallel)
cl = makeCluster(6)
registerDoParallel(cl)

SQFdataTrain_DSAMP.scaled$arstmade<- as.factor(SQFdataTrain_DSAMP.scaled$arstmade)
levels(SQFdataTrain_DSAMP.scaled$arstmade) <- list(Y="1", N="0")
SQFdataTrain_DSAMP.scaled$arstmade <- factor(SQFdataTrain_DSAMP.scaled$arstmade,
                                             levels=c("Y", "N"),
                                             ordered=TRUE)
set.seed(1)
seeds <- vector(mode = "list", length = 6)
for(i in 1:5) seeds[[i]] <- sample.int(n=1000, 60) 
seeds[[6]] <- 1


fitControl <- trainControl(method = "cv", 
                           number = 5, 
                           classProbs = TRUE, 
                           summaryFunction = twoClassSummary,
                           seeds = seeds,
                           allowParallel = TRUE)


nnetGrid <-  expand.grid(size = seq(from = 1, to = 10, by = 1),
                         decay= c(0.5, 0.1, 0.01, 0.001, 0.0001, 0.005))


caret.fit.mod <- train(arstmade~., 
                       data=SQFdataTrain_DSAMP.scaled,
                       method = "nnet", 
                       metric = "Sens",
                       trace = F,
                       trControl = fitControl,
                       tuneGrid = nnetGrid,
                       verbose = FALSE)

stopCluster(cl)
remove(cl)

plot(caret.fit.mod)
caret.fit.mod$bestTune

```
### 4.5.8 Predicción
```{r}

SQFdataTest.scaled <- as.data.frame(scale(test , center = mins, scale = maxs - mins))
SQFdataTest.scaled$arstmade<- as.factor(SQFdataTest.scaled$arstmade)
levels(SQFdataTest.scaled$arstmade) <- list(Y="1", N="0")
SQFdataTest.scaled$arstmade <- factor(SQFdataTest.scaled$arstmade,
                                             levels=c("Y", "N"),
                                             ordered=TRUE)

predict.caret <- predict(caret.fit.mod$finalModel, SQFdataTest.scaled[,-3], type="class")
predicciones <- data.frame(predict(caret.fit.mod$finalModel, SQFdataTest.scaled[,-3], type="raw"),
                           prediction=predict(caret.fit.mod$finalModel, SQFdataTest.scaled[,-3],                                                 type="class"))
```

# 5. EVALUACIÓN

Se evalúan los tres mejores modelos obtenidos en cada caso.

## 5.1 Validación cruzada

Dado que nuestro objetivo es construir un modelo de predicción, la medida de evaluación más importante es determinar lo bien que el modelo predice para observaciones diferentes a las de prueba. Se construye una tabla de clasificación para cada modelo, donde se cruza el verdadero valor de la observación con la predicción de la misma. Para ello se toma como referencia una predicción mayor a 0.5.

De dicha tabla se obtienen las métricas *F-measure*, *precision*, *recall o sensitivity* y *specificity*.

```{r}
# Función de evaluación de modelos
fun_eval_mod <- function(x){
    c(x$byClass[7], x$byClass[5:6], x$byClass[2])
    }

# Obtención de matrices de confusión para cada modelo

# Regresión Logística
pred_DSAMP_hair_back <- factor(predict(model_glm_DSAMP_hair_back, SQFdataTest,
                                       type="response")>0.5,
                          levels=c(TRUE, FALSE),
                          labels=c("Y","N"))

cM_DSAMP_hair_back <- confusionMatrix(pred_DSAMP_hair_back,
                                      relevel(SQFdataTest$arstmade, ref = "Y"),
                                      positive="Y")

# KNN
cM_knn <- confusionMatrix(factor(prediccion_knn, levels = c(0,1), labels=c('N','Y')),
                          test.labels, positive = 'Y')


# Random Forest
cM_RF_par <- confusionMatrix(table.moguerza.test.par)


df.comp.models <- data.frame(
    LogisticRegression = fun_eval_mod(cM_DSAMP_hair_back),
    knn = fun_eval_mod(cM_knn),
    RandomForest = fun_eval_mod(cM_RF_par),
    row.names = c("F-measure","Precision","Recall/Sensitivity","Specificity")
)

kable(df.comp.models, format = "markdown", digits = 4)

# Redes neuronales

cM_rN <- confusionMatrix(factor(predict.caret),
                reference= factor(SQFdataTest.scaled$arstmade),
                positive='Y')
```

## 5.2 Curvas ROC

La curva ROC muestra la relación entre la tasa de *true positives* y la tasa de *false positives*, es decir, entre la tasa de casos predichos correctamente como positivos y la tasa de casos predichos erróneamente como positivos:

* *True Positive Rate (TPR)*:

$$\text{TPR}=\frac{TP}{TP+FN}$$

* *False Positive Rate (FPR)*:

$$\text{FPR}=\frac{FP}{FP+TN}$$

Esta métrica ofrece un mejor resumen de la capacidad predictiva que una tabla de clasificación porque presenta la potencia predictiva para todos los posibles valores sin establecer una referencia arbitraria, permitiendo así evaluar el rendimiento del clasificador.

### 5.2.1 Regresión logística

```{r, warming = FALSE, message=FALSE}
prob_test_glm <- predict(model_glm_DSAMP_hair_back, SQFdataTest, type="response")
pr_test_glm <- prediction(prob_test_glm, SQFdataTest$arstmade)
pred_tpr_fpr_glm <- performance(pr_test_glm, measure = "tpr", x.measure = "fpr")
plot(pred_tpr_fpr_glm, main = "ROC curve", col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)

auc_test_glm <- performance(pr_test_glm, measure = "auc")
auc_test_glm <- auc_test_glm@y.values[[1]]
paste("Índice de área bajo la curva:", round(auc_test_glm, 4))
```

### 5.2.2 Random Forest

```{r, warming = FALSE, message=FALSE}
prob_test_RF <- rowSums(pred.matrix.test.par==factores[2])/N
pr_test_RF <- prediction(prob_test_RF, SQFdataTest$arstmade)
pred_tpr_fpr_RF <- performance(pr_test_RF, measure = "tpr", x.measure = "fpr")
plot(pred_tpr_fpr_RF, main = "ROC curve", col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)

auc_test_RF <- performance(pr_test_RF, measure = "auc")
auc_test_RF <- auc_test_RF@y.values[[1]]
paste("Índice de área bajo la curva:", round(auc_test_RF, 4))
```

### 5.2.3 SVM
```{r}
predSVM=prediction(as.numeric(svm.test.radial),as.numeric(SQFdataTest_svm$arstmade))
prefSVM=performance(predSVM,"tpr","fpr")
plot(prefSVM)
```

\newpage

### 5.2.4 Redes neuronales
```{r}
predict.caret.prob <- predict(caret.fit.mod$finalModel, SQFdataTest.scaled[,-3], type="raw")
nnetROC <- roc(SQFdataTest.scaled$arstmade, as.vector(predict.caret.prob), auc=TRUE)
nnetROC
plot(nnetROC, main = "ROC curve", col = "blue", lwd = 3)
```

# 6. CONCLUSIONES

En los modelos estadísticos analizados, en principio se determina que la variable *race* que corresponde a la raza de las personas paradas resulta significativa en la probabilidad de que sean arrestados, sin embargo, resultaría interesante verificar si efectivamente este es un factor determinante para que una persona sea parada o no, es decir, verificar la hipótesis de que esta ley es un "política de discriminación racial indirecta".  

Según las estadísticas presentadas por el Departamento de Policía (NYPD) en el año 2016, Nueva York ha experimentado una reducción en todas las categorías de delitos, además de la reducción de uso de la técnica de "Stop and Frisk". Ante estos resultados, resulta interesante conocer el impacto que tiene esta ley en las estadísticas de delincuencia.

## 6.1 Comparación de resultados sin Down-Sampling

En el apartado *3.4.1* se explicó que la técnica de Down-Sampling permite incrementar el número de $TP$ generados por el modelo. En este último punto se pretende ilustrar de forma sencilla dicha mejora. Se realiza una comparación de valores entre el modelo óptimo de regresión logística obtenido y el modelo que se hubiera obtenido de no haber aplicado Down-Sampling al dataset.

```{r}
# Generación del modelo
model_glm <- glm(arstmade ~ ., data = SQFdataTrain, family = "binomial")

model_glm$xlevels$eyecolor <- levels(SQFdataTest$eyecolor)


cM_glm <- confusionMatrix(factor(predict(model_glm, SQFdataTest, type="response")<0.5,
                       levels = c(TRUE,FALSE), labels = c("Y","N")),
                relevel(SQFdataTest$arstmade, ref = "Y"), positive = "Y")

df.comp.DS.models <- data.frame(glm = fun_eval_mod(cM_glm),
                                glm_DS = fun_eval_mod(cM_DSAMP_hair_back),
                                row.names = c("F-measure","Precision",
                                              "Recall/Sensitivity","Specificity"))

kable(df.comp.DS.models, format = "markdown", digits = 4)
```

Tal y como se afirmó, tras aplicar Down-Sampling se alcanza el objetivo fijado de mejorar el *sensitivity* del modelo y por tanto, reducir al máximo los falsos negativos.

