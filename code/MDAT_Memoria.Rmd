---
title: "MDAT_Memoria"
author: "Nathaly Cárdenas, Iván Artalejo, Hugo Fernández, Jorge Navarro"
date: "3 de mayo de 2017"
output:
  pdf_document: default
  html_document: default
---

```{r, message = FALSE, warning = FALSE}
# Apartado 2
library(dataQualityR)
library(knitr)
library(grid)
library(gridExtra)

# Apartado 3
library(magrittr)
library(dplyr)


library(caret)

library(pscl)
detach("package:pscl", unload=TRUE)
library(survey)
library(ROCR)
library(foreach)
library(doMC)
registerDoMC(8)
library(rpart)
```

# 1. DESCRIPCIÓN DEL PROBLEMA

El programa ***[Stop and frisk](https://en.wikipedia.org/wiki/Stop-and-frisk_in_New_York_City)*** de la ciudad de Nueva York consiste en la práctica de detenciones temporales, interrogatorios e incluso cacheos a ciudadanos en busca de armas o cualquier tipo de contrabando. Los motivos en los cuales la policía puede ampararse para llevar a cabo estas prácticas se encuentran dentro de la ley criminal estadounidense.

La mayoría de detenciones producidas se centran en la población afroamericana y latina de la ciudad de edades comprendidas entre los 15 y los 25 años, lo cual ha generado gran controversia en torno a dicha ley. También contribuye al rechazo generado por la ley determinados **[estudios](https://www.washingtonpost.com/politics/2016/live-updates/general-election/real-time-fact-checking-and-analysis-of-the-first-presidential-debate/fact-check-trump-on-crime-statistics-and-stop-and-frisk/?utm_term=.52808601905f)** que demuestran que no existe relación entre el número de detenidos y la tasa de criminalidad de la ciudad. 

El departamento de policía de NY facilita de forma periódica **[datos](https://www.nyclu.org/en/stop-and-frisk-data)** sobre las detenciones realizadas en la ciudad. 9 de cada 10 personas detenidas son inocentes y aunque el número de detenciones se ha visto reducido considerablemente, pasando en 2011 de 685,724 detenciones a 22,939 en 2015, las proporciones según la etnia de las personas detenidas se han mantenido constantes.

Se generan distintos modelos a lo largo del trabajo para poder determinar la necesidad o no de arrestar a las personas detenidas.

# 2. DESCRIPCIÓN DE LOS DATOS

Se expone a continuación una breve descripción sobre las variables incluidas en el dataset y un análisis de la calidad de las observaciones.

## 2.1 Diccionario de datos

```{r, message=FALSE, warning=FALSE}
if(!file.exists("../data/data_dictionary.csv"))
    download.file(paste("https://raw.githubusercontent.com/jorgenav/Stop-Frisk/",
                  "master/data/data_dictionary.csv", sep = ""),
                  "../data/data_dictionary.csv")
SQFdataDictionary <- read.csv("../data/data_dictionary.csv")

kable(SQFdataDictionary, caption="NYPD Stop Question Frisk Database 2014")
```

## 2.2 Data Quality Report

```{r, message=FALSE, warning=FALSE}
# CARGA DE DATOS DEL PROYECTO
if(!file.exists("../data/2014.csv")) {
  download.file("http://www.nyc.gov/html/nypd/downloads/zip/analysis_and_planning/2014_sqf_csv.zip",
                "../data/2014_sqf_csv.zip")
  unzip("../data/2014_sqf_csv.zip", exdir = "../data/")
}

SQFdata <- read.csv("../data/2014.csv")

drq.num <- paste("./dqr_num.csv", sep = "")
drq.cat <- paste("./dqr_cat.csv", sep = "")
checkDataQuality(SQFdata, out.file.num = drq.num,  out.file.cat = drq.cat)
DQR.num <- read.csv("dqr_num.csv")
DQR.cat <- read.csv("dqr_cat.csv")
```

### 2.2.a Variables numéricas

```{r, message=FALSE, warning=FALSE}
grid.table(DQR.num,
           theme = ttheme_default(base_size = 5, padding = unit(c(1, 1), "mm")))
```

### 2.2.b Variables categóricas

```{r, message=FALSE, warning=FALSE}
grid.table(DQR.cat[1:45,1:15],
           theme = ttheme_default(base_size = 5, padding = unit(c(1, 1), "mm")))
```

```{r}
grid.table(DQR.cat[46:86,1:15],
           theme = ttheme_default(base_size = 5, padding = unit(c(1, 1), "mm")))
```

\newpage

# 3. PREPARACIÓN DE LOS DATOS

[...]

## 3.1 Depuración de los datos

[...]

## 3.2 Análisis exploratorio

[...]

### 3.2.1 VARIABLE DEPENDIENTE

[...]

### 3.2.2 VARIABLES INDEPENDIENTES

[...]

### 3.2.3 Conclusiones

[...]

## 3.3 Transformación de variables

Se genera un dataset a partir de diversas transformaciones aplicadas a las variables del dataset original. Se busca seleccionar las variables y las observaciones que puedan aportar información a los modelos y eliminar todos aquellos casos que no permitan trabajar con ellos.

### 3.3.1 Creación de dataset transformado y ordenación de niveles en variable objetivo

```{r}
# source("code/Cleaning_Data.R")
source("Cleaning_Data.R")
SQFdata_modif <- SQFdata
```

### 3.3.2 Eliminación de variables

En las tablas obtenidas en el segundo apartado del presente documento se puede obtener información sobre qué variables sería interesante eliminar del dataset teniendo en cuenta distintos aspectos:

* Porcentaje de datos faltantes.
* Casos con varianza nula o casi nula.
* Factores con demasiados niveles.
* Otros aspectos.

```{r}
#
# Eliminación de variables con más de ~60% de datos faltantes.
#
perc_NA <- function(x) {
    perc <- sum(is.na(x))*100/length(x)
    paste(perc,"%")
}

perc_NA(SQFdata_modif$arstoffn);perc_NA(SQFdata_modif$sumoffen);perc_NA(SQFdata_modif$officrid)
perc_NA(SQFdata_modif$offverb);perc_NA(SQFdata_modif$offshld);perc_NA(SQFdata_modif$forceuse)
perc_NA(SQFdata_modif$othfeatr);perc_NA(SQFdata_modif$addrnum);perc_NA(SQFdata_modif$stname)
perc_NA(SQFdata_modif$beat);perc_NA(SQFdata_modif$post);perc_NA(SQFdata_modif$state)
perc_NA(SQFdata_modif$zip);perc_NA(SQFdata_modif$rescode);perc_NA(SQFdata_modif$premtype)
perc_NA(SQFdata_modif$aptnum);

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(arstoffn, sumoffen, officrid, offverb, offshld,
                              forceuse, othfeatr, addrnum, stname, beat,
                              post, state, zip, rescode, premtype, aptnum))



#
# Eliminación de variables con poca o nula varianza (casos pertenecientes
# todos a una misma clase). 7 variables eliminadas
#
summary(SQFdata_modif$adtlrept);summary(SQFdata_modif$riflshot);
summary(SQFdata_modif$asltweap);summary(SQFdata_modif$machgun);
summary(SQFdata_modif$pf_baton);summary(SQFdata_modif$pf_pepsp)
summary(SQFdata_modif$addrtyp);summary(SQFdata_modif$year);
summary(SQFdata_modif$compyear);summary(SQFdata_modif$comppct);
summary(SQFdata_modif$lineCM);summary(SQFdata_modif$dob);
summary(SQFdata_modif$dettypCM)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(adtlrept, riflshot, asltweap, machgun,
                             pf_baton, pf_pepsp, addrtyp, year,
                             compyear, comppct, lineCM, dob, dettypCM))



# 
# Eliminación de variables con demasiados niveles (strings). 8 variables eliminadas
# 
length(levels(SQFdata_modif$premname));length(levels(SQFdata_modif$stinter))
length(levels(SQFdata_modif$crossst));length(levels(SQFdata_modif$sector))
length(levels(SQFdata_modif$pct));length(levels(SQFdata_modif$crimsusp))
length(levels(SQFdata_modif$addrpct));length(levels(SQFdata_modif$detailCM))

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(premname, stinter, crossst, sector,
                              pct, crimsusp, addrpct, detailCM))

# 
# Variables asociadas a series temporales o coordenadas -> No son de interés para
# el problema que ocupa
# 
SQFdata_modif <- SQFdata_modif %>%
                    select(-c(datestop, timestop, xcoord, ycoord))



# 
# Número de variables final
# 
dim(SQFdata)
dim(SQFdata_modif)
```

### 3.3.3 Imputación de NAs

Nos encontramos ante dos casos distintos de NAs después de haber realizado la eliminación previa de variables:


* Variable *age*: Presenta 212 casos sin valor frente a los 45.787 totales disponibles en el dataset original. Dado que se trata de un porcentaje ínfimo de casos, se opta por eliminarlos del conjunto de datos.
    
* Variables asociadas a distintos aspectos de la dentención (armas, fuerza física, circunstancias adicionales, etc): Se consideran dichas variables como información complementaria a la detención. De esta forma se asume que, en aquellos casos donde no existe información sobre la variable, o bien el agente no ha rellenado la casilla o ha rellenado alguna de las otras clases de la variable. Por tanto, se asigna a todas esas observaciones el nivel NO. Esta decisión permitirá volver a eliminar variables que presenten varianza casi nula.


```{r}
# 
# Eliminación de NAs en variable age
#
SQFdata_modif %>% group_by(is.na(age)) %>%
    summarise(n())

SQFdata_modif <- SQFdata_modif %>% filter(!is.na(age))



# 
# Modificación de variables no eliminadas
# 

# Uso de armas
summary(SQFdata_modif$pistol);summary(SQFdata_modif$knifcuti);
summary(SQFdata_modif$othrweap);

SQFdata_modif$pistol[which(is.na(SQFdata_modif$pistol))]     <- 'N'
SQFdata_modif$knifcuti[which(is.na(SQFdata_modif$knifcuti))] <- 'N'
SQFdata_modif$othrweap[which(is.na(SQFdata_modif$othrweap))] <- 'N'

# Uso de fuerza física
summary(SQFdata_modif$pf_hands);summary(SQFdata_modif$pf_wall);
summary(SQFdata_modif$pf_grnd);summary(SQFdata_modif$pf_drwep);
summary(SQFdata_modif$pf_ptwep);summary(SQFdata_modif$pf_hcuff);
summary(SQFdata_modif$pf_other);

SQFdata_modif$pf_hands[which(is.na(SQFdata_modif$pf_hands))] <- 'N'
SQFdata_modif$pf_wall[which(is.na(SQFdata_modif$pf_wall))]   <- 'N'
SQFdata_modif$pf_grnd[which(is.na(SQFdata_modif$pf_grnd))]   <- 'N'
SQFdata_modif$pf_drwep[which(is.na(SQFdata_modif$pf_drwep))] <- 'N'
SQFdata_modif$pf_ptwep[which(is.na(SQFdata_modif$pf_ptwep))] <- 'N'
SQFdata_modif$pf_hcuff[which(is.na(SQFdata_modif$pf_hcuff))] <- 'N'
SQFdata_modif$pf_other[which(is.na(SQFdata_modif$pf_other))] <- 'N'

# Circunstancias adicionales
summary(SQFdata_modif$ac_rept);summary(SQFdata_modif$ac_inves);
summary(SQFdata_modif$ac_proxm);summary(SQFdata_modif$ac_evasv);
summary(SQFdata_modif$ac_assoc);summary(SQFdata_modif$ac_cgdir);
summary(SQFdata_modif$ac_incid);summary(SQFdata_modif$ac_time);
summary(SQFdata_modif$ac_stsnd);summary(SQFdata_modif$ac_other);

SQFdata_modif$ac_rept[which(is.na(SQFdata_modif$ac_rept))]   <- 'N'
SQFdata_modif$ac_inves[which(is.na(SQFdata_modif$ac_inves))] <- 'N'
SQFdata_modif$ac_proxm[which(is.na(SQFdata_modif$ac_proxm))] <- 'N'
SQFdata_modif$ac_incid[which(is.na(SQFdata_modif$ac_incid))] <- 'N'
SQFdata_modif$ac_time[which(is.na(SQFdata_modif$ac_time))]   <- 'N'
SQFdata_modif$ac_evasv[which(is.na(SQFdata_modif$ac_evasv))] <- 'N'
SQFdata_modif$ac_assoc[which(is.na(SQFdata_modif$ac_assoc))] <- 'N'
SQFdata_modif$ac_cgdir[which(is.na(SQFdata_modif$ac_cgdir))] <- 'N'
SQFdata_modif$ac_stsnd[which(is.na(SQFdata_modif$ac_stsnd))] <- 'N'
SQFdata_modif$ac_other[which(is.na(SQFdata_modif$ac_other))] <- 'N'

# Razones para el cacheo
summary(SQFdata_modif$rf_vcrim);summary(SQFdata_modif$rf_othsw);
summary(SQFdata_modif$rf_attir);summary(SQFdata_modif$rf_vcact);
summary(SQFdata_modif$rf_rfcmp);summary(SQFdata_modif$rf_verbl);
summary(SQFdata_modif$rf_knowl);summary(SQFdata_modif$rf_furt);
summary(SQFdata_modif$rf_bulg);

SQFdata_modif$rf_vcrim[which(is.na(SQFdata_modif$rf_vcrim))] <- 'N'
SQFdata_modif$rf_othsw[which(is.na(SQFdata_modif$rf_othsw))] <- 'N'
SQFdata_modif$rf_attir[which(is.na(SQFdata_modif$rf_attir))] <- 'N'
SQFdata_modif$rf_vcact[which(is.na(SQFdata_modif$rf_vcact))] <- 'N'
SQFdata_modif$rf_rfcmp[which(is.na(SQFdata_modif$rf_rfcmp))] <- 'N'
SQFdata_modif$rf_furt[which(is.na(SQFdata_modif$rf_furt))]   <- 'N'
SQFdata_modif$rf_bulg[which(is.na(SQFdata_modif$rf_bulg))]   <- 'N'
SQFdata_modif$rf_verbl[which(is.na(SQFdata_modif$rf_verbl))] <- 'N'
SQFdata_modif$rf_knowl[which(is.na(SQFdata_modif$rf_knowl))] <- 'N'

# Razones para la detención
summary(SQFdata_modif$cs_objcs);summary(SQFdata_modif$cs_descr);
summary(SQFdata_modif$cs_casng);summary(SQFdata_modif$cs_lkout);
summary(SQFdata_modif$cs_cloth);summary(SQFdata_modif$cs_drgtr);
summary(SQFdata_modif$cs_furtv);summary(SQFdata_modif$cs_vcrim);
summary(SQFdata_modif$cs_bulge);summary(SQFdata_modif$cs_other);

SQFdata_modif$cs_objcs[which(is.na(SQFdata_modif$cs_objcs))] <- 'N'
SQFdata_modif$cs_descr[which(is.na(SQFdata_modif$cs_descr))] <- 'N'
SQFdata_modif$cs_casng[which(is.na(SQFdata_modif$cs_casng))] <- 'N'
SQFdata_modif$cs_lkout[which(is.na(SQFdata_modif$cs_lkout))] <- 'N'
SQFdata_modif$cs_cloth[which(is.na(SQFdata_modif$cs_cloth))] <- 'N'
SQFdata_modif$cs_drgtr[which(is.na(SQFdata_modif$cs_drgtr))] <- 'N'
SQFdata_modif$cs_furtv[which(is.na(SQFdata_modif$cs_furtv))] <- 'N'
SQFdata_modif$cs_vcrim[which(is.na(SQFdata_modif$cs_vcrim))] <- 'N'
SQFdata_modif$cs_bulge[which(is.na(SQFdata_modif$cs_bulge))] <- 'N'
SQFdata_modif$cs_other[which(is.na(SQFdata_modif$cs_other))] <- 'N'

# Motivos de búsqueda
summary(SQFdata_modif$sb_hdobj);summary(SQFdata_modif$sb_outln);
summary(SQFdata_modif$sb_admis);summary(SQFdata_modif$sb_other);

SQFdata_modif$sb_hdobj[which(is.na(SQFdata_modif$sb_hdobj))] <- 'N'
SQFdata_modif$sb_outln[which(is.na(SQFdata_modif$sb_outln))] <- 'N'
SQFdata_modif$sb_admis[which(is.na(SQFdata_modif$sb_admis))] <- 'N'
SQFdata_modif$sb_other[which(is.na(SQFdata_modif$sb_other))] <- 'N'

# Comprobación de NAs
sum(is.na(SQFdata))
sum(is.na(SQFdata_modif))
```

### 3.3.4 Eliminación de variables con varianza nula

```{r}
# 
# Con caret::nearZeroVar se elimina el resto de variables que presentan varianza
# nula después de aplicar la imputación de NAs
#
sapply(SQFdata_modif[nearZeroVar(SQFdata_modif)], summary)

SQFdata_modif <- SQFdata_modif[-nearZeroVar(SQFdata_modif)]

dim(SQFdata)
dim(SQFdata_modif)
```

## 3.4 Creación de conjuntos de *train* y *test*

Tras haber realizado las transformaciones necesarias a las variables, se crean los conjuntos de *train* y *test* a partir del dataset modificado. Tras crear los conjuntos se comprueba la proporción de clases que existe en la variable objetivo.

```{r}
# 
# Creación de conjuntos train y test
# 
tot_obs <- dim(SQFdata_modif)[1]
indices <- 1:tot_obs

set.seed(1234)
indices_train <- sample(indices, 0.7*tot_obs)
SQFdataTrain = SQFdata_modif[indices_train, ]
SQFdataTest = SQFdata_modif[-indices_train, ]

# Datos desbalanceados
SQFdataTrain %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### 3.4.1 Ajuste del desbalanceo: Down-Sampling

Tal y como se puede observar en la tabla anterior, de los casos seleccionados para el conjunto de train, el caso positivo o arresto de la persona detenida corresponde únicamente a un 15\% de ellos. Al disponer de un número tan reducido en nuestro conjunto de train, el modelo tenderá a predecir más casos negativos que positivos, lo que supone dejar marchar a personas que deberían ser arrestadas.

Esta situación, conocida como clases desbalanceadas, es muy típica en problemas de clasificación binaria. Para tratar de resolver este problema se pueden adoptar diferentes medidas:

* Conseguir más datos.
* Remuestreo del conjunto de train con diferentes técnicas: Up-Sampling, Down-Sampling, SMOTE, etc.
* Uso de modelos con peso.

En la realización del presente trabajo se han empleado las técnicas de remuestreo expuestas. Únicamente se muestran los resultados obtenidos tras emplear Down-Sampling dado que el resto de técnicas suponían mejoras menores, lo cual es lógico teniendo en cuenta que el dataset original cuenta con un total de 45.787 observaciones y por tanto es posible eliminar observaciones sin arriesgarse a perser demasiada información para generar los modelos.

Cabe destacar que, a pesar de mejorar en la predicción de los casos positivos, también conlleva desventajas frente al dataset desbalanceado. De las métricas empleadas para evaluar los modelos, la técnica de Down-Sampling mejora el *recall* del modelo pero empeora su *precision*. Dichas métricas se corresponden con:
    
* ***Recall***: Tasa de arrestos reales predichos como tal.

$$\text{Recall}=\frac{TP}{TP+FN}$$

* ***Precision***: Tasa de acierto en la predicción de arrestos.

$$\text{Precision}=\frac{TP}{TP+FP}$$

Siendo $TP=\text{True Positive}$ y $FN=\text{False Negative}$.

La mejora en la predicción de casos positivos se basa en el incremento de las predicciones para dicha clase a costa de una reducción en la contraria. Esto conlleva un menor número de $FN$ y un mayor número de $TP$ en la matriz de confusión, pero también un mayor número de $FP$.

Analizando las dos situaciones, el hecho de que el modelo empeore su *precision* supone arrestar a gente que no debería ser arrestada. Por el contrario, que mejore su *recall* implica reducir el número de sospechosos que deberían ser arrestados y sin embargo se les permite marchar.

Dado que se considera más perjudicial para la ciudad el hecho de dejar marchar a un sospechoso que debiera ser arrestado, se opta finalmente por las soluciones aportadas por la ténica Down-Sampling.

$$"All\ models\ are\ wrong,\ but\ some\ are\ useful"$$


```{r}
# 
# Total de casos -> 4799 (SI) + 27103 (NO) = 32050
# Queremos que los SI correspondan a un 50% de la muestra -> Los NO deberían ser 4799 casos
# 
training.yes <- SQFdataTrain %>% filter(arstmade == 'Y')
training.no <- SQFdataTrain %>% filter(arstmade == 'N')

set.seed(4567)
ind_training.no <- sample(rownames(training.no),4799)
training.no <- training.no[ind_training.no,]

SQFdataTrain_DSAMP <- rbind(training.yes, training.no)

SQFdataTrain_DSAMP %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

\newpage

# 4. Modelado

## 4.1 Regresión logística

Para encontrar los determinantes de que una persona parada sea arrestada o no, utilizamos los modelos lineales generalizados, y dado que la variable respuesta, toma valores N (no fueron arrestados) o Y (sí fueron arrestados), utilizamos la función de enlace logit. Este modelo es de la familia binomial.

Hipótesis

1.	Los casos son independientes entre sí.
2.	La probabilidad de éxito es la misma para todos los casos que tienen los mismos valores de los regresores.

### 4.1.1 Creación de modelos vacío y completo

```{r}
# Creación de modelo vacío
model_glm_DSAMP_Vacio <- glm(arstmade ~ 1, data = SQFdataTrain_DSAMP, family = "binomial")

# Creación de modelo completo
model_glm_DSAMP <- glm(arstmade ~ ., data = SQFdataTrain_DSAMP, family = "binomial")
```

### 4.1.2 Selección de modelos mediante stepwise

```{r}
# Stepwise modelo con Down-Sampling
model_glm_DSAMP_Forw <- step(model_glm_DSAMP_Vacio,
                       scope = list(lower = formula(model_glm_DSAMP_Vacio), upper = formula(model_glm_DSAMP)),
                       direction = "forward", trace = 0)
summary(model_glm_DSAMP_Forw)
```

### 4.1.3 Prueba Likelihood ratio

Dado que la hipótesis nula sostiene que el modelo reducido es el mejor, un valor del p-value para el modelo estadístico mayor que 0,05 nos obliga a aceptar la hipótesis nula, es decir, proporciona evidencia a favor del modelo reducido. Además se puede verificar, según el criterio AIC, el modelo balanceado y construido en base a stepwise es el mejor. 

```{r, warming = FALSE, message=FALSE}
anova(model_glm_DSAMP, model_glm_DSAMP_Forw,  test="Chisq")
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic)
```

### 4.1.4 Evaluación de los parámetros del modelo seleccionado

Como la respuesta es binaria, la función de salida es la probabilidad condicionada de que la respuesta sea un acierto dado los valores de los predictores. Los betas estimados son los log- odds, donde la probabilidad (odds) de que el suceso ocurra se da como la probabilidad de acierto dividido por la probabilidad de fallo.
En cuanto a la interpretación de los parámetros estimados del modelo *model_glm_DSAMP_Forw*, el signo de los mismos indica que ese predictor aumenta o disminuye la probabilidad de que una persona sea arrestada y para evaluar la magnitud de la variación se calculó el exponencial de cada beta. Así se puede determinar por ejemplo: si aumenta  una unidad en la edad, la probabilidad de ser arrestado  se incrementa en un factor de 1,01

```{r}
round(exp(cbind(Estimate=coef(model_glm_DSAMP_Forw),
                confint(model_glm_DSAMP_Forw))), 2)
```

### 4.1.5 Pseudo R^2

Evaluamos el R cuadrado de McFadden mientras más cercano a uno indica que el modelo tiene poder predictivo, es este caso el valor es de 0.587.

```{r, warming = FALSE}
library(pscl)
pR2(model_glm_DSAMP_Forw)
```

### 4.1.6 Importancia de la variable

Si bien el método stepwise selecciona el modelo por criterio AIC, es necesario verificar si al eliminar una variable que no es significativa afecta mucho al modelo, en este caso se valora la opción de eliminar la variable *haircolr*, dado que según el estadístico de Wald a un nivel de significancia de *0.05*, está en el umbral de no rechazar la hipótesis nula de que el coeficiente de una variable independiente en el modelo no es significativamente diferente de cero. Se evalúa un nuevo modelo eliminando esta variable y a priori observando el criterio AIC, no causa un gran efecto en el modelo. Esto se comprueba al analizar tabla *anova* en la que se demuestra que no hay suficiente evidencia para rechazar Ho. 

El análisis se repite para la variable *race*, dado que es un factor, a priori, relacionado con la controversia que ampara esta ley. Después de evaluar los estadísticos vemos que hay suficiente evidencia para considerar importante la variable dentro del modelo.

```{r, warming = FALSE}
# Eliminar haircolr
regTermTest(model_glm_DSAMP_Forw, "haircolr")
model_glm_DSAMP_hair<- glm(arstmade ~ .-haircolr, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_DSAMP_hair_back<-step(model_glm_DSAMP_hair, direction = "backward", trace = 0)
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic, model_glm_DSAMP_hair_back$aic)
anova(model_glm_DSAMP_hair_back, model_glm_DSAMP_Forw,  test="Chisq")

# Eliminar race
regTermTest(model_glm_DSAMP_Forw, "race")
model_glm_DSAMP_race<- glm(arstmade ~ .-race, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_DSAMP_race_back<-step(model_glm_DSAMP_race, direction = "backward", trace = 0)
c(model_glm_DSAMP$aic, model_glm_DSAMP_Forw$aic, model_glm_DSAMP_hair_back$aic, model_glm_DSAMP_race_back$aic)
anova(model_glm_DSAMP_race_back, model_glm_DSAMP_Forw,  test="Chisq")
```

## 4.2 Knn

## 4.3 Random Forest

A continuación se recurre al uso de árboles de decisión para predecir la variable objetivo del problema planteado. Se seguirá el código programado por Javier Moguerza y como complemento al mismo, se compara el procesado de dicho código de forma secuencial y en paralelo.

<!-- ## Árboles de decisión: arstmade -->

<!-- ### Decision tree -->

<!-- ```{r} -->

<!-- ``` -->

### 4.3.1 Selección de predictores

La función `randomForest::rfcv` permite realizar una evaluación del comportamiento del modelo según el número de variables a escoger para cada rama. Dado que el conjunto de train cuenta con relativamente pocos predictores, se emplea un step elevado para comprobar todas las particiones posibles y seleccionar la óptima a la hora de generar el modelo. Una vez realizado el cálculo, se escoge el valor óptimo para generar el conjunto de árboles.

```{r}
# Random Forest con Cross-Validation para selección de predictores
cv.model_rf_10 <- rfcv(trainx=SQFdataTrain_DSAMP[,-match("arstmade",
                                                         colnames(SQFdataTrain_DSAMP))],
                       trainy=SQFdataTrain_DSAMP$arstmade, cv.fold=10,
                       step=0.99, mtry=function(p) max(1, floor(sqrt(p))), ntree = 100)
```

### 4.3.2 Preparación de datos para la generación de modelos

```{r}
# importance(model_rf_10)

# varImpPlot(model_rf_10)

# Preparación de datasets con target en última columna
SQFdataTrain_DSAMP_RF <- SQFdataTrain_DSAMP %>% select(-arstmade)
SQFdataTrain_DSAMP_RF <- cbind(SQFdataTrain_DSAMP_RF,
                               arstmade = SQFdataTrain_DSAMP$arstmade)

SQFdataTest_RF <- SQFdataTest %>% select(-arstmade)
SQFdataTest_RF <- cbind(SQFdataTest_RF, arstmade = SQFdataTest$arstmade)

# Parámetros para el bosque (N - Nº arboles, K - Nº predictores, M - Nº muestras)
N = 600
K = as.integer(names(cv.model_rf_10$error.cv[which.min(cv.model_rf_10$error.cv)])) 
M = round(dim(SQFdataTrain_DSAMP_RF)[1]*0.7)

# Posición de la variable respuesta en el dataset
res = which(colnames(SQFdataTrain_DSAMP_RF)=="arstmade")

# Vectores de modelos
moguerza.forest.sec <- vector("list", N)
moguerza.forest.par <- vector("list", N)
 
# Matrices de predictores
vars.sec = matrix(0,K,N)
vars.par = matrix(0,K,N)

# Tamaño total de la muestra de train y test
k = dim(SQFdataTrain_DSAMP_RF)[1]
m = dim(SQFdataTest_RF)[1]
```

### 4.3.3 Generación de modelos

Se combina la generación de los modelos secuencial y paralelo con el cálculo del tiempo requerido para cada uno de ellos.

* Código secuencial:

```{r}
start.time <- Sys.time()

for(i in 1:N) {
    # Selección de predictores y observaciones para el árbol
    a = sort(sample(1:(dim(SQFdataTrain_DSAMP_RF)[2]-1),K))
    b = sort(sample(1:k, M, replace=TRUE))
    
    # Datos para el árbol
    SQFdataTrain_DSAMP.vot = SQFdataTrain_DSAMP_RF[b,c(a,res)]
    
    # Creación de los árboles
    model.rp <- rpart(SQFdataTrain_DSAMP.vot[,K+1] ~., data = SQFdataTrain_DSAMP.vot[,1:K],
                      cp=0.0001, control = rpart.control(maxdepth = 10),
                      parms=list(split="gini"))
    
    # Almacenamiento de árboles en modelo secuencial
    moguerza.forest.sec[[i]] = model.rp
    
    # Almacenamiento de los predictores seleccionados por árbol
    vars.sec[,i] = as.vector(a)
}

varImp(moguerza.forest.sec)

time.taken.sec <- Sys.time() - start.time
```

* Código paralelo:

```{r}
start.time <- Sys.time()

# Creación de conjuntos aleatorios de train
SQFdataTrain_DSAMP.vot <- foreach(n = 1:N) %dopar% {
    # Selección de predictores y observaciones para el árbol
    a = sort(sample(1:(dim(SQFdataTrain_DSAMP_RF)[2]-1),K))
    b = sort(sample(1:k, M, replace=TRUE))

    # Datos para el árbol
    SQFdataTrain_DSAMP_RF[b,c(a,res)]
}

# Creación de árboles
moguerza.forest.par <- foreach(i=1:N) %dopar% {
    model.rp <- rpart(SQFdataTrain_DSAMP.vot[[i]][,K+1] ~., data = SQFdataTrain_DSAMP.vot[[i]][,1:K],
                      cp=0.0001, control = rpart.control(maxdepth = 10),
                      parms=list(split="gini"))
}

# Almacenamiento de predictores por árbol
for (i in 1:N) {
    vars.par[,i] <- which(is_in(colnames(SQFdataTrain_DSAMP_RF), attr(moguerza.forest.par[[i]]$terms,"term.labels")))
}

time.taken.par <- Sys.time() - start.time
```

### 4.3.4 Evaluación del error en conjunto de train

* Código secuencial:

```{r}
# Matriz de predicciones
pred.matrix.train.sec = matrix(0,k,N)

start.time <- Sys.time()
for (j in 1:N)
{
    prediction = predict(moguerza.forest.sec[[j]], SQFdataTrain_DSAMP_RF[,vars.sec[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
    pred.matrix.train.sec[,j] = prediction.fact
}
Sys.time() - start.time
# Vector de probabilidades
p.arstmade.train.sec = rowSums(pred.matrix.train.sec==factores[2])/N

pred.train.fact.sec = factores[round(p.arstmade.train.sec)+1]
real.train.fact = SQFdataTrain_DSAMP_RF[,res]
pred.train.fact.sec <- relevel(as.factor(pred.train.fact.sec), ref = "Y")

table.moguerza.train.sec = table(pred.train.fact.sec, real.train.fact)
confusionMatrix(table.moguerza.train.sec)
```

* Código paralelo:

```{r}
# Matriz de predicciones
pred.matrix.train.par = matrix(0,k,N)

start.time <- Sys.time()
pred.vect.train.par <- foreach(j = 1:N) %dopar% {
    prediction <- predict(moguerza.forest.par[[j]], SQFdataTrain_DSAMP_RF[,vars.par[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
}

for(j in 1:N){
    pred.matrix.train.par[,j] = pred.vect.train.par[[j]]
}

Sys.time() - start.time

# Vector de probabilidades
p.arstmade.train.par = rowSums(pred.matrix.train.par==factores[2])/N

pred.train.fact.par = factores[round(p.arstmade.train.par)+1]
real.train.fact = SQFdataTrain_DSAMP_RF[,res]
pred.train.fact.par <- relevel(as.factor(pred.train.fact.par), ref = "Y")

table.moguerza.train.par = table(pred.train.fact.par, real.train.fact)
confusionMatrix(table.moguerza.train.par)
```

### 4.3.5 Evaluación del error en conjunto de test

* Código secuencial:

```{r}
# Matriz de predicciones
pred.matrix.test.sec = matrix(0,m,N)

for (j in 1:N)
{
    prediction = predict(moguerza.forest.sec[[j]], SQFdataTest_RF[,vars.sec[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
    pred.matrix.test.sec[,j] = prediction.fact
}

# Vector de probabilidades
p.arstmade.test.sec = rowSums(pred.matrix.test.sec==factores[2])/N 

pred.test.fact.sec = factores[round(p.arstmade.test.sec) + 1]
real.train.fact = SQFdataTest_RF[,res]
pred.test.fact.sec <- relevel(as.factor(pred.test.fact.sec), ref = "Y")

table.moguerza.test.sec = table(pred.test.fact.sec,real.train.fact)
cM_moguerza_sec <- confusionMatrix(table.moguerza.test.sec)
```

* Código paralelo:

```{r}
# Matriz de predicciones
pred.matrix.test.par = matrix(0,m,N)

pred.vect.test.par <- foreach(j = 1:N) %dopar% {
    prediction <- predict(moguerza.forest.par[[j]], SQFdataTest_RF[,vars.par[,j]] )
    factores = colnames(prediction)
    prediction.fact = factores[max.col(prediction)]
}

for(j in 1:N){
    pred.matrix.test.par[,j] = pred.vect.test.par[[j]]
}

# Vector de probabilidades
p.arstmade.test.par = rowSums(pred.matrix.test.par==factores[2])/N

pred.test.fact.par = factores[round(p.arstmade.test.par)+1]
real.train.fact = SQFdataTest_RF[,res]
pred.test.fact.par <- relevel(as.factor(pred.test.fact.par), ref = "Y")

table.moguerza.test.par = table(pred.test.fact.par,real.train.fact)
cM_moguerza_par <- confusionMatrix(table.moguerza.test.par)
#==========================================================================================
```

# 5. EVALUACIÓN

### 4.1.7 Validación cruzada

Dado que nuestro objetivo es construir un modelo de predicción, la métrica más importante es determinar lo bien que el modelo predice para observaciones diferentes a las de prueba. Se construye una tabla de clasificación donde se cruza el verdadero valor de la observación, con la predicción de la misma según el modelo seleccionado, tomando como referencia una predicción mayor a 0.5. Como resultado se obtiene que el modelo predijo con exactitud 1671 personas paradas que fueron arrestadas, de un total de 2091 lo que representa un **sensitivity** de 0.7991, en cuanto a la predicción de los que no fueron arrestados **specificity** corresponde a un acierto de 0.8607


```{r}
# Evaluación del modelo y creación de tabla de resultados
pred_DSAMP_hair_back <- factor(predict(model_glm_DSAMP_hair_back, SQFdataTest, type="response")>0.5,
                          levels=c(FALSE, TRUE),
                          labels=c("N","Y"))

cM_DSAMP_hair_back <- confusionMatrix(pred_DSAMP_hair_back, SQFdataTest$arstmade, positive="Y")

eval_DSAMP_hair_back_metrics <- c(model_glm_DSAMP_hair_back$aic,
                                  model_glm_DSAMP_hair_back$null.deviance,
                                  model_glm_DSAMP_hair_back$deviance,
                                  length(model_glm_DSAMP_hair_back$model)-1)

eval_DSAMP_hair_back <- c(cM_DSAMP_hair_back$byClass[7],
                          cM_DSAMP_hair_back$byClass[5:6],
                          cM_DSAMP_hair_back$byClass[2])
```

#### 4.1.8 Curva ROC

La curva ROC es un gráfico que muestra la relación entre los datos que se predicen correctamente con la tasa de los datos negativos que se consideran erróneamente como positivos. Esta métrica ofrece un mejor resumen de la capacidad predictiva que una tabla de clasificación, porque presenta la potencia predictiva para todos los posibles valores sin establecer una referencia arbitraria, permitiendo así evaluar el rendimiento del clasificador. El área bajo la curva ROC para los datos de testeo es de 0.8977 lo que indica que el modelo discrimina adecuadamente a los arrestados y no arrestados.

```{r, warming = FALSE, message=FALSE}
prob_test <- predict(model_glm_DSAMP_hair_back, SQFdataTest, type="response")
pr_test <- prediction(prob_test, SQFdataTest$arstmade)
pred_tpr_fpr <- performance(pr_test, measure = "tpr", x.measure = "fpr")
plot(pred_tpr_fpr, main = "ROC curve", col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)

auc_test <- performance(pr_test, measure = "auc")
auc_test <- auc_test@y.values[[1]]
auc_test
```


#### 4.1.9 Conclusiones

En los modelos estadísticos analizados, en principio se determina que la variable *race* que corresponde a la raza de las personas paradas resulta significativa en la probabilidad de que sean arrestados, sin embargo, resultaría interesante verificar si efectivamente este es un factor determinante para que una persona sea parada o no, es decir, verificar la hipótesis de que esta ley es un "política de discriminación racial indirecta".  

Según las estadísticas presentadas por el Departamento de Policía (NYPD) en el año 2016, Nueva York ha experimentado una reducción en todas las categorías de delitos, además de la reducción de uso de la técnica de "Stop and Frisk". Ante estos resultados, resulta interesante conocer el impacto que tiene esta ley en las estadísticas de delincuencia.


## 5.1 Comparativa de modelos

```{r}
cM_moguerza_sec <- confusionMatrix(table.moguerza.test.sec)
cM_moguerza_par <- confusionMatrix(table.moguerza.test.par)

fun_rf_eval <- function(x){
    return(c(x$byClass[7],x$byClass[5:6],x$byClass[2]))
}

df.comp.rf <- data.frame(
    rf_node_10 = fun_rf_eval(cM_10),
    rf_moguerza_sec = fun_rf_eval(cM_moguerza_sec),
    rf_moguerza_par = fun_rf_eval(cM_moguerza_par),
    row.names = c("F-measure","Precision","Recall/Sensitivity","Specificity")
)

df.comp.rf
#==========================================================================================
```



# 6. CONCLUSIONES





