---
title: "Models"
author: "Jorge Navarro Garcia"
date: "13 de abril de 2017"
output: pdf_document
---

```{r, message=FALSE}
# Carga de librerías
library(magrittr)
library(dplyr)
library(car)
library(effects)
library(randomForest)
library(caret)
library(dataQualityR)
library(DMwR)
library(foreach)
library(doMC)
registerDoMC(4)
library(class)
```

# Creación de modelos predictivos

Dado que la variable target *arstmade* muestra un desbalanceo en sus clases, 15% clase positiva frente a 85% clase negativa, es necesario tener en cuenta métricas de evaluación de los modelos que tengan en cuenta las diferencias entre clases a la hora de realizar predicciones. De esta forma, la evaluación de modelos mediante el coeficiente de *accuracy*, una de las métricas más comunes en problemas de clasificación binaria, se muestra incompleta. Por ello se tiene en cuenta otro tipo de métricas como la matriz de confusión o 

## Carga de datos

```{r,message=FALSE}
# Carga del Dataset
source('Cleaning_Data.R')
dim(SQFdata)
```


## Análisis descriptivo

```{r, message=FALSE}
drq.num <- paste("./dqr_num.csv", sep = "")
drq.cat <- paste("./dqr_cat.csv", sep = "")
checkDataQuality(SQFdata, out.file.num = drq.num,  out.file.cat = drq.cat)
DQR.num <- read.csv("dqr_num.csv")
DQR.cat <- read.csv("dqr_cat.csv")
```

### A Variables numéricas
```{r}
print(DQR.num)

# Variables a tener en cuenta por NAs -> age, xcoord e ycoord
```

### B Variables categóricas
```{r}
print(DQR.cat)
# Variables a tener en cuenta por NAs > 60% -> arstoffn, sumoffen, officrid, offverb, ¿offshld (54.62)?, forceuse, othfeatr, addrnum, stname, beat, post

# Variables a tener en cuenta por NAs cercanos al 20% -> adtlrept, pistol, riflshot, asltweap, knifcuti, machgun, othrweap, pf_hands, pf_wall, pf_grnd, pf_drwep, pf_ptwep, pf_baton, pf_hcuff, pf_pepsp, pf_other, , ac_rept, ac_inves, rf_vcrim, rf_othsw, ac_proxm, rf_attir, cs_objcs, cs_descr, cs_casng, cs_lkout, rf_vcact, cs_cloth, cs_drgtr, ac_evasv, ac_assoc, cs_furtv, rf_rfcmp, , ac_cgdir, rf_verbl, cs_vcrim, cs_bulge, cs_other, ac_incid, ac_time, rf_knowl, ac_stsnd, ac_other, sb_hdobj, sb_outln, sb_admis, sb_other, rf_furt, rf_bulg, premname, stinter, crossst, sector
```

## Transformación de los datos

### Eliminación de variables

```{r}

# Eliminación de variables con más de 60% de datos faltantes.
SQFdata_modif <- SQFdata %>%
                    select(-c(arstoffn, sumoffen, officrid, offverb, offshld,
                                       forceuse, othfeatr, addrnum, stname, beat, post))



# Eliminación de variables con 20% de NAs pero nula varianza (casos pertenecientes
# todos a una misma clase). 6 variables eliminadas
summary(SQFdata_modif$adtlrept);summary(SQFdata_modif$riflshot);
summary(SQFdata_modif$asltweap);summary(SQFdata_modif$machgun);
summary(SQFdata_modif$pf_baton);summary(SQFdata_modif$pf_pepsp)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(adtlrept, riflshot, asltweap, machgun,
                             pf_baton, pf_pepsp))



# Eliminación de variables con demasiados niveles (strings). 4 variables eliminadas
summary(SQFdata_modif$premname);summary(SQFdata_modif$stinter);
summary(SQFdata_modif$crossst);summary(SQFdata_modif$sector)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(premname, stinter, crossst, sector))



# Eliminación de variables que no aparecen en el checkDataQuality. 7 variables eliminadas.
summary(SQFdata_modif$state);summary(SQFdata_modif$zip);summary(SQFdata_modif$addrtyp);
summary(SQFdata_modif$rescode);summary(SQFdata_modif$premtype);
summary(SQFdata_modif$aptnum);summary(SQFdata_modif$timestop)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(state,zip,addrtyp,rescode,premtype,aptnum,timestop))



# Eliminación de factores con más de 53 niveles. 4 variables eliminadas.
length(levels(SQFdata_modif$pct));length(levels(SQFdata_modif$crimsusp));
length(levels(SQFdata_modif$addrpct));length(levels(SQFdata_modif$detailCM))

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(pct,crimsusp,addrpct,detailCM))



# Eliminación de variables con poca varianza. 6 variables eliminadas.
summary(SQFdata_modif$year);summary(SQFdata_modif$datestop);
summary(SQFdata_modif$compyear);summary(SQFdata_modif$comppct);
summary(SQFdata_modif$lineCM);summary(SQFdata_modif$dob)

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(year,datestop,compyear,comppct, lineCM, dob))



# Eliminación de más variables con poca varianza. 1 variable eliminada.

# Se analiza el atributo y en caso de que no sea un factor, se devuelve valor
# 2 para que no sea eliminado.
fun_2level <- function(x){
    ifelse(is.factor(x),return(length(levels(x))),return(2))
}

names(SQFdata_modif)[which(sapply(SQFdata_modif, fun_2level) < 2)]

SQFdata_modif <- SQFdata_modif %>%
                    select(-c(which(sapply(SQFdata_modif, fun_2level) < 2)))

# Con nearZeroVar se eliminan más variables
# SQFdata_modif <- SQFdata_modif[-nearZeroVar(SQFdata_modif)]



# Eliminación de coordenadas:
SQFdata_modif <- SQFdata_modif %>%
                    select(-c(xcoord, ycoord))



# Variables en duda
summary(SQFdata_modif$ser_num)
summary(SQFdata_modif$revcmd)
summary(SQFdata_modif$repcmd)



# Número de variables final
dim(SQFdata)
dim(SQFdata_modif)
```

### Eliminación de NAs

```{r}

# Eliminación de NAs en variable age
SQFdata_modif %>% group_by(is.na(age)) %>%
    summarise(n())

SQFdata_modif <- SQFdata_modif %>% filter(!is.na(age))

dim(SQFdata)
dim(SQFdata_modif)

# Trabajo con NAs

# Variables NO eliminadas
summary(SQFdata_modif$pistol);summary(SQFdata_modif$knifcuti);summary(SQFdata_modif$othrweap);

summary(SQFdata_modif$pf_hands);summary(SQFdata_modif$pf_wall);summary(SQFdata_modif$pf_grnd);
summary(SQFdata_modif$pf_drwep);summary(SQFdata_modif$pf_ptwep);summary(SQFdata_modif$pf_hcuff);
summary(SQFdata_modif$pf_other);

summary(SQFdata_modif$ac_rept);summary(SQFdata_modif$ac_inves);summary(SQFdata_modif$rf_vcrim);
summary(SQFdata_modif$rf_othsw);summary(SQFdata_modif$ac_proxm);summary(SQFdata_modif$rf_attir);
summary(SQFdata_modif$cs_objcs);summary(SQFdata_modif$cs_descr);summary(SQFdata_modif$cs_casng);
summary(SQFdata_modif$cs_lkout);summary(SQFdata_modif$rf_vcact);summary(SQFdata_modif$cs_cloth);
summary(SQFdata_modif$cs_drgtr);summary(SQFdata_modif$ac_evasv);summary(SQFdata_modif$ac_assoc);
summary(SQFdata_modif$cs_furtv);summary(SQFdata_modif$rf_rfcmp);summary(SQFdata_modif$ac_cgdir);
summary(SQFdata_modif$rf_verbl);summary(SQFdata_modif$cs_vcrim);summary(SQFdata_modif$cs_bulge);
summary(SQFdata_modif$cs_other);summary(SQFdata_modif$ac_incid);summary(SQFdata_modif$ac_time);
summary(SQFdata_modif$rf_knowl);summary(SQFdata_modif$ac_stsnd);summary(SQFdata_modif$ac_other);
summary(SQFdata_modif$sb_hdobj);summary(SQFdata_modif$sb_outln);summary(SQFdata_modif$sb_admis);
summary(SQFdata_modif$sb_other);summary(SQFdata_modif$rf_furt);summary(SQFdata_modif$rf_bulg);


# Modificación de variables no eliminadas
SQFdata_modif$pistol[which(is.na(SQFdata_modif$pistol))]     <- 'N'
SQFdata_modif$knifcuti[which(is.na(SQFdata_modif$knifcuti))] <- 'N'
SQFdata_modif$othrweap[which(is.na(SQFdata_modif$othrweap))] <- 'N'

SQFdata_modif$pf_hands[which(is.na(SQFdata_modif$pf_hands))] <- 'N'
SQFdata_modif$pf_wall[which(is.na(SQFdata_modif$pf_wall))]   <- 'N'
SQFdata_modif$pf_grnd[which(is.na(SQFdata_modif$pf_grnd))]   <- 'N'
SQFdata_modif$pf_drwep[which(is.na(SQFdata_modif$pf_drwep))] <- 'N'
SQFdata_modif$pf_ptwep[which(is.na(SQFdata_modif$pf_ptwep))] <- 'N'
SQFdata_modif$pf_hcuff[which(is.na(SQFdata_modif$pf_hcuff))] <- 'N'
SQFdata_modif$pf_other[which(is.na(SQFdata_modif$pf_other))] <- 'N'

SQFdata_modif$ac_rept[which(is.na(SQFdata_modif$ac_rept))]   <- 'N'
SQFdata_modif$ac_inves[which(is.na(SQFdata_modif$ac_inves))] <- 'N'
SQFdata_modif$rf_vcrim[which(is.na(SQFdata_modif$rf_vcrim))] <- 'N'
SQFdata_modif$rf_othsw[which(is.na(SQFdata_modif$rf_othsw))] <- 'N'
SQFdata_modif$ac_proxm[which(is.na(SQFdata_modif$ac_proxm))] <- 'N'
SQFdata_modif$rf_attir[which(is.na(SQFdata_modif$rf_attir))] <- 'N'
SQFdata_modif$cs_objcs[which(is.na(SQFdata_modif$cs_objcs))] <- 'N'
SQFdata_modif$cs_descr[which(is.na(SQFdata_modif$cs_descr))] <- 'N'
SQFdata_modif$cs_casng[which(is.na(SQFdata_modif$cs_casng))] <- 'N'
SQFdata_modif$cs_lkout[which(is.na(SQFdata_modif$cs_lkout))] <- 'N'
SQFdata_modif$rf_vcact[which(is.na(SQFdata_modif$rf_vcact))] <- 'N'
SQFdata_modif$cs_cloth[which(is.na(SQFdata_modif$cs_cloth))] <- 'N'
SQFdata_modif$cs_drgtr[which(is.na(SQFdata_modif$cs_drgtr))] <- 'N'
SQFdata_modif$ac_evasv[which(is.na(SQFdata_modif$ac_evasv))] <- 'N'
SQFdata_modif$ac_assoc[which(is.na(SQFdata_modif$ac_assoc))] <- 'N'
SQFdata_modif$cs_furtv[which(is.na(SQFdata_modif$cs_furtv))] <- 'N'
SQFdata_modif$rf_rfcmp[which(is.na(SQFdata_modif$rf_rfcmp))] <- 'N'
SQFdata_modif$ac_cgdir[which(is.na(SQFdata_modif$ac_cgdir))] <- 'N'
SQFdata_modif$rf_verbl[which(is.na(SQFdata_modif$rf_verbl))] <- 'N'
SQFdata_modif$cs_vcrim[which(is.na(SQFdata_modif$cs_vcrim))] <- 'N'
SQFdata_modif$cs_bulge[which(is.na(SQFdata_modif$cs_bulge))] <- 'N'
SQFdata_modif$cs_other[which(is.na(SQFdata_modif$cs_other))] <- 'N'
SQFdata_modif$ac_incid[which(is.na(SQFdata_modif$ac_incid))] <- 'N'
SQFdata_modif$ac_time[which(is.na(SQFdata_modif$ac_time))]   <- 'N'
SQFdata_modif$rf_knowl[which(is.na(SQFdata_modif$rf_knowl))] <- 'N'
SQFdata_modif$ac_stsnd[which(is.na(SQFdata_modif$ac_stsnd))] <- 'N'
SQFdata_modif$ac_other[which(is.na(SQFdata_modif$ac_other))] <- 'N'
SQFdata_modif$sb_hdobj[which(is.na(SQFdata_modif$sb_hdobj))] <- 'N'
SQFdata_modif$sb_outln[which(is.na(SQFdata_modif$sb_outln))] <- 'N'
SQFdata_modif$sb_admis[which(is.na(SQFdata_modif$sb_admis))] <- 'N'
SQFdata_modif$sb_other[which(is.na(SQFdata_modif$sb_other))] <- 'N'
SQFdata_modif$rf_furt[which(is.na(SQFdata_modif$rf_furt))]   <- 'N'
SQFdata_modif$rf_bulg[which(is.na(SQFdata_modif$rf_bulg))]   <- 'N'


# AÑADIR EXPLICACIÓN CON PAQUETE MissingDataGUI


# SQFdata_modif %>% group_by(pistol) %>%
#     group_by(pistol, knifcuti, othrweap) %>%
#     select(pistol, knifcuti, othrweap) %>% 
#     summarise(n())

# SQFdata_modif %>% group_by(pf_hands) %>%
#     filter(is.na(pf_hands)) %>%
#     group_by(pf_wall,pf_grnd,pf_drwep,pf_ptwep,pf_hcuff,pf_other) %>%
#     group_by(pf_wall) %>%
#     group_by(pf_hands,pf_wall,pf_grnd,pf_drwep,pf_ptwep,pf_hcuff,pf_other) %>%
#     select(pf_hands,pf_wall,pf_grnd,pf_drwep,pf_ptwep,pf_hcuff,pf_other) %>% 
#     summarise(count = n())
#     mutate(percent = 100*count/sum(count))

# Comprobación de NAs
sum(is.na(SQFdata))
sum(is.na(SQFdata_modif))
```

## División de muestra en train/test

```{r}
# Creación de conjuntos train y test
tot_obs <- dim(SQFdata_modif)[1]
indices <- 1:tot_obs

set.seed(1234)
indices_train <- sample(indices, 0.7*tot_obs)
SQFdataTrain = SQFdata_modif[indices_train, ]
SQFdataTest = SQFdata_modif[-indices_train, ]

# Datos desbalanceados
SQFdataTrain %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

### Ajuste del desbalanceo: Down-sampling y SMOTE

- Down-Sampling:

```{r}
# Total de casos -> 4847 (si) + 27203 (no) = 32050
# Queremos que los SI correspondan a un 50% de la muestra -> Los NO deberían ser 4847 casos
training.yes <- SQFdataTrain %>% filter(arstmade == 'Y')
training.no <- SQFdataTrain %>% filter(arstmade == 'N')

set.seed(4567)
ind_training.no <- sample(rownames(training.no),4799)
training.no <- training.no[ind_training.no,]

SQFdataTrain_DSAMP <- rbind(training.yes, training.no)

SQFdataTrain_DSAMP %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

- SMOTE:

En SMOTE perc.over determina el número de casos por caso que se añaden a la clase minoritaria, mientras que perc.under es el número de casos que se seleccionan de la clase mayoritaria por caso añadido a la minoritaria.

Es decir, en el caso que nos ocupa, la clase negativa son 4799 casos y la positiva 27103 Nos interesa que ambas clases posean el mismo número de casos, por lo que la clase negativa tendrá que ser ampliada en 27103/4799 = 5.647 = 4.647 casos por cada caso que existe.

Para añadir los casos necesarios, perc.over tiene que fijarse a un múltiplo de 100, de lo contrario redondea a la baja. Para afinar el resultado, se ajusta perc.under de la siguiente forma:

Sabemos que para este caso debemos añadir al menos 4.647 casos por caso en la clase minoritaria, perc.over se fija a 400 y se calcula el número de casos que se han de seleccionar de la clase mayoritaria en base al número de casos añadidos. Se añaden 4·4799 = 19196 casos, por lo que en la clase minoritaria quedarán finalmente $19196+4799=23995$ casos. Queremos que la clase mayoritaria alcance ese mismo número de casos, por lo que habrá que seleccionar *X* casos por cada caso añadido a la clase minoritaria: $19196·X=23995$
Quedando como resultado final un perc.under de *1.25*.

```{r}
# Ajuste del desbalanceo con SMOTE (se rechaza la posibilidad de realizar
# up-sampling dado que es necesario añadir demasiados casos)
set.seed(6789)
# SQFdataTrain_SMOTE <- SMOTE(arstmade ~ ., data=SQFdataTrain, k = 10, perc.over = 400, perc.under = 125)
# SQFdataTrain_SMOTE <- SMOTE(arstmade ~ ., data=SQFdataTrain, k = 10, perc.over = 300, perc.under = 133.33)
SQFdataTrain_SMOTE <- SMOTE(arstmade ~ ., data=SQFdataTrain, k = 10, perc.over = 100, perc.under = 200)
# SQFdataTrain_SMOTE <- SMOTE(arstmade ~ ., data=SQFdataTrain, k = 15, perc.over = 50, perc.under = 300)
# SQFdataTrain_SMOTE <- SMOTE(arstmade ~ ., data=SQFdataTrain, k = 15, perc.over = 20, perc.under = 600.4)
# SQFdataTrain_SMOTE <- SMOTE(arstmade ~ ., data=SQFdataTrain, k = 15, perc.over = 15, perc.under = 767.45)

SQFdataTrain_SMOTE %>% group_by(arstmade) %>%
    summarise(count = n()) %>%
    mutate(percent = 100*count/sum(count))
```

## Regresión logística: arstmade

### Creación de modelos vacíos y completos

```{r}
# CREACION DE MODELOS VACIOS
#==========================================================================================
model_glm_Vacio <- glm(arstmade ~ 1, data = SQFdataTrain, family = "binomial")
model_glm_DSAMP_Vacio <- glm(arstmade ~ 1, data = SQFdataTrain_DSAMP, family = "binomial")
model_glm_SMOTE_Vacio <- glm(arstmade ~ 1, data = SQFdataTrain_SMOTE, family = "binomial")
#==========================================================================================

# CREACION DE MODELOS COMPLETOS
#==========================================================================================
fun_glm <- function(x){
    model <- glm(arstmade ~ ., data = x, family = "binomial")
    print(summary(model))
    # if(deparse(substitute(x)) %in% c("SQFdataTrain_DSAMP","SQFdataTrain_SMOTE")){
    model$xlevels$eyecolor <- levels(SQFdataTrain$eyecolor)
    # }
    pred <- predict(model, SQFdataTest, type = "response")
    print(confusionMatrix(factor(pred > 0.5, levels = c(FALSE, TRUE), labels = c("N","Y")),
    SQFdataTest$arstmade, positive = "Y"))
    return(model)
}

model_glm       <- fun_glm(SQFdataTrain)
model_glm_DSAMP <- fun_glm(SQFdataTrain_DSAMP)
model_glm_SMOTE <- fun_glm(SQFdataTrain_SMOTE)
#==========================================================================================
```

### Selección de modelos mediante stepwise

```{r}
# STEPWISE MODELO NORMAL
#==========================================================================================
model_glm_Back <- step(model_glm, trace = 0)

model_glm_Back <- step(model_glm,
                       scope = list(lower = formula(model_glm_Vacio), upper = formula(model_glm)),
                       direction = "backward", trace = 0)
model_glm_Forw <- step(model_glm_Vacio,
                       scope = list(lower = formula(model_glm_Vacio), upper = formula(model_glm)),
                       direction = "forward", trace = 0)
model_glm_Both <- step(model_glm_Vacio,
                       scope = list(lower = formula(model_glm_Vacio), upper = formula(model_glm)),
                       direction = "both", trace = 0, k = 2)
#==========================================================================================

# STEPWISE MODELO DOWN-SAMPLING
#==========================================================================================
model_glm_DSAMP_Back <- step(model_glm_DSAMP,
                       scope = list(lower = formula(model_glm_DSAMP_Vacio), upper = formula(model_glm_DSAMP)),
                       direction = "backward", trace = 0)
model_glm_DSAMP_Forw <- step(model_glm_DSAMP_Vacio,
                       scope = list(lower = formula(model_glm_DSAMP_Vacio), upper = formula(model_glm_DSAMP)),
                       direction = "forward", trace = 0)
model_glm_DSAMP_Both <- step(model_glm_DSAMP_Vacio,
                       scope = list(lower = formula(model_glm_DSAMP_Vacio), upper = formula(model_glm_DSAMP)),
                       direction = "both", trace = 0, k = 2)
#==========================================================================================

# STEPWISE MODELO SMOTE
#==========================================================================================
model_glm_SMOTE_Back <- step(model_glm_SMOTE,
                       scope = list(lower = formula(model_glm_SMOTE_Vacio), upper = formula(model_glm_SMOTE)),
                       direction = "backward", trace = 0)
model_glm_SMOTE_Forw <- step(model_glm_SMOTE_Vacio,
                       scope = list(lower = formula(model_glm_SMOTE_Vacio), upper = formula(model_glm_SMOTE)),
                       direction = "forward", trace = 0)
model_glm_SMOTE_Both <- step(model_glm_SMOTE_Vacio,
                       scope = list(lower = formula(model_glm_SMOTE_Vacio), upper = formula(model_glm_SMOTE)),
                       direction = "both", trace = 0, k = 2)
#==========================================================================================

# AUTOMATIZACION DE STEPWISE (por terminar)
#==========================================================================================
fun_glm_stepwise <- function(low, up){
    # model_Back <- do.call("step", list(up, scope = list(lower = formula(low), upper = formula(up)),
    #                    direction = "backward", trace = 0))
        
    # model_Back <- step(up, scope = list(lower = formula(low), upper = formula(up)),
    #                    direction = "backward", trace = 0)
    model_Forw <- step(low, scope = list(lower = formula(low), upper = formula(up)),
                       direction = "forward", trace = 0)
    model_Both <- step(low, scope = list(lower = formula(low), upper = formula(up)),
                       direction = "both", trace = 0, k = 2)
    models <- list(model_Forw, model_Both)
    return(models)
}

fun_glm_stepwise <- function(low, up){
    foreach(i=2:3) %dopar% 
        case_when(
        # i == 1 ~ ,
        i == 2 ~ model_Forw <- step(low, scope = list(lower = formula(low), upper = formula(up)),
                                        direction = "forward", trace = 0),
        i == 3 ~ model_Both <- step(low, scope = list(lower = formula(low), upper = formula(up)),
                                    direction = "both", trace = 0, k = 2)
    )
    models <- list(model_Forw, model_Both)
    return(models)
}

models_glm <- fun_glm_stepwise(model_glm_Vacio, model_glm)
#==========================================================================================
```

### Evaluación de modelos de regresión logística

```{r}
# FUNCION DE EVALUACION Y CREACION DE TABLA DE RESULTADOS
#==========================================================================================
fun_glm_eval <- function(x){return(c(x$aic, x$null.deviance, x$deviance, length(x$model)-1))}

df.comp.glm <- data.frame(glm = fun_glm_eval(model_glm),
                          # glm_Back = fun_glm_eval(model_glm_Back),
                          glm_Forw = fun_glm_eval(model_glm_Forw),
                          glm_Both = fun_glm_eval(model_glm_Both),
                          glm_DSAMP = fun_glm_eval(model_glm),
                          # glm_DSAMP_Back = fun_glm_eval(model_glm_DSAMP_Back),
                          glm_DSAMP_Forw = fun_glm_eval(model_glm_DSAMP_Forw),
                          glm_DSAMP_Both = fun_glm_eval(model_glm_DSAMP_Both),
                          glm_SMOTE = fun_glm_eval(model_glm),
                          # glm_SMOTE_Back = fun_glm_eval(model_glm_SMOTE_Back),
                          glm_SMOTE_Forw = fun_glm_eval(model_glm_SMOTE_Forw),
                          glm_SMOTE_Both = fun_glm_eval(model_glm_SMOTE_Both),
                          row.names = c("AIC","Null deviance","Deviance","Nº Predictors"))

df.comp.glm
#==========================================================================================

# OTRAS EVALUACIONES (por terminar)
#==========================================================================================

sensitivity(SQFdataTest$arstmade, factor(pred_glm > 0.5, levels = c(FALSE, TRUE), labels = c("N","Y")), positive = "Y")
specificity(SQFdataTest$arstmade, factor(pred_glm > 0.5, levels = c(FALSE, TRUE), labels = c("N","Y")))

# ¿Es interesante?
library(ROSE)
accuracy.meas(SQFdataTest$arstmade, pred_glm, threshold = 0.02)
accuracy.meas(SQFdataTest$arstmade, pred_glm_DSAMP, threshold = 0.02)
accuracy.meas(SQFdataTest$arstmade, pred_glm_SMOTE, threshold = 0.02)
#==========================================================================================
```

## KNN: arstmade

```{r}
# SEPARACION DE DATOS EN VARIABLES CUALITATIVAS Y CUANTITATIVAS
#==========================================================================================
# TRAIN
SQFdataTrain.numeric <- SQFdataTrain[,which(sapply(SQFdataTrain,is.numeric))]
SQFdataTrain.numeric$arstmade <- as.factor(as.numeric(SQFdataTrain$arstmade)-1)

SQFdataTrain_DSAMP.numeric <- SQFdataTrain_DSAMP[,which(sapply(SQFdataTrain_DSAMP,is.numeric))]
SQFdataTrain_DSAMP.numeric$arstmade <- as.factor(as.numeric(SQFdataTrain_DSAMP$arstmade)-1)

SQFdataTrain_SMOTE.numeric <- SQFdataTrain_SMOTE[,which(sapply(SQFdataTrain_SMOTE,is.numeric))]
SQFdataTrain_SMOTE.numeric$arstmade <- as.factor(as.numeric(SQFdataTrain_SMOTE$arstmade)-1)

SQFdataTrain.cat <- SQFdataTrain[,which(sapply(SQFdataTrain,is.factor))]
SQFdataTrain_DSAMP.cat <- SQFdataTrain_DSAMP[,which(sapply(SQFdataTrain_DSAMP,is.factor))]
SQFdataTrain_SMOTE.cat <- SQFdataTrain_SMOTE[,which(sapply(SQFdataTrain_SMOTE,is.factor))]


# TEST
SQFdataTest.numeric <- SQFdataTest[,which(sapply(SQFdataTest,is.numeric))]
SQFdataTest.numeric$arstmade <- as.factor(as.numeric(SQFdataTest$arstmade)-1)

SQFdataTest.cat <- SQFdataTest[,which(sapply(SQFdataTest,is.factor))]
#==========================================================================================

# KNN CON CARET Y EXPAND.GRID
#==========================================================================================
KNN_grid <- expand.grid(k = seq(3,18,5))
train_control <- trainControl(method="cv", number=10, repeats = 1, allowParallel = TRUE)

fun_knn <- function(x){
    norm <- train(arstmade ~ ., data = x, method = "knn",
                      tuneGrid = KNN_grid, preProcess = c("center", "scale"),
                      trControl = train_control)
    return(norm)
}
fun_knn.cat <- function(x){
    cat <- train(arstmade ~ ., data = x, method = "knn",
                      tuneGrid = KNN_grid, preProcess = c("center", "scale"),
                      trControl = train_control)
    return(cat)
}
fun_knn.numeric <- function(x){
    numeric <- train(arstmade ~ ., data = x, method = "knn",
                      tuneGrid = KNN_grid, preProcess = c("center", "scale"),
                      trControl = train_control)
    return(numeric)
}

model_knn <- fun_knn(SQFdataTrain)
model_knn.cat <- fun_knn.cat(SQFdataTrain.cat)
model_knn.numeric <- fun_knn.numeric(SQFdataTrain.numeric)

model_knn_DSAMP <- fun_knn(SQFdataTrain_DSAMP)
model_knn_DSAMP.cat <- fun_knn.cat(SQFdataTrain_DSAMP.cat)
model_knn_DSAMP.numeric <- fun_knn.numeric(SQFdataTrain_DSAMP.numeric)

model_knn_SMOTE <- fun_knn(SQFdataTrain_SMOTE)
model_knn_SMOTE.cat <- fun_knn.cat(SQFdataTrain_SMOTE.cat)
model_knn_SMOTE.numeric <- fun_knn.numeric(SQFdataTrain_SMOTE.numeric)
#==========================================================================================
```

```{r}
# EVALUACION DE KNN
#==========================================================================================
cM_knn <- confusionMatrix(predict(model_knn, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_knn.cat <- confusionMatrix(predict(model_knn.cat, SQFdataTest.cat), SQFdataTest.cat$arstmade, positive="Y")
cM_knn.numeric <- confusionMatrix(predict(model_knn.numeric, SQFdataTest.numeric), SQFdataTest.numeric$arstmade, positive="1")

cM_knn_DSAMP <- confusionMatrix(predict(model_knn_DSAMP, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_knn_DSAMP.cat <- confusionMatrix(predict(model_knn_DSAMP.cat, SQFdataTest.cat), SQFdataTest.cat$arstmade, positive="Y")
cM_knn_DSAMP.numeric <- confusionMatrix(predict(model_knn_DSAMP.numeric, SQFdataTest.numeric), SQFdataTest.numeric$arstmade, positive="1")

cM_knn_SMOTE <- confusionMatrix(predict(model_knn_SMOTE, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_knn_SMOTE.cat <- confusionMatrix(predict(model_knn_SMOTE.cat, SQFdataTest.cat), SQFdataTest.cat$arstmade, positive="Y")
cM_knn_SMOTE.numeric <- confusionMatrix(predict(model_knn_SMOTE.numeric, SQFdataTest.numeric), SQFdataTest.numeric$arstmade, positive="1")

fun_eval <- function(x){
    return(c(x$byClass[7],x$byClass[5:6],x$byClass[2]))
}

df.comp.knn <- data.frame(
    knn = fun_eval(cM_knn),
    knn.cat = fun_eval(cM_knn.cat),
    knn.numeric = fun_eval(cM_knn.numeric),
    knn_DSAMP = fun_eval(cM_knn_DSAMP),
    knn_DSAMP.cat = fun_eval(cM_knn_DSAMP.cat),
    knn_DSAMP.numeric = fun_eval(cM_knn_DSAMP.numeric),
    knn_SMOTE = fun_eval(cM_knn_SMOTE),
    knn_SMOTE.cat = fun_eval(cM_knn_SMOTE.cat),
    knn_SMOTE.numeric = fun_eval(cM_knn_SMOTE.numeric),
    row.names = c("F-measure","Precision","Recall/Sensitivity","Specificity")
)

df.comp.knn
#==========================================================================================
```


## Árboles de decisión: arstmade

### Random Forest con Caret: Cross Validation (k=10) y Expand.Grid

```{r}
# RANDOM FOREST CON CARET: CROSS VALIDATION Y GRID
#==========================================================================================
RF_grid <- expand.grid(mtry = c(9,19,27,36,45,53))
train_control <- trainControl(method="cv", number=10, repeats = 1, allowParallel = TRUE)

model_rforst <- train(arstmade ~ ., data = SQFdataTrain, method = "parRF",
                      tuneGrid = RF_grid, preProcess = c("center", "scale"),
                      trControl = train_control)
model_rforst_DSAMP <- train(arstmade ~ ., data = SQFdataTrain_DSAMP, method = "parRF",
                      tuneGrid = RF_grid, preProcess = c("center", "scale"),
                      trControl = train_control)
model_rforst_SMOTE <- train(arstmade ~ ., data = SQFdataTrain_SMOTE, method = "parRF",
                      tuneGrid = RF_grid, preProcess = c("center", "scale"),
                      trControl = train_control)
#==========================================================================================

```

### Random Forest con limite de nodos terminales

```{r}

# GENERACION DE MODELOS CON LIMITE DE NODOS TERMINALES
#==========================================================================================
fun_rf_limNode <- function(x){
    foreach(ntree=rep(100, 6), .combine=combine, .multicombine=TRUE,
              .packages='randomForest') %dopar% {
    randomForest(arstmade ~ ., data = SQFdataTrain_DSAMP, ntree=ntree, mtry = 19, maxnodes = x)
    }
}

model_rf_10 <- fun_rf_limNode(10)
model_rf_25 <- fun_rf_limNode(25)
model_rf_50 <- fun_rf_limNode(50)
model_rf_75 <- fun_rf_limNode(75)
model_rf_120 <- fun_rf_limNode(120)
model_rf_200 <- fun_rf_limNode(200)
model_rf_500 <- fun_rf_limNode(500)

model_rf_NOmax <- foreach(ntree=rep(100, 6), .combine=combine, .multicombine=TRUE,
              .packages='randomForest') %dopar% {
    randomForest(arstmade ~ ., data = SQFdataTrain_DSAMP, ntree=ntree, mtry = 19)
}

model_rf_NOmax_UNB <- foreach(ntree=rep(100, 6), .combine=combine, .multicombine=TRUE,
              .packages='randomForest') %dopar% {
    randomForest(arstmade ~ ., data = SQFdataTrain, ntree=ntree, mtry = 19)
}
#==========================================================================================

```

### Evaluación de modelos de random forest

```{r}

# RANDOM FOREST CON CARET - EVALUACION
#==========================================================================================
cM_rforst <- confusionMatrix(predict(model_rforst, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_rforst_DSAMP <- confusionMatrix(predict(model_rforst_DSAMP, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_rforst_SMOTE <- confusionMatrix(predict(model_rforst_SMOTE, SQFdataTest), SQFdataTest$arstmade, positive="Y")
#==========================================================================================

# RESTO DE MODELOS - EVALUACION
#==========================================================================================
cM_10 <- confusionMatrix(predict(model_rf_10, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_25 <- confusionMatrix(predict(model_rf_25, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_50 <- confusionMatrix(predict(model_rf_50, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_75 <- confusionMatrix(predict(model_rf_75, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_120 <- confusionMatrix(predict(model_rf_120, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_200 <- confusionMatrix(predict(model_rf_200, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_500 <- confusionMatrix(predict(model_rf_500, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_NOmax <- confusionMatrix(predict(model_rf_NOmax, SQFdataTest), SQFdataTest$arstmade, positive="Y")
cM_NOmax_UNB <- confusionMatrix(predict(model_rf_NOmax_UNB, SQFdataTest), SQFdataTest$arstmade, positive="Y")

cM_NOmax$overall
cM_NOmax$byClass

cM_NOmax_UNB$overall
cM_NOmax_UNB$byClass

cM_NOmax_UNB$byClass[7]
cM_NOmax_UNB$byClass[5]

fun_rf_eval <- function(x){
    return(c(x$byClass[7],x$byClass[5:6],x$byClass[2]))
}

df.comp.rf <- data.frame(
    rf_caret = fun_rf_eval(cM_rforst),
    rf_caret_DSAMP = fun_rf_eval(cM_rforst_DSAMP),
    rf_caret_SMOTE = fun_rf_eval(cM_rforst_SMOTE),
    rf_node_10 = fun_rf_eval(cM_10),
    rf_node_25 = fun_rf_eval(cM_25),
    rf_node_50 = fun_rf_eval(cM_50),
    rf_node_75 = fun_rf_eval(cM_75),
    rf_node_120 = fun_rf_eval(cM_120),
    rf_node_200 = fun_rf_eval(cM_200),
    rf_node_500 = fun_rf_eval(cM_500),
    rf_node_NOmax = fun_rf_eval(cM_NOmax),
    rf_node_NOmax_UNB = fun_rf_eval(cM_NOmax_UNB),
    row.names = c("F-measure","Precision","Recall/Sensitivity","Specificity")
)

df.comp.rf

#==========================================================================================
```

Problema al generar modelos con down-sampling: Se mejora considerablemente la métrica *recall* (que coincide con la métrica *sensitivity* de la matriz de confusión) del modelo, es decir, la tasa de arrestos reales predichos como tal. Sin embargo, se empeora la métrica *precision* o la tasa de acierto en las predicciones de arrestos.

Siendo $TP=\text{True Positive}$ y $FN=\text{False Negative}$:

$$\text{Sensitivity}=\frac{TP}{TP+FN}$$
$$\text{Precision}=\frac{TP}{TP+FN}$$

Por tanto, es necesario determinar cuál de ambas métricas se desea favorecer. También cabría destacar que, al reducir el número de observaciones, down-sampling permite generar los modelos de forma más rápida.



## Sistemas de recomendación: arstmade
    Aprendizaje colaborativo
	Basándonos en las características de otros delincuentes que NO hayan sido detenidos, recomendar posibles armas o crímenes "extra"
	Basándonos en la gente arrestada, recomendar si se debe arrestar a un nuevo individuo que ya ha sido parado
